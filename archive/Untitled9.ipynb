{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda env=/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/ipykernel_launcher.py:153: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.sum(chosenMask)=4927\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of chosenMask (94, 94, 72)\n",
      "(480, 4927)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 4927)\n",
      "new trained 4 way classifier accuracy=0.3520833333333333\n",
      "best 4way classifier accuracy =  0.3520833333333333\n",
      "bedbench_bedchair 0.5\n",
      "bedbench_bedtable 0.45\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.575\n",
      "bedchair_bedbench 0.6\n",
      "bedchair_bedtable 0.45\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.475\n",
      "bedtable_bedbench 0.6\n",
      "bedtable_bedchair 0.5\n",
      "bedtable_tablebench 0.575\n",
      "bedtable_tablechair 0.475\n",
      "benchchair_benchbed 0.6\n",
      "benchchair_benchtable 0.575\n",
      "benchchair_chairbed 0.5\n",
      "benchchair_chairtable 0.475\n",
      "benchtable_benchbed 0.6\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.45\n",
      "benchtable_tablechair 0.475\n",
      "chairtable_chairbed 0.5\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.45\n",
      "chairtable_tablebench 0.575\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4927) shape of mask (94, 94, 72)\n",
      "(80, 4927)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4927)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.28403150374256286\n",
      "C evidence for AC_clf when A is presented=-0.08419816188336389\n",
      "D evidence for CD_clf when A is presented=-0.1040101817607326\n",
      "C evidence for CD_clf when A is presented=0.1040101817607326\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.08419816188336389\n",
      "A evidence in AD_clf when A is presented=0.28403150374256286\n",
      "evidence_ceil=0.1841148328129634\n",
      "floor=0.1040101817607326, ceil=0.1841148328129634\n",
      "mu=0.144062507286848, sig=0.03401760279099321\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:30<12:17, 30.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 4927) shape of mask (94, 94, 72)\n",
      "(80, 4927)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4927)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.4142112244384277\n",
      "C evidence for AC_clf when A is presented=-3.4294846566069217\n",
      "D evidence for CD_clf when A is presented=0.2152135502794307\n",
      "C evidence for CD_clf when A is presented=-0.2152135502794307\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.4294846566069217\n",
      "A evidence in AD_clf when A is presented=3.4142112244384277\n",
      "evidence_ceil=3.4218479405226745\n",
      "floor=-0.2152135502794307, ceil=3.4218479405226745\n",
      "mu=1.6033171951216219, sig=1.5445309541371264\n",
      "np.sum(chosenMask)=3488\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "(480, 3488)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 3488)\n",
      "new trained 4 way classifier accuracy=0.325\n",
      "best 4way classifier accuracy =  0.325\n",
      "bedbench_bedchair 0.525\n",
      "bedbench_bedtable 0.55\n",
      "bedbench_benchchair 0.525\n",
      "bedbench_benchtable 0.675\n",
      "bedchair_bedbench 0.6\n",
      "bedchair_bedtable 0.55\n",
      "bedchair_chairbench 0.525\n",
      "bedchair_chairtable 0.5\n",
      "bedtable_bedbench 0.6\n",
      "bedtable_bedchair 0.525\n",
      "bedtable_tablebench 0.675\n",
      "bedtable_tablechair 0.5\n",
      "benchchair_benchbed 0.6\n",
      "benchchair_benchtable 0.675\n",
      "benchchair_chairbed 0.525\n",
      "benchchair_chairtable 0.5\n",
      "benchtable_benchbed 0.6\n",
      "benchtable_benchchair 0.525\n",
      "benchtable_tablebed 0.55\n",
      "benchtable_tablechair 0.5\n",
      "chairtable_chairbed 0.525\n",
      "chairtable_chairbench 0.525\n",
      "chairtable_tablebed 0.55\n",
      "chairtable_tablebench 0.675\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of mask (94, 94, 72)\n",
      "(80, 3488)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3488)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.051884448218457516\n",
      "C evidence for AC_clf when A is presented=-0.01705912876212199\n",
      "D evidence for CD_clf when A is presented=-0.0047471010805816725\n",
      "C evidence for CD_clf when A is presented=0.0047471010805816725\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.01705912876212199\n",
      "A evidence in AD_clf when A is presented=0.051884448218457516\n",
      "evidence_ceil=0.03447178849028972\n",
      "floor=0.0047471010805816725, ceil=0.03447178849028972\n",
      "mu=0.019609444785435696, sig=0.01262301996335487\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [00:58<11:07, 29.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 3488) shape of mask (94, 94, 72)\n",
      "(80, 3488)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3488)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.3465661747520037\n",
      "C evidence for AC_clf when A is presented=-3.3442462376564874\n",
      "D evidence for CD_clf when A is presented=-0.11352732455801277\n",
      "C evidence for CD_clf when A is presented=0.11352732455801277\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.3442462376564874\n",
      "A evidence in AD_clf when A is presented=3.3465661747520037\n",
      "evidence_ceil=3.3454062062042453\n",
      "floor=0.11352732455801277, ceil=3.3454062062042453\n",
      "mu=1.729466765381129, sig=1.372464277920092\n",
      "np.sum(chosenMask)=3140\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of chosenMask (94, 94, 72)\n",
      "(480, 3140)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 3140)\n",
      "new trained 4 way classifier accuracy=0.3583333333333334\n",
      "best 4way classifier accuracy =  0.3583333333333334\n",
      "bedbench_bedchair 0.525\n",
      "bedbench_bedtable 0.525\n",
      "bedbench_benchchair 0.6\n",
      "bedbench_benchtable 0.55\n",
      "bedchair_bedbench 0.6\n",
      "bedchair_bedtable 0.525\n",
      "bedchair_chairbench 0.6\n",
      "bedchair_chairtable 0.625\n",
      "bedtable_bedbench 0.6\n",
      "bedtable_bedchair 0.525\n",
      "bedtable_tablebench 0.55\n",
      "bedtable_tablechair 0.625\n",
      "benchchair_benchbed 0.6\n",
      "benchchair_benchtable 0.55\n",
      "benchchair_chairbed 0.525\n",
      "benchchair_chairtable 0.625\n",
      "benchtable_benchbed 0.6\n",
      "benchtable_benchchair 0.6\n",
      "benchtable_tablebed 0.525\n",
      "benchtable_tablechair 0.625\n",
      "chairtable_chairbed 0.525\n",
      "chairtable_chairbench 0.6\n",
      "chairtable_tablebed 0.525\n",
      "chairtable_tablebench 0.55\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3140) shape of mask (94, 94, 72)\n",
      "(80, 3140)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3140)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.008206036134410222\n",
      "C evidence for AC_clf when A is presented=0.05725995583293899\n",
      "D evidence for CD_clf when A is presented=-0.08732330754110029\n",
      "C evidence for CD_clf when A is presented=0.08732330754110029\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=-0.05725995583293899\n",
      "A evidence in AD_clf when A is presented=0.008206036134410222\n",
      "evidence_ceil=-0.024526959849264375\n",
      "floor=0.08732330754110029, ceil=-0.024526959849264375\n",
      "mu=0.03139817384591796, sig=-0.04749883955765443\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [01:26<10:28, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 3140) shape of mask (94, 94, 72)\n",
      "(80, 3140)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3140)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.259991779350149\n",
      "C evidence for AC_clf when A is presented=-3.297604477824239\n",
      "D evidence for CD_clf when A is presented=0.04883728537700199\n",
      "C evidence for CD_clf when A is presented=-0.04883728537700199\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.297604477824239\n",
      "A evidence in AD_clf when A is presented=3.259991779350149\n",
      "evidence_ceil=3.2787981285871943\n",
      "floor=-0.04883728537700199, ceil=3.2787981285871943\n",
      "mu=1.6149804216050963, sig=1.4131286792781537\n",
      "np.sum(chosenMask)=6267\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of chosenMask (94, 94, 72)\n",
      "(480, 6267)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 6267)\n",
      "new trained 4 way classifier accuracy=0.32083333333333336\n",
      "best 4way classifier accuracy =  0.32083333333333336\n",
      "bedbench_bedchair 0.4\n",
      "bedbench_bedtable 0.575\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.575\n",
      "bedchair_bedbench 0.6\n",
      "bedchair_bedtable 0.575\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.3\n",
      "bedtable_bedbench 0.6\n",
      "bedtable_bedchair 0.4\n",
      "bedtable_tablebench 0.575\n",
      "bedtable_tablechair 0.3\n",
      "benchchair_benchbed 0.6\n",
      "benchchair_benchtable 0.575\n",
      "benchchair_chairbed 0.4\n",
      "benchchair_chairtable 0.3\n",
      "benchtable_benchbed 0.6\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.575\n",
      "benchtable_tablechair 0.3\n",
      "chairtable_chairbed 0.4\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.575\n",
      "chairtable_tablebench 0.575\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 6267) shape of mask (94, 94, 72)\n",
      "(80, 6267)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 6267)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.19315217373157179\n",
      "C evidence for AC_clf when A is presented=-0.1360055950659129\n",
      "D evidence for CD_clf when A is presented=-0.02608689598450814\n",
      "C evidence for CD_clf when A is presented=0.02608689598450814\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.1360055950659129\n",
      "A evidence in AD_clf when A is presented=0.19315217373157179\n",
      "evidence_ceil=0.16457888439874235\n",
      "floor=0.02608689598450814, ceil=0.16457888439874235\n",
      "mu=0.09533289019162525, sig=0.058812633095903774\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [01:58<10:29, 29.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 6267) shape of mask (94, 94, 72)\n",
      "(80, 6267)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 6267)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.588141956515473\n",
      "C evidence for AC_clf when A is presented=-3.5736227349491125\n",
      "D evidence for CD_clf when A is presented=-0.07491391730443227\n",
      "C evidence for CD_clf when A is presented=0.07491391730443227\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.5736227349491125\n",
      "A evidence in AD_clf when A is presented=3.588141956515473\n",
      "evidence_ceil=3.580882345732293\n",
      "floor=0.07491391730443227, ceil=3.580882345732293\n",
      "mu=1.8278981315183627, sig=1.4888603823797606\n",
      "np.sum(chosenMask)=2759\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of chosenMask (94, 94, 72)\n",
      "(480, 2759)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 2759)\n",
      "new trained 4 way classifier accuracy=0.33958333333333335\n",
      "best 4way classifier accuracy =  0.33958333333333335\n",
      "bedbench_bedchair 0.7\n",
      "bedbench_bedtable 0.525\n",
      "bedbench_benchchair 0.675\n",
      "bedbench_benchtable 0.5\n",
      "bedchair_bedbench 0.6\n",
      "bedchair_bedtable 0.525\n",
      "bedchair_chairbench 0.675\n",
      "bedchair_chairtable 0.6\n",
      "bedtable_bedbench 0.6\n",
      "bedtable_bedchair 0.7\n",
      "bedtable_tablebench 0.5\n",
      "bedtable_tablechair 0.6\n",
      "benchchair_benchbed 0.6\n",
      "benchchair_benchtable 0.5\n",
      "benchchair_chairbed 0.7\n",
      "benchchair_chairtable 0.6\n",
      "benchtable_benchbed 0.6\n",
      "benchtable_benchchair 0.675\n",
      "benchtable_tablebed 0.525\n",
      "benchtable_tablechair 0.6\n",
      "chairtable_chairbed 0.7\n",
      "chairtable_chairbench 0.675\n",
      "chairtable_tablebed 0.525\n",
      "chairtable_tablebench 0.5\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 2759) shape of mask (94, 94, 72)\n",
      "(80, 2759)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 2759)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.30790850021531835\n",
      "C evidence for AC_clf when A is presented=-0.14028912971612328\n",
      "D evidence for CD_clf when A is presented=-0.14323473903859302\n",
      "C evidence for CD_clf when A is presented=0.14323473903859302\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.14028912971612328\n",
      "A evidence in AD_clf when A is presented=0.30790850021531835\n",
      "evidence_ceil=0.22409881496572087\n",
      "floor=0.14323473903859302, ceil=0.22409881496572087\n",
      "mu=0.18366677700215694, sig=0.034340103587195456\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [02:26<09:45, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 2759) shape of mask (94, 94, 72)\n",
      "(80, 2759)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 2759)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.2599693765886597\n",
      "C evidence for AC_clf when A is presented=-3.1934005684289697\n",
      "D evidence for CD_clf when A is presented=-0.12081135211297885\n",
      "C evidence for CD_clf when A is presented=0.12081135211297885\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.1934005684289697\n",
      "A evidence in AD_clf when A is presented=3.2599693765886597\n",
      "evidence_ceil=3.226684972508815\n",
      "floor=0.12081135211297885, ceil=3.226684972508815\n",
      "mu=1.673748162310897, sig=1.3189543147595701\n",
      "np.sum(chosenMask)=5493\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of chosenMask (94, 94, 72)\n",
      "(480, 5493)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 5493)\n",
      "new trained 4 way classifier accuracy=0.34791666666666665\n",
      "best 4way classifier accuracy =  0.34791666666666665\n",
      "bedbench_bedchair 0.575\n",
      "bedbench_bedtable 0.775\n",
      "bedbench_benchchair 0.625\n",
      "bedbench_benchtable 0.475\n",
      "bedchair_bedbench 0.55\n",
      "bedchair_bedtable 0.775\n",
      "bedchair_chairbench 0.625\n",
      "bedchair_chairtable 0.65\n",
      "bedtable_bedbench 0.55\n",
      "bedtable_bedchair 0.575\n",
      "bedtable_tablebench 0.475\n",
      "bedtable_tablechair 0.65\n",
      "benchchair_benchbed 0.55\n",
      "benchchair_benchtable 0.475\n",
      "benchchair_chairbed 0.575\n",
      "benchchair_chairtable 0.65\n",
      "benchtable_benchbed 0.55\n",
      "benchtable_benchchair 0.625\n",
      "benchtable_tablebed 0.775\n",
      "benchtable_tablechair 0.65\n",
      "chairtable_chairbed 0.575\n",
      "chairtable_chairbench 0.625\n",
      "chairtable_tablebed 0.775\n",
      "chairtable_tablebench 0.475\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 5493) shape of mask (94, 94, 72)\n",
      "(80, 5493)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 5493)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.3114454460692828\n",
      "C evidence for AC_clf when A is presented=-0.2612863547268568\n",
      "D evidence for CD_clf when A is presented=-0.12792851161918303\n",
      "C evidence for CD_clf when A is presented=0.12792851161918303\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.2612863547268568\n",
      "A evidence in AD_clf when A is presented=0.3114454460692828\n",
      "evidence_ceil=0.28636590039806975\n",
      "floor=0.12792851161918303, ceil=0.28636590039806975\n",
      "mu=0.2071472060086264, sig=0.06728273686890042\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [02:56<09:22, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 5493) shape of mask (94, 94, 72)\n",
      "(80, 5493)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 5493)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.543075407958623\n",
      "C evidence for AC_clf when A is presented=-3.553383892973131\n",
      "D evidence for CD_clf when A is presented=0.06377816928564801\n",
      "C evidence for CD_clf when A is presented=-0.06377816928564801\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.553383892973131\n",
      "A evidence in AD_clf when A is presented=3.543075407958623\n",
      "evidence_ceil=3.548229650465877\n",
      "floor=-0.06377816928564801, ceil=3.548229650465877\n",
      "mu=1.7422257405901145, sig=1.5338915490706322\n",
      "np.sum(chosenMask)=4369\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of chosenMask (94, 94, 72)\n",
      "(480, 4369)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 4369)\n",
      "new trained 4 way classifier accuracy=0.33125000000000004\n",
      "best 4way classifier accuracy =  0.33125000000000004\n",
      "bedbench_bedchair 0.6\n",
      "bedbench_bedtable 0.5\n",
      "bedbench_benchchair 0.425\n",
      "bedbench_benchtable 0.45\n",
      "bedchair_bedbench 0.65\n",
      "bedchair_bedtable 0.5\n",
      "bedchair_chairbench 0.425\n",
      "bedchair_chairtable 0.55\n",
      "bedtable_bedbench 0.65\n",
      "bedtable_bedchair 0.6\n",
      "bedtable_tablebench 0.45\n",
      "bedtable_tablechair 0.55\n",
      "benchchair_benchbed 0.65\n",
      "benchchair_benchtable 0.45\n",
      "benchchair_chairbed 0.6\n",
      "benchchair_chairtable 0.55\n",
      "benchtable_benchbed 0.65\n",
      "benchtable_benchchair 0.425\n",
      "benchtable_tablebed 0.5\n",
      "benchtable_tablechair 0.55\n",
      "chairtable_chairbed 0.6\n",
      "chairtable_chairbench 0.425\n",
      "chairtable_tablebed 0.5\n",
      "chairtable_tablebench 0.45\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4369) shape of mask (94, 94, 72)\n",
      "(80, 4369)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4369)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.29391009729191936\n",
      "C evidence for AC_clf when A is presented=0.054230111476429324\n",
      "D evidence for CD_clf when A is presented=-0.329794878788798\n",
      "C evidence for CD_clf when A is presented=0.329794878788798\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=-0.054230111476429324\n",
      "A evidence in AD_clf when A is presented=0.29391009729191936\n",
      "evidence_ceil=0.11983999290774498\n",
      "floor=0.329794878788798, ceil=0.11983999290774498\n",
      "mu=0.2248174358482715, sig=-0.08916038979151222\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [03:26<08:53, 29.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 4369) shape of mask (94, 94, 72)\n",
      "(80, 4369)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4369)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.5031227991513996\n",
      "C evidence for AC_clf when A is presented=-3.5185811665262348\n",
      "D evidence for CD_clf when A is presented=0.002963343113865857\n",
      "C evidence for CD_clf when A is presented=-0.002963343113865857\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.5185811665262348\n",
      "A evidence in AD_clf when A is presented=3.5031227991513996\n",
      "evidence_ceil=3.5108519828388176\n",
      "floor=-0.002963343113865857, ceil=3.5108519828388176\n",
      "mu=1.7539443198624758, sig=1.4921926813116544\n",
      "np.sum(chosenMask)=222\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of chosenMask (94, 94, 72)\n",
      "(480, 222)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 222)\n",
      "new trained 4 way classifier accuracy=0.3145833333333334\n",
      "best 4way classifier accuracy =  0.3145833333333334\n",
      "bedbench_bedchair 0.475\n",
      "bedbench_bedtable 0.475\n",
      "bedbench_benchchair 0.625\n",
      "bedbench_benchtable 0.475\n",
      "bedchair_bedbench 0.475\n",
      "bedchair_bedtable 0.475\n",
      "bedchair_chairbench 0.625\n",
      "bedchair_chairtable 0.425\n",
      "bedtable_bedbench 0.475\n",
      "bedtable_bedchair 0.475\n",
      "bedtable_tablebench 0.475\n",
      "bedtable_tablechair 0.425\n",
      "benchchair_benchbed 0.475\n",
      "benchchair_benchtable 0.475\n",
      "benchchair_chairbed 0.475\n",
      "benchchair_chairtable 0.425\n",
      "benchtable_benchbed 0.475\n",
      "benchtable_benchchair 0.625\n",
      "benchtable_tablebed 0.475\n",
      "benchtable_tablechair 0.425\n",
      "chairtable_chairbed 0.475\n",
      "chairtable_chairbench 0.625\n",
      "chairtable_tablebed 0.475\n",
      "chairtable_tablebench 0.475\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 222) shape of mask (94, 94, 72)\n",
      "(80, 222)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 222)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=0.19073727217774938\n",
      "C evidence for AC_clf when A is presented=0.11283785966706945\n",
      "D evidence for CD_clf when A is presented=0.2873623762795963\n",
      "C evidence for CD_clf when A is presented=-0.2873623762795963\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=-0.11283785966706945\n",
      "A evidence in AD_clf when A is presented=-0.19073727217774938\n",
      "evidence_ceil=-0.15178756592240938\n",
      "floor=-0.2873623762795963, ceil=-0.15178756592240938\n",
      "mu=-0.21957497110100285, sig=0.05757381109104252\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [03:53<08:08, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 222) shape of mask (94, 94, 72)\n",
      "(80, 222)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 222)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-2.1695180025672496\n",
      "C evidence for AC_clf when A is presented=-2.434692605959435\n",
      "D evidence for CD_clf when A is presented=-0.24812092083963688\n",
      "C evidence for CD_clf when A is presented=0.24812092083963688\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=2.434692605959435\n",
      "A evidence in AD_clf when A is presented=2.1695180025672496\n",
      "evidence_ceil=2.302105304263342\n",
      "floor=0.24812092083963688, ceil=2.302105304263342\n",
      "mu=1.2751131125514896, sig=0.8722542820722375\n",
      "np.sum(chosenMask)=4381\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of chosenMask (94, 94, 72)\n",
      "(480, 4381)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 4381)\n",
      "new trained 4 way classifier accuracy=0.33541666666666664\n",
      "best 4way classifier accuracy =  0.33541666666666664\n",
      "bedbench_bedchair 0.575\n",
      "bedbench_bedtable 0.775\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.625\n",
      "bedchair_bedbench 0.55\n",
      "bedchair_bedtable 0.775\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.675\n",
      "bedtable_bedbench 0.55\n",
      "bedtable_bedchair 0.575\n",
      "bedtable_tablebench 0.625\n",
      "bedtable_tablechair 0.675\n",
      "benchchair_benchbed 0.55\n",
      "benchchair_benchtable 0.625\n",
      "benchchair_chairbed 0.575\n",
      "benchchair_chairtable 0.675\n",
      "benchtable_benchbed 0.55\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.775\n",
      "benchtable_tablechair 0.675\n",
      "chairtable_chairbed 0.575\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.775\n",
      "chairtable_tablebench 0.625\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 4381) shape of mask (94, 94, 72)\n",
      "(80, 4381)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4381)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.07572211490965883\n",
      "C evidence for AC_clf when A is presented=-0.36251509153525197\n",
      "D evidence for CD_clf when A is presented=0.2106666303373797\n",
      "C evidence for CD_clf when A is presented=-0.2106666303373797\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.36251509153525197\n",
      "A evidence in AD_clf when A is presented=0.07572211490965883\n",
      "evidence_ceil=0.21911860322245538\n",
      "floor=-0.2106666303373797, ceil=0.21911860322245538\n",
      "mu=0.004225986442537841, sig=0.18251453777808524\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [04:22<07:42, 28.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 4381) shape of mask (94, 94, 72)\n",
      "(80, 4381)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 4381)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.4631522790147264\n",
      "C evidence for AC_clf when A is presented=-3.4720302292411005\n",
      "D evidence for CD_clf when A is presented=0.02020248048930326\n",
      "C evidence for CD_clf when A is presented=-0.02020248048930326\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.4720302292411005\n",
      "A evidence in AD_clf when A is presented=3.4631522790147264\n",
      "evidence_ceil=3.467591254127913\n",
      "floor=-0.02020248048930326, ceil=3.467591254127913\n",
      "mu=1.7236943868193049, sig=1.481142234846788\n",
      "np.sum(chosenMask)=2850\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of chosenMask (94, 94, 72)\n",
      "(480, 2850)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 2850)\n",
      "new trained 4 way classifier accuracy=0.32083333333333336\n",
      "best 4way classifier accuracy =  0.32083333333333336\n",
      "bedbench_bedchair 0.625\n",
      "bedbench_bedtable 0.525\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.5\n",
      "bedchair_bedbench 0.525\n",
      "bedchair_bedtable 0.525\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.55\n",
      "bedtable_bedbench 0.525\n",
      "bedtable_bedchair 0.625\n",
      "bedtable_tablebench 0.5\n",
      "bedtable_tablechair 0.55\n",
      "benchchair_benchbed 0.525\n",
      "benchchair_benchtable 0.5\n",
      "benchchair_chairbed 0.625\n",
      "benchchair_chairtable 0.55\n",
      "benchtable_benchbed 0.525\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.525\n",
      "benchtable_tablechair 0.55\n",
      "chairtable_chairbed 0.625\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.525\n",
      "chairtable_tablebench 0.5\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 2850) shape of mask (94, 94, 72)\n",
      "(80, 2850)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 2850)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.1302477689102912\n",
      "C evidence for AC_clf when A is presented=-0.16320747005887973\n",
      "D evidence for CD_clf when A is presented=0.1072611082128088\n",
      "C evidence for CD_clf when A is presented=-0.1072611082128088\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.16320747005887973\n",
      "A evidence in AD_clf when A is presented=0.1302477689102912\n",
      "evidence_ceil=0.14672761948458551\n",
      "floor=-0.1072611082128088, ceil=0.14672761948458551\n",
      "mu=0.019733255635888354, sig=0.10785999987149411\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [04:50<07:06, 28.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 2850) shape of mask (94, 94, 72)\n",
      "(80, 2850)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 2850)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.2855757389112563\n",
      "C evidence for AC_clf when A is presented=-3.248397463619418\n",
      "D evidence for CD_clf when A is presented=-0.00024273732490211753\n",
      "C evidence for CD_clf when A is presented=0.00024273732490211753\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.248397463619418\n",
      "A evidence in AD_clf when A is presented=3.2855757389112563\n",
      "evidence_ceil=3.2669866012653372\n",
      "floor=0.00024273732490211753, ceil=3.2669866012653372\n",
      "mu=1.6336146692951197, sig=1.3872701987176979\n",
      "np.sum(chosenMask)=699\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of chosenMask (94, 94, 72)\n",
      "(480, 699)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 699)\n",
      "new trained 4 way classifier accuracy=0.3520833333333333\n",
      "best 4way classifier accuracy =  0.3520833333333333\n",
      "bedbench_bedchair 0.6\n",
      "bedbench_bedtable 0.675\n",
      "bedbench_benchchair 0.5\n",
      "bedbench_benchtable 0.625\n",
      "bedchair_bedbench 0.675\n",
      "bedchair_bedtable 0.675\n",
      "bedchair_chairbench 0.5\n",
      "bedchair_chairtable 0.65\n",
      "bedtable_bedbench 0.675\n",
      "bedtable_bedchair 0.6\n",
      "bedtable_tablebench 0.625\n",
      "bedtable_tablechair 0.65\n",
      "benchchair_benchbed 0.675\n",
      "benchchair_benchtable 0.625\n",
      "benchchair_chairbed 0.6\n",
      "benchchair_chairtable 0.65\n",
      "benchtable_benchbed 0.675\n",
      "benchtable_benchchair 0.5\n",
      "benchtable_tablebed 0.675\n",
      "benchtable_tablechair 0.65\n",
      "chairtable_chairbed 0.6\n",
      "chairtable_chairbench 0.5\n",
      "chairtable_tablebed 0.675\n",
      "chairtable_tablebench 0.625\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 699) shape of mask (94, 94, 72)\n",
      "(80, 699)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 699)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.35059961532186645\n",
      "C evidence for AC_clf when A is presented=-0.7236128340089738\n",
      "D evidence for CD_clf when A is presented=0.29176675572948063\n",
      "C evidence for CD_clf when A is presented=-0.29176675572948063\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.7236128340089738\n",
      "A evidence in AD_clf when A is presented=0.35059961532186645\n",
      "evidence_ceil=0.53710622466542\n",
      "floor=-0.29176675572948063, ceil=0.53710622466542\n",
      "mu=0.1226697344679697, sig=0.35199294224346045\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [05:17<06:32, 28.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 699) shape of mask (94, 94, 72)\n",
      "(80, 699)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 699)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-2.5675797770337043\n",
      "C evidence for AC_clf when A is presented=-2.6675965332938683\n",
      "D evidence for CD_clf when A is presented=0.17864049922980088\n",
      "C evidence for CD_clf when A is presented=-0.17864049922980088\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=2.6675965332938683\n",
      "A evidence in AD_clf when A is presented=2.5675797770337043\n",
      "evidence_ceil=2.6175881551637867\n",
      "floor=-0.17864049922980088, ceil=2.6175881551637867\n",
      "mu=1.219473827966993, sig=1.1874590854397773\n",
      "np.sum(chosenMask)=6219\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of chosenMask (94, 94, 72)\n",
      "(480, 6219)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 6219)\n",
      "new trained 4 way classifier accuracy=0.3333333333333333\n",
      "best 4way classifier accuracy =  0.3333333333333333\n",
      "bedbench_bedchair 0.6\n",
      "bedbench_bedtable 0.7\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.5\n",
      "bedchair_bedbench 0.525\n",
      "bedchair_bedtable 0.7\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.525\n",
      "bedtable_bedbench 0.525\n",
      "bedtable_bedchair 0.6\n",
      "bedtable_tablebench 0.5\n",
      "bedtable_tablechair 0.525\n",
      "benchchair_benchbed 0.525\n",
      "benchchair_benchtable 0.5\n",
      "benchchair_chairbed 0.6\n",
      "benchchair_chairtable 0.525\n",
      "benchtable_benchbed 0.525\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.7\n",
      "benchtable_tablechair 0.525\n",
      "chairtable_chairbed 0.6\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.7\n",
      "chairtable_tablebench 0.5\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 6219) shape of mask (94, 94, 72)\n",
      "(80, 6219)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 6219)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.24450883571925597\n",
      "C evidence for AC_clf when A is presented=-0.5563857865354273\n",
      "D evidence for CD_clf when A is presented=0.39001446762600817\n",
      "C evidence for CD_clf when A is presented=-0.39001446762600817\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.5563857865354273\n",
      "A evidence in AD_clf when A is presented=0.24450883571925597\n",
      "evidence_ceil=0.4004473111273416\n",
      "floor=-0.39001446762600817, ceil=0.4004473111273416\n",
      "mu=0.005216421750666722, sig=0.3356810679265117\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [05:49<06:19, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 6219) shape of mask (94, 94, 72)\n",
      "(80, 6219)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 6219)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.593611236177979\n",
      "C evidence for AC_clf when A is presented=-3.6061335915896913\n",
      "D evidence for CD_clf when A is presented=0.09491240827298392\n",
      "C evidence for CD_clf when A is presented=-0.09491240827298392\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.6061335915896913\n",
      "A evidence in AD_clf when A is presented=3.593611236177979\n",
      "evidence_ceil=3.5998724138838347\n",
      "floor=-0.09491240827298392, ceil=3.5998724138838347\n",
      "mu=1.7524800028054255, sig=1.569044004652972\n",
      "np.sum(chosenMask)=1976\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of chosenMask (94, 94, 72)\n",
      "(480, 1976)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 1976)\n",
      "new trained 4 way classifier accuracy=0.32708333333333334\n",
      "best 4way classifier accuracy =  0.32708333333333334\n",
      "bedbench_bedchair 0.7\n",
      "bedbench_bedtable 0.6\n",
      "bedbench_benchchair 0.55\n",
      "bedbench_benchtable 0.525\n",
      "bedchair_bedbench 0.575\n",
      "bedchair_bedtable 0.6\n",
      "bedchair_chairbench 0.55\n",
      "bedchair_chairtable 0.6\n",
      "bedtable_bedbench 0.575\n",
      "bedtable_bedchair 0.7\n",
      "bedtable_tablebench 0.525\n",
      "bedtable_tablechair 0.6\n",
      "benchchair_benchbed 0.575\n",
      "benchchair_benchtable 0.525\n",
      "benchchair_chairbed 0.7\n",
      "benchchair_chairtable 0.6\n",
      "benchtable_benchbed 0.575\n",
      "benchtable_benchchair 0.55\n",
      "benchtable_tablebed 0.6\n",
      "benchtable_tablechair 0.6\n",
      "chairtable_chairbed 0.7\n",
      "chairtable_chairbench 0.55\n",
      "chairtable_tablebed 0.6\n",
      "chairtable_tablebench 0.525\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1976) shape of mask (94, 94, 72)\n",
      "(80, 1976)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1976)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.25053023136977015\n",
      "C evidence for AC_clf when A is presented=-0.3147122594493354\n",
      "D evidence for CD_clf when A is presented=0.1281795099945023\n",
      "C evidence for CD_clf when A is presented=-0.1281795099945023\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.3147122594493354\n",
      "A evidence in AD_clf when A is presented=0.25053023136977015\n",
      "evidence_ceil=0.2826212454095528\n",
      "floor=-0.1281795099945023, ceil=0.2826212454095528\n",
      "mu=0.07722086770752525, sig=0.174452503568904\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [06:17<05:46, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 1976) shape of mask (94, 94, 72)\n",
      "(80, 1976)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1976)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.194609623173621\n",
      "C evidence for AC_clf when A is presented=-3.1113427157454603\n",
      "D evidence for CD_clf when A is presented=-0.36390915947619307\n",
      "C evidence for CD_clf when A is presented=0.36390915947619307\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.1113427157454603\n",
      "A evidence in AD_clf when A is presented=3.194609623173621\n",
      "evidence_ceil=3.15297616945954\n",
      "floor=0.36390915947619307, ceil=3.15297616945954\n",
      "mu=1.7584426644678666, sig=1.1844177891894627\n",
      "np.sum(chosenMask)=1410\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of chosenMask (94, 94, 72)\n",
      "(480, 1410)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 1410)\n",
      "new trained 4 way classifier accuracy=0.34375\n",
      "best 4way classifier accuracy =  0.34375\n",
      "bedbench_bedchair 0.525\n",
      "bedbench_bedtable 0.55\n",
      "bedbench_benchchair 0.55\n",
      "bedbench_benchtable 0.45\n",
      "bedchair_bedbench 0.5\n",
      "bedchair_bedtable 0.55\n",
      "bedchair_chairbench 0.55\n",
      "bedchair_chairtable 0.625\n",
      "bedtable_bedbench 0.5\n",
      "bedtable_bedchair 0.525\n",
      "bedtable_tablebench 0.45\n",
      "bedtable_tablechair 0.625\n",
      "benchchair_benchbed 0.5\n",
      "benchchair_benchtable 0.45\n",
      "benchchair_chairbed 0.525\n",
      "benchchair_chairtable 0.625\n",
      "benchtable_benchbed 0.5\n",
      "benchtable_benchchair 0.55\n",
      "benchtable_tablebed 0.55\n",
      "benchtable_tablechair 0.625\n",
      "chairtable_chairbed 0.525\n",
      "chairtable_chairbench 0.55\n",
      "chairtable_tablebed 0.55\n",
      "chairtable_tablebench 0.45\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1410) shape of mask (94, 94, 72)\n",
      "(80, 1410)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1410)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.19139014915788372\n",
      "C evidence for AC_clf when A is presented=-0.33028578353097854\n",
      "D evidence for CD_clf when A is presented=0.1287003382515664\n",
      "C evidence for CD_clf when A is presented=-0.1287003382515664\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=0.33028578353097854\n",
      "A evidence in AD_clf when A is presented=0.19139014915788372\n",
      "evidence_ceil=0.26083796634443124\n",
      "floor=-0.1287003382515664, ceil=0.26083796634443124\n",
      "mu=0.06606881404643242, sig=0.1654230952080846\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [06:44<05:12, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 1410) shape of mask (94, 94, 72)\n",
      "(80, 1410)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1410)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-2.992943599027134\n",
      "C evidence for AC_clf when A is presented=-2.987853557605717\n",
      "D evidence for CD_clf when A is presented=0.18610664294492832\n",
      "C evidence for CD_clf when A is presented=-0.18610664294492832\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=2.987853557605717\n",
      "A evidence in AD_clf when A is presented=2.992943599027134\n",
      "evidence_ceil=2.9903985783164253\n",
      "floor=-0.18610664294492832, ceil=2.9903985783164253\n",
      "mu=1.4021459676857484, sig=1.3489490492871385\n",
      "np.sum(chosenMask)=1879\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of chosenMask (94, 94, 72)\n",
      "(480, 1879)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 1879)\n",
      "new trained 4 way classifier accuracy=0.34791666666666665\n",
      "best 4way classifier accuracy =  0.34791666666666665\n",
      "bedbench_bedchair 0.525\n",
      "bedbench_bedtable 0.525\n",
      "bedbench_benchchair 0.475\n",
      "bedbench_benchtable 0.625\n",
      "bedchair_bedbench 0.65\n",
      "bedchair_bedtable 0.525\n",
      "bedchair_chairbench 0.475\n",
      "bedchair_chairtable 0.575\n",
      "bedtable_bedbench 0.65\n",
      "bedtable_bedchair 0.525\n",
      "bedtable_tablebench 0.625\n",
      "bedtable_tablechair 0.575\n",
      "benchchair_benchbed 0.65\n",
      "benchchair_benchtable 0.625\n",
      "benchchair_chairbed 0.525\n",
      "benchchair_chairtable 0.575\n",
      "benchtable_benchbed 0.65\n",
      "benchtable_benchchair 0.475\n",
      "benchtable_tablebed 0.525\n",
      "benchtable_tablechair 0.575\n",
      "chairtable_chairbed 0.525\n",
      "chairtable_chairbench 0.475\n",
      "chairtable_tablebed 0.525\n",
      "chairtable_tablebench 0.625\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 1879) shape of mask (94, 94, 72)\n",
      "(80, 1879)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1879)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.41405392320060985\n",
      "C evidence for AC_clf when A is presented=0.18433158819669515\n",
      "D evidence for CD_clf when A is presented=-0.5271831842105206\n",
      "C evidence for CD_clf when A is presented=0.5271831842105206\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=-0.18433158819669515\n",
      "A evidence in AD_clf when A is presented=0.41405392320060985\n",
      "evidence_ceil=0.11486116750195734\n",
      "floor=0.5271831842105206, ceil=0.11486116750195734\n",
      "mu=0.32102217585623893, sig=-0.17509852926302158\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [07:12<04:42, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (80, 1879) shape of mask (94, 94, 72)\n",
      "(80, 1879)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 1879)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-3.1123495233518197\n",
      "C evidence for AC_clf when A is presented=-3.203382580086238\n",
      "D evidence for CD_clf when A is presented=0.17406875220042564\n",
      "C evidence for CD_clf when A is presented=-0.17406875220042564\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=3.203382580086238\n",
      "A evidence in AD_clf when A is presented=3.1123495233518197\n",
      "evidence_ceil=3.157866051719029\n",
      "floor=-0.17406875220042564, ceil=3.157866051719029\n",
      "mu=1.4918986497593016, sig=1.4149544776284417\n",
      "np.sum(chosenMask)=3429\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of chosenMask (94, 94, 72)\n",
      "(480, 3429)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 3429)\n",
      "new trained 4 way classifier accuracy=0.33749999999999997\n",
      "best 4way classifier accuracy =  0.33749999999999997\n",
      "bedbench_bedchair 0.5\n",
      "bedbench_bedtable 0.525\n",
      "bedbench_benchchair 0.575\n",
      "bedbench_benchtable 0.45\n",
      "bedchair_bedbench 0.625\n",
      "bedchair_bedtable 0.525\n",
      "bedchair_chairbench 0.575\n",
      "bedchair_chairtable 0.525\n",
      "bedtable_bedbench 0.625\n",
      "bedtable_bedchair 0.5\n",
      "bedtable_tablebench 0.45\n",
      "bedtable_tablechair 0.525\n",
      "benchchair_benchbed 0.625\n",
      "benchchair_benchtable 0.45\n",
      "benchchair_chairbed 0.5\n",
      "benchchair_chairtable 0.525\n",
      "benchtable_benchbed 0.625\n",
      "benchtable_benchchair 0.575\n",
      "benchtable_tablebed 0.525\n",
      "benchtable_tablechair 0.525\n",
      "chairtable_chairbed 0.5\n",
      "chairtable_chairbench 0.575\n",
      "chairtable_tablebed 0.525\n",
      "chairtable_tablebench 0.45\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3429) shape of mask (94, 94, 72)\n",
      "(80, 3429)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3429)\n",
      "floor\n",
      "D evidence for AD_clf when A is presented=-0.2633176850018941\n",
      "C evidence for AC_clf when A is presented=0.006569318340045377\n",
      "D evidence for CD_clf when A is presented=-0.38738580877994844\n",
      "C evidence for CD_clf when A is presented=0.38738580877994844\n",
      "ceil\n",
      "A evidence in AC_clf when A is presented=-0.006569318340045377\n",
      "A evidence in AD_clf when A is presented=0.2633176850018941\n",
      "evidence_ceil=0.12837418333092437\n",
      "floor=0.38738580877994844, ceil=0.12837418333092437\n",
      "mu=0.25787999605543643, sig=-0.10999304630925091\n",
      "1--LENGTH OF TR: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [07:39<05:06, 30.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-990603cbf34a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-990603cbf34a>\u001b[0m in \u001b[0;36msubLoop\u001b[0;34m(subject)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0mfloor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorphingTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"store testing run\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0mfloor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorphingTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"store training run\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-990603cbf34a>\u001b[0m in \u001b[0;36mmorphingTarget\u001b[0;34m(subject, testRun)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0mrunIm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis4d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0maffine_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunIm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0mrunImDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunIm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;31m# Use the TR numbers to select the correct features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/nibabel/dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;31m# For array proxies, will attempt to confine data array to dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# during scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mScaled\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \"\"\"\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslicer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m_get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mscl_inter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscl_inter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# Read array and upcast as necessary for big slopes, intercepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscl_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpromote_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m_get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    335\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             return fileslice(fileobj,\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "这个code的目的是用neurosketch 的数据来检测现在在realtime data里面发现的issue：也就是ceiling有时候竟然比floor更小\n",
    "这个code的运行逻辑是\n",
    "用neurosketch前五个run训练2 way classifiers，然后用最后一个run来计算ceiling和floor的值，看是否合理\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "purpose:\n",
    "    find the best performed mask from the result of aggregate_greedy.py and save as chosenMask\n",
    "    train all possible pairs of 2way classifiers and save for evidence calculation\n",
    "    load saved classifiers and calculate different forms of evidence\n",
    "steps:\n",
    "    load the result of aggregate_greedy.py\n",
    "    display the result of aggregate_greedy.py\n",
    "    find the best performed ROI for each subject and display the accuracy of each subject, save the best performed ROI as chosenMask\n",
    "    load the functional and behavior data and choseMask and train all possible pairs of 2way classifiers\n",
    "    calculate the evidence floor and ceil for each subject and display different forms of evidences.\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "load the result of aggregate_greedy.py\n",
    "'''\n",
    "# To visualize the greedy result starting for 31 ROIs, in total 25 subjects.\n",
    "import os\n",
    "os.chdir(\"/gpfs/milgram/project/turk-browne/projects/rtTest/kp_scratch/\")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle5 as pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "print(f\"conda env={os.environ['CONDA_DEFAULT_ENV']}\") \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools\n",
    "import pickle\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "workingDir=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "roiloc=\"schaefer2018\"\n",
    "dataSource=\"neurosketch\"\n",
    "subjects_correctly_aligned=['1206161','0119173','1206162','1130161','1206163','0120171','0111171','1202161','0125172','0110172','0123173','0120173','0110171','0119172','0124171','0123171','1203161','0118172','0118171','0112171','1207162','0117171','0119174','0112173','0112172']\n",
    "subjects=subjects_correctly_aligned\n",
    "N=25\n",
    "workingPath=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "GreedyBestAcc=np.zeros((len(subjects),N+1))\n",
    "GreedyBestAcc[GreedyBestAcc==0]=None\n",
    "GreedyBestAcc={}\n",
    "numberOfROIs={}\n",
    "for ii,subject in enumerate(subjects):\n",
    "    # try:\n",
    "    #     GreedyBestAcc[ii,N]=np.load(workingPath+\"./{}/{}/output/uniMaskRanktag2_top{}.npy\".format(roiloc, subject, N))\n",
    "    # except:\n",
    "    #     pass\n",
    "    t=np.load(workingPath+\"./{}/{}/output/uniMaskRanktag2_top{}.npy\".format(roiloc, subject, N))\n",
    "    GreedyBestAcc[subject]=[np.float(t)]\n",
    "    numberOfROIs[subject]=[N]\n",
    "    # for len_topN_1 in range(N-1,0,-1):\n",
    "    for len_topN in range(1,N):\n",
    "        # Wait(f\"./tmp/{subject}_{N}_{roiloc}_{dataSource}_{len_topN_1}.pkl\")\n",
    "        try:\n",
    "            # {当前的被试}_{greedy开始的ROI数目，也就是25}_{mask的种类schaefer2018}_{数据来源neurosketch}_{当前的 megaROI 包含有的数目}\n",
    "            di = load_obj(f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len_topN}\")\n",
    "            GreedyBestAcc[subject].append(np.float(di['bestAcc']))\n",
    "            numberOfROIs[subject].append(len_topN)\n",
    "            # GreedyBestAcc[ii,len_topN] = di['bestAcc']\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# '''\n",
    "# to load the imtermediate results from greedy code to examine the system\n",
    "# '''\n",
    "# def wait(tmpFile):\n",
    "#     while not os.path.exists(tmpFile+'_result.npy'):\n",
    "#         time.sleep(5)\n",
    "#         print(f\"waiting for {tmpFile}_result.npy\\n\")\n",
    "#     return np.load(tmpFile+'_result.npy')\n",
    "\n",
    "# subject= '0119173' #sys.argv[1]\n",
    "# sub_id = [i for i,x in enumerate(subjects) if x == subject][0]\n",
    "# intermediate_result=np.zeros((N+1,N+1))\n",
    "# # 应该有多少？25个24ROI，2个1ROI，24个\n",
    "# for i in range(N,1,-1):\n",
    "#     for j in range(i):\n",
    "#         tmpFile=f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{i}_{j}\"\n",
    "#         sl_result=wait(tmpFile)\n",
    "#         intermediate_result[i,j]=sl_result\n",
    "\n",
    "# # _=plt.imshow(intermediate_result)\n",
    "# #最后一行是25个24ROI，第2行是2个1ROI\n",
    "\n",
    "'''\n",
    "display the result of aggregate_greedy.py\n",
    "'''\n",
    "# GreedyBestAcc=GreedyBestAcc.T\n",
    "# plt.imshow(GreedyBestAcc)\n",
    "# _=plt.figure()\n",
    "# for i in range(GreedyBestAcc.shape[0]):\n",
    "#     plt.scatter([i]*GreedyBestAcc.shape[1],GreedyBestAcc[i,:],c='g',s=2)\n",
    "# plt.plot(np.arange(GreedyBestAcc.shape[0]),np.nanmean(GreedyBestAcc,axis=1))\n",
    "# # plt.ylim([0.19,0.36])\n",
    "# # plt.xlabel(\"number of ROIs\")\n",
    "# # plt.ylabel(\"accuracy\")\n",
    "# _=plt.figure()\n",
    "# for j in range(GreedyBestAcc.shape[1]):\n",
    "#     plt.plot(GreedyBestAcc[:,j])\n",
    "\n",
    "\n",
    "# GreedyBestAcc=GreedyBestAcc.T\n",
    "# _=plt.figure()\n",
    "# plt.imshow(GreedyBestAcc)\n",
    "\n",
    "'''\n",
    "find the best performed ROI for each subject and display the accuracy of each subject, save the best performed ROI as chosenMask\n",
    "'''\n",
    "#find best ID for each subject\n",
    "bestID={}\n",
    "for ii,subject in enumerate(subjects):\n",
    "    t=GreedyBestAcc[subject]\n",
    "    bestID[subject] = numberOfROIs[subject][np.where(t==np.nanmax(t))[0][0]] #bestID 指的是每一个subject对应的最好的megaROI包含的ROI的数目\n",
    "chosenMask={}\n",
    "for subject in bestID:\n",
    "    # best ID  \n",
    "    # {当前的被试}_{greedy开始的ROI数目，也就是25}_{mask的种类schaefer2018}_{数据来源neurosketch}_{最好的megaROI 包含有的数目}\n",
    "    di = load_obj(f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{bestID[subject]}\")\n",
    "    chosenMask[subject] = di['bestROIs']\n",
    "\n",
    "def getMask(topN, subject):\n",
    "    workingDir=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "    for pn, parc in enumerate(topN):\n",
    "        _mask = nib.load(workingDir+\"/{}/{}/{}\".format(roiloc, subject, parc))\n",
    "        aff = _mask.affine\n",
    "        _mask = _mask.get_data()\n",
    "        _mask = _mask.astype(int)\n",
    "        # say some things about the mask.\n",
    "        mask = _mask if pn == 0 else mask + _mask\n",
    "        mask[mask>0] = 1\n",
    "    return mask\n",
    "\n",
    "for sub in chosenMask:\n",
    "    mask=getMask(chosenMask[sub], sub)\n",
    "    # if not os.path.exists(f\"{workingDir}/{roiloc}/{sub}/chosenMask.npy\"):\n",
    "    np.save(f\"{workingDir}/{roiloc}/{sub}/chosenMask\",mask)\n",
    "    \n",
    "\n",
    "from scipy.stats import zscore\n",
    "def normalize(X):\n",
    "    _X=X.copy()\n",
    "    _X = zscore(_X, axis=0)\n",
    "    _X[np.isnan(_X)]=0\n",
    "    return _X\n",
    "\n",
    "def mkdir(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "\n",
    "'''\n",
    "load the functional and behavior data and choseMask and train all possible pairs of 2way classifiers\n",
    "''' \n",
    "def minimalClass(subject):\n",
    "    '''\n",
    "    purpose: \n",
    "        train offline models\n",
    "\n",
    "    steps:\n",
    "        load preprocessed and aligned behavior and brain data \n",
    "        select data with the wanted pattern like AB AC AD BC BD CD \n",
    "        train correspondng classifier and save the classifier performance and the classifiers themselves.\n",
    "\n",
    "    '''\n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import sklearn\n",
    "    import joblib\n",
    "    import nibabel as nib\n",
    "    import itertools\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    def gaussian(x, mu, sig):\n",
    "        # mu and sig is determined before each neurofeedback session using 2 recognition runs.\n",
    "        return round(1+18*(1 - np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))))) # map from (0,1) -> [1,19]\n",
    "\n",
    "    def jitter(size,const=0):\n",
    "        jit = np.random.normal(0+const, 0.05, size)\n",
    "        X = np.zeros((size))\n",
    "        X = X + jit\n",
    "        return X\n",
    "\n",
    "    def other(target):\n",
    "        other_objs = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in target]\n",
    "        return other_objs\n",
    "\n",
    "    def red_vox(n_vox, prop=0.1):\n",
    "        return int(np.ceil(n_vox * prop))\n",
    "\n",
    "    def get_inds(X, Y, pair, testRun=None):\n",
    "\n",
    "        inds = {}\n",
    "\n",
    "        # return relative indices\n",
    "        if testRun:\n",
    "            trainIX = Y.index[(Y['label'].isin(pair)) & (Y['run_num'] != int(testRun))]\n",
    "        else:\n",
    "            trainIX = Y.index[(Y['label'].isin(pair))]\n",
    "\n",
    "        # pull training and test data\n",
    "        trainX = X[trainIX]\n",
    "        trainY = Y.iloc[trainIX].label\n",
    "\n",
    "        # Main classifier on 5 runs, testing on 6th\n",
    "        clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                multi_class='multinomial').fit(trainX, trainY)\n",
    "        B = clf.coef_[0]  # pull betas\n",
    "\n",
    "        # retrieve only the first object, then only the second object\n",
    "        if testRun:\n",
    "            obj1IX = Y.index[(Y['label'] == pair[0]) & (Y['run_num'] != int(testRun))]\n",
    "            obj2IX = Y.index[(Y['label'] == pair[1]) & (Y['run_num'] != int(testRun))]\n",
    "        else:\n",
    "            obj1IX = Y.index[(Y['label'] == pair[0])]\n",
    "            obj2IX = Y.index[(Y['label'] == pair[1])]\n",
    "\n",
    "        # Get the average of the first object, then the second object\n",
    "        obj1X = np.mean(X[obj1IX], 0)\n",
    "        obj2X = np.mean(X[obj2IX], 0)\n",
    "\n",
    "        # Build the importance map\n",
    "        mult1X = obj1X * B\n",
    "        mult2X = obj2X * B\n",
    "\n",
    "        # Sort these so that they are from least to most important for a given category.\n",
    "        sortmult1X = mult1X.argsort()[::-1]\n",
    "        sortmult2X = mult2X.argsort()\n",
    "\n",
    "        # add to a dictionary for later use\n",
    "        inds[clf.classes_[0]] = sortmult1X\n",
    "        inds[clf.classes_[1]] = sortmult2X\n",
    "\n",
    "        return inds\n",
    "\n",
    "    if 'milgram' in os.getcwd():\n",
    "        main_dir='/gpfs/milgram/project/turk-browne/projects/rtTest/'\n",
    "    else:\n",
    "        main_dir='/Users/kailong/Desktop/rtTest'\n",
    "\n",
    "    working_dir=main_dir\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    objects = ['bed', 'bench', 'chair', 'table']\n",
    "\n",
    "\n",
    "    if dataSource == \"neurosketch\":\n",
    "        funcdata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/realtime_preprocessed/{sub}_neurosketch_recognition_run_{run}.nii.gz\"\n",
    "        metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "        anat = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/{sub}_neurosketch_anat_mprage_brain.nii.gz\"\n",
    "    elif dataSource == \"realtime\":\n",
    "        funcdata = \"/gpfs/milgram/project/turk-browne/projects/rtcloud_kp/subjects/{sub}/ses{ses}_recognition/run0{run}/nifti/{sub}_functional.nii.gz\"\n",
    "        metadata = \"/gpfs/milgram/project/turk-browne/projects/rtcloud_kp/subjects/{sub}/ses{ses}_recognition/run0{run}/{sub}_0{run}_preprocessed_behavData.csv\"\n",
    "        anat = \"$TO_BE_FILLED\"\n",
    "    else:\n",
    "        funcdata = \"/gpfs/milgram/project/turk-browne/projects/rtTest/searchout/feat/{sub}_pre.nii.gz\"\n",
    "        metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "        anat = \"$TO_BE_FILLED\"\n",
    "\n",
    "    # print('mask dimensions: {}'. format(mask.shape))\n",
    "    # print('number of voxels in mask: {}'.format(np.sum(mask)))\n",
    "    phasedict = dict(zip([1,2,3,4,5,6],[\"12\", \"12\", \"34\", \"34\", \"56\", \"56\"]))\n",
    "    imcodeDict={\"A\": \"bed\", \"B\": \"Chair\", \"C\": \"table\", \"D\": \"bench\"}\n",
    "    chosenMask = np.load(f\"/gpfs/milgram/project/turk-browne/projects/rtTest/schaefer2018/{subject}/chosenMask.npy\")\n",
    "    print(f\"np.sum(chosenMask)={np.sum(chosenMask)}\")\n",
    "    # Compile preprocessed data and corresponding indices\n",
    "    metas = []\n",
    "    for run in range(1, 7):\n",
    "        print(run, end='--')\n",
    "        # retrieve from the dictionary which phase it is, assign the session\n",
    "        phase = phasedict[run]\n",
    "        \n",
    "        # Build the path for the preprocessed functional data\n",
    "        this4d = funcdata.format(run=run, phase=phase, sub=subject)\n",
    "        \n",
    "        # Read in the metadata, and reduce it to only the TR values from this run, add to a list\n",
    "        thismeta = pd.read_csv(metadata.format(run=run, phase=phase, sub=subject))\n",
    "        if dataSource == \"neurosketch\":\n",
    "            _run = 1 if run % 2 == 0 else 2\n",
    "        else:\n",
    "            _run = run\n",
    "        thismeta = thismeta[thismeta['run_num'] == int(_run)]\n",
    "        \n",
    "        if dataSource == \"realtime\":\n",
    "            TR_num = list(thismeta.TR.astype(int))\n",
    "            labels = list(thismeta.Item)\n",
    "            labels = [imcodeDict[label] for label in labels]\n",
    "        else:\n",
    "            TR_num = list(thismeta.TR_num.astype(int))\n",
    "            labels = list(thismeta.label)\n",
    "        \n",
    "        print(\"LENGTH OF TR: {}\".format(len(TR_num)))\n",
    "        # Load the functional data\n",
    "        runIm = nib.load(this4d)\n",
    "        affine_mat = runIm.affine\n",
    "        runImDat = runIm.get_fdata()\n",
    "        \n",
    "        # Use the TR numbers to select the correct features\n",
    "        features = [runImDat[:,:,:,n+3] for n in TR_num] # here shape is from (94, 94, 72, 240) to (80, 94, 94, 72)\n",
    "        features = np.array(features)\n",
    "        features = features[:, chosenMask==1]\n",
    "        print(\"shape of features\", features.shape, \"shape of chosenMask\", chosenMask.shape)\n",
    "        features = normalize(features)\n",
    "        # features = np.expand_dims(features, 0)\n",
    "        \n",
    "        # Append both so we can use it later\n",
    "        # metas.append(labels)\n",
    "        # metas['label']\n",
    "\n",
    "        t=pd.DataFrame()\n",
    "        t['label']=labels\n",
    "        t[\"run_num\"]=run\n",
    "        behav_data=t if run==1 else pd.concat([behav_data,t])\n",
    "        \n",
    "        runs = features if run == 1 else np.concatenate((runs, features))\n",
    "\n",
    "    dimsize = runIm.header.get_zooms()\n",
    "    brain_data = runs\n",
    "    print(brain_data.shape)\n",
    "    print(behav_data.shape)\n",
    "    FEAT=brain_data\n",
    "    print(f\"FEAT.shape={FEAT.shape}\")\n",
    "    META=behav_data\n",
    "\n",
    "    def Class(brain_data,behav_data):\n",
    "        accs = []\n",
    "        for run in range(1,7):\n",
    "            trainIX = behav_data['run_num']!=int(run)\n",
    "            testIX = behav_data['run_num']==int(run)\n",
    "\n",
    "            trainX =  brain_data[trainIX]\n",
    "            trainY =  behav_data.iloc[np.asarray(trainIX)].label\n",
    "\n",
    "            testX =  brain_data[testIX]\n",
    "            testY =  behav_data.iloc[np.asarray(testIX)].label\n",
    "\n",
    "            clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                    multi_class='multinomial').fit(trainX, trainY)\n",
    "\n",
    "            # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "            acc = clf.score(testX, testY)\n",
    "            accs.append(acc)\n",
    "        accs\n",
    "        return np.mean(accs)\n",
    "    accs=Class(brain_data,behav_data)\n",
    "    print(f\"new trained 4 way classifier accuracy={accs}\")\n",
    "\n",
    "\n",
    "    # convert item colume to label colume\n",
    "    imcodeDict={\n",
    "    'A': 'bed',\n",
    "    'B': 'chair',\n",
    "    'C': 'table',\n",
    "    'D': 'bench'}\n",
    "\n",
    "    # Which run to use as test data (leave as None to not have test data)\n",
    "    testRun = 6 # when testing: testRun = 2 ; META['run_num'].iloc[:5]=2\n",
    "\n",
    "    # Decide on the proportion of crescent data to use for classification\n",
    "    include = 1\n",
    "    objects = ['bed', 'bench', 'chair', 'table']\n",
    "    allpairs = itertools.combinations(objects,2)\n",
    "    accs={}\n",
    "    # Iterate over all the possible target pairs of objects\n",
    "    for pair in allpairs:\n",
    "        # Find the control (remaining) objects for this pair\n",
    "        altpair = other(pair)\n",
    "\n",
    "        # pull sorted indices for each of the critical objects, in order of importance (low to high)\n",
    "        # inds = get_inds(FEAT, META, pair, testRun=testRun)\n",
    "\n",
    "        # Find the number of voxels that will be left given your inclusion parameter above\n",
    "        # nvox = red_vox(FEAT.shape[1], include)\n",
    "\n",
    "        for obj in pair:\n",
    "            # foil = [i for i in pair if i != obj][0]\n",
    "            for altobj in altpair:\n",
    "\n",
    "                # establish a naming convention where it is $TARGET_$CLASSIFICATION\n",
    "                # Target is the NF pair (e.g. bed/bench)\n",
    "                # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)\n",
    "                naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)\n",
    "\n",
    "                # Pull the relevant inds from your previously established dictionary \n",
    "                # obj_inds = inds[obj]\n",
    "\n",
    "                # If you're using testdata, this function will split it up. Otherwise it leaves out run as a parameter\n",
    "                # if testRun:\n",
    "                #     trainIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] != int(testRun))]\n",
    "                #     testIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] == int(testRun))]\n",
    "                # else:\n",
    "                #     trainIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "                #     testIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "                # # pull training and test data\n",
    "                # trainX = FEAT[trainIX]\n",
    "                # testX = FEAT[testIX]\n",
    "                # trainY = META.iloc[trainIX].label\n",
    "                # testY = META.iloc[testIX].label\n",
    "\n",
    "                # print(f\"obj={obj},altobj={altobj}\")\n",
    "                # print(f\"unique(trainY)={np.unique(trainY)}\")\n",
    "                # print(f\"unique(testY)={np.unique(testY)}\")\n",
    "                # assert len(np.unique(trainY))==2\n",
    "\n",
    "                # for testRun in range(6):\n",
    "                if testRun:\n",
    "                    trainIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']!=int(testRun))\n",
    "                    testIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']==int(testRun))\n",
    "                else:\n",
    "                    trainIX = ((META['label']==obj) + (META['label']==altobj))\n",
    "                    testIX = ((META['label']==obj) + (META['label']==altobj))\n",
    "                # pull training and test data\n",
    "                trainX = FEAT[trainIX]\n",
    "                testX = FEAT[testIX]\n",
    "                trainY = META.iloc[np.asarray(trainIX)].label\n",
    "                testY = META.iloc[np.asarray(testIX)].label\n",
    "\n",
    "                # print(f\"obj={obj},altobj={altobj}\")\n",
    "                # print(f\"unique(trainY)={np.unique(trainY)}\")\n",
    "                # print(f\"unique(testY)={np.unique(testY)}\")\n",
    "                assert len(np.unique(trainY))==2\n",
    "\n",
    "                # # If you're selecting high-importance features, this bit handles that\n",
    "                # if include < 1:\n",
    "                #     trainX = trainX[:, obj_inds[-nvox:]]\n",
    "                #     testX = testX[:, obj_inds[-nvox:]]\n",
    "\n",
    "                # Train your classifier\n",
    "                clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                        multi_class='multinomial').fit(trainX, trainY)\n",
    "\n",
    "\n",
    "                model_folder = f\"{working_dir}{roiloc}/{subject}/clf/\"\n",
    "                mkdir(model_folder)\n",
    "                # Save it for later use\n",
    "                joblib.dump(clf, model_folder +'/{}.joblib'.format(naming))\n",
    "\n",
    "                # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "                acc = clf.score(testX, testY)\n",
    "                # print(naming, acc)\n",
    "                accs[naming]=acc\n",
    "    \n",
    "    # _=plt.figure()\n",
    "    # _=plt.hist(list(accs.values()))\n",
    "    return accs \n",
    "\n",
    "\n",
    "'''\n",
    "calculate the evidence floor and ceil for each subject and display different forms of evidences.\n",
    "'''\n",
    "def morphingTarget(subject,testRun=6):\n",
    "    '''\n",
    "    purpose:\n",
    "        get the morphing target function\n",
    "    steps:\n",
    "        load train clf\n",
    "        load brain data and behavior data\n",
    "        get the morphing target function\n",
    "            evidence_floor is C evidence for CD classifier(can also be D evidence for CD classifier)\n",
    "            evidence_ceil  is A evidence in AC and AD classifier\n",
    "    '''\n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import nibabel as nib\n",
    "\n",
    "\n",
    "    phasedict = dict(zip([1,2,3,4,5,6],[\"12\", \"12\", \"34\", \"34\", \"56\", \"56\"]))\n",
    "    imcodeDict={\"A\": \"bed\", \"B\": \"Chair\", \"C\": \"table\", \"D\": \"bench\"}\n",
    "    if 'milgram' in os.getcwd():\n",
    "        main_dir='/gpfs/milgram/project/turk-browne/projects/rtTest/'\n",
    "    else:\n",
    "        main_dir='/Users/kailong/Desktop/rtTest'\n",
    "\n",
    "    working_dir=main_dir\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    funcdata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/realtime_preprocessed/{sub}_neurosketch_recognition_run_{run}.nii.gz\"\n",
    "    metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "\n",
    "    metas = []\n",
    "    # for run in range(1, 7):\n",
    "    #     print(run, end='--')\n",
    "    #     # retrieve from the dictionary which phase it is, assign the session\n",
    "    #     phase = phasedict[run]\n",
    "    #     ses = 1\n",
    "        \n",
    "    #     # Build the path for the preprocessed functional data\n",
    "    #     this4d = funcdata.format(ses=ses, run=run, phase=phase, sub=subject)\n",
    "        \n",
    "    #     # Read in the metadata, and reduce it to only the TR values from this run, add to a list\n",
    "    #     thismeta = pd.read_csv(metadata.format(ses=ses, run=run, phase=phase, sub=subject))\n",
    "    #     if dataSource == \"neurosketch\":\n",
    "    #         _run = 1 if run % 2 == 0 else 2\n",
    "    #     else:\n",
    "    #         _run = run\n",
    "    #     thismeta = thismeta[thismeta['run_num'] == int(_run)]\n",
    "        \n",
    "    #     if dataSource == \"realtime\":\n",
    "    #         TR_num = list(thismeta.TR.astype(int))\n",
    "    #         labels = list(thismeta.Item)\n",
    "    #         labels = [imcodeDict[label] for label in labels]\n",
    "    #     else:\n",
    "    #         TR_num = list(thismeta.TR_num.astype(int))\n",
    "    #         labels = list(thismeta.label)\n",
    "        \n",
    "    #     print(\"LENGTH OF TR: {}\".format(len(TR_num)))\n",
    "    #     # Load the functional data\n",
    "    #     runIm = nib.load(this4d)\n",
    "    #     affine_mat = runIm.affine\n",
    "    #     runImDat = runIm.get_fdata()\n",
    "        \n",
    "    #     # Use the TR numbers to select the correct features\n",
    "    #     features = [runImDat[:,:,:,n+3] for n in TR_num]\n",
    "    #     features = np.array(features)\n",
    "    #     chosenMask = np.load(f\"/gpfs/milgram/project/turk-browne/projects/rtTest/schaefer2018/{subject}/chosenMask.npy\")\n",
    "    #     features = features[:, chosenMask==1]\n",
    "    #     print(\"shape of features\", features.shape, \"shape of mask\", mask.shape)\n",
    "    #     # featmean = features.mean(1).mean(1).mean(1)[..., None,None,None] #features.mean(1)[..., None]\n",
    "    #     # features = features - featmean\n",
    "    #     # features = features - features.mean(0)\n",
    "    #     features = normalize(features)\n",
    "    #     # features = np.expand_dims(features, 0)\n",
    "        \n",
    "    #     # Append both so we can use it later\n",
    "    #     # metas.append(labels)\n",
    "    #     # metas['label']\n",
    "\n",
    "    #     t=pd.DataFrame()\n",
    "    #     t['label']=labels\n",
    "    #     t[\"run_num\"]=run\n",
    "    #     behav_data=t if run==1 else pd.concat([behav_data,t])\n",
    "        \n",
    "    #     runs = features if run == 1 else np.concatenate((runs, features))\n",
    "    # for run in range(1, 7):\n",
    "    run=testRun\n",
    "    print(run, end='--')\n",
    "    # retrieve from the dictionary which phase it is, assign the session\n",
    "    phase = phasedict[run]\n",
    "    ses = 1\n",
    "    \n",
    "    # Build the path for the preprocessed functional data\n",
    "    this4d = funcdata.format(ses=ses, run=run, phase=phase, sub=subject)\n",
    "    \n",
    "    # Read in the metadata, and reduce it to only the TR values from this run, add to a list\n",
    "    thismeta = pd.read_csv(metadata.format(ses=ses, run=run, phase=phase, sub=subject))\n",
    "    if dataSource == \"neurosketch\":\n",
    "        _run = 1 if run % 2 == 0 else 2\n",
    "    else:\n",
    "        _run = run\n",
    "    thismeta = thismeta[thismeta['run_num'] == int(_run)]\n",
    "    \n",
    "    if dataSource == \"realtime\":\n",
    "        TR_num = list(thismeta.TR.astype(int))\n",
    "        labels = list(thismeta.Item)\n",
    "        labels = [imcodeDict[label] for label in labels]\n",
    "    else:\n",
    "        TR_num = list(thismeta.TR_num.astype(int))\n",
    "        labels = list(thismeta.label)\n",
    "    \n",
    "    print(\"LENGTH OF TR: {}\".format(len(TR_num)))\n",
    "    # Load the functional data\n",
    "    runIm = nib.load(this4d)\n",
    "    affine_mat = runIm.affine\n",
    "    runImDat = runIm.get_fdata()\n",
    "    \n",
    "    # Use the TR numbers to select the correct features\n",
    "    features = [runImDat[:,:,:,n+3] for n in TR_num]\n",
    "    features = np.array(features)\n",
    "    chosenMask = np.load(f\"/gpfs/milgram/project/turk-browne/projects/rtTest/schaefer2018/{subject}/chosenMask.npy\")\n",
    "    features = features[:, chosenMask==1]\n",
    "    print(\"shape of features\", features.shape, \"shape of mask\", mask.shape)\n",
    "    # featmean = features.mean(1).mean(1).mean(1)[..., None,None,None] #features.mean(1)[..., None]\n",
    "    # features = features - featmean\n",
    "    # features = features - features.mean(0)\n",
    "    features = normalize(features)\n",
    "    # features = np.expand_dims(features, 0)\n",
    "    \n",
    "    # Append both so we can use it later\n",
    "    # metas.append(labels)\n",
    "    # metas['label']\n",
    "\n",
    "    t=pd.DataFrame()\n",
    "    t['label']=labels\n",
    "    t[\"run_num\"]=run\n",
    "    behav_data=t\n",
    "    \n",
    "    runs = features\n",
    "\n",
    "    \n",
    "    dimsize = runIm.header.get_zooms()\n",
    "    \n",
    "    brain_data = runs\n",
    "    print(brain_data.shape)\n",
    "    print(behav_data.shape)\n",
    "    FEAT=brain_data\n",
    "    print(f\"FEAT.shape={FEAT.shape}\")\n",
    "    META=behav_data\n",
    "\n",
    "    # print('mask dimensions: {}'. format(mask.shape))\n",
    "    # print('number of voxels in mask: {}'.format(np.sum(mask)))\n",
    "\n",
    "    # runRecording = pd.read_csv(f\"{cfg.recognition_dir}../runRecording.csv\")\n",
    "    # actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])]) # can be [1,2,3,4,5,6,7,8] or [1,2,4,5]\n",
    "\n",
    "    # objects = ['bed', 'bench', 'chair', 'table']\n",
    "\n",
    "    # for ii,run in enumerate(actualRuns[:2]): # load behavior and brain data for current session\n",
    "    #     t = np.load(f\"{cfg.recognition_dir}brain_run{run}.npy\")\n",
    "    #     # mask = nib.load(f\"{cfg.chosenMask}\").get_data()\n",
    "    #     mask = np.load(cfg.chosenMask)\n",
    "    #     t = t[:,mask==1]\n",
    "    #     t = normalize(t)\n",
    "    #     brain_data=t if ii==0 else np.concatenate((brain_data,t), axis=0)\n",
    "\n",
    "    #     t = pd.read_csv(f\"{cfg.recognition_dir}behav_run{run}.csv\")\n",
    "    #     behav_data=t if ii==0 else pd.concat([behav_data,t])\n",
    "\n",
    "    # FEAT=brain_data.reshape(brain_data.shape[0],-1)\n",
    "    # # FEAT_mean=np.mean(FEAT,axis=1)\n",
    "    # # FEAT=(FEAT.T-FEAT_mean).T\n",
    "    # # FEAT_mean=np.mean(FEAT,axis=0)\n",
    "    # # FEAT=FEAT-FEAT_mean\n",
    "\n",
    "    # META=behav_data\n",
    "\n",
    "    # convert item colume to label colume\n",
    "    imcodeDict={\n",
    "    'A': 'bed',\n",
    "    'B': 'chair',\n",
    "    'C': 'table',\n",
    "    'D': 'bench'}\n",
    "    # label=[]\n",
    "    # for curr_trial in range(META.shape[0]):\n",
    "    #     label.append(imcodeDict[META['Item'].iloc[curr_trial]])\n",
    "    # META['label']=label # merge the label column with the data dataframe\n",
    "\n",
    "\n",
    "    # def classifierEvidence(clf,X,Y): # X shape is [trials,voxelNumber], Y is ['bed', 'bed'] for example # return a 1-d array of probability\n",
    "    #     # This function get the data X and evidence object I want to know Y, and output the trained model evidence.\n",
    "    #     targetID=[np.where((clf.classes_==i)==True)[0][0] for i in Y]\n",
    "    #     # Evidence=(np.sum(X*clf.coef_,axis=1)+clf.intercept_) if targetID[0]==1 else (1-(np.sum(X*clf.coef_,axis=1)+clf.intercept_))\n",
    "    #     Evidence=(X@clf.coef_.T+clf.intercept_) if targetID[0]==1 else (-(X@clf.coef_.T+clf.intercept_))\n",
    "    #     Evidence = 1/(1+np.exp(-Evidence))\n",
    "    #     return np.asarray(Evidence)\n",
    "\n",
    "    # def classifierEvidence(clf,X,Y):\n",
    "    #     ID=np.where((clf.classes_==Y[0])*1==1)[0][0]\n",
    "    #     p = clf.predict_proba(X)[:,ID]\n",
    "    #     BX=np.log(p/(1-p))\n",
    "    #     return BX\n",
    "\n",
    "    def classifierEvidence(clf,X,Y):\n",
    "        ID=np.where((clf.classes_==Y[0])*1==1)[0][0]\n",
    "        Evidence=(X@clf.coef_.T+clf.intercept_) if ID==1 else (-(X@clf.coef_.T+clf.intercept_))\n",
    "        # Evidence=(X@clf.coef_.T+clf.intercept_) if ID==0 else (-(X@clf.coef_.T+clf.intercept_))\n",
    "        return np.asarray(Evidence)\n",
    "\n",
    "    A_ID = (META['label']=='bed')\n",
    "    X = FEAT[A_ID]\n",
    "\n",
    "    # evidence_floor is C evidence for AC_CD BC_CD CD_CD classifier(can also be D evidence for CD classifier)\n",
    "    # Y = ['table'] * X.shape[0]\n",
    "    # CD_clf=joblib.load(cfg.usingModel_dir +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    # CD_C_evidence = classifierEvidence(CD_clf,X,Y)\n",
    "    # evidence_floor = np.mean(CD_C_evidence)\n",
    "    # print(f\"evidence_floor={evidence_floor}\")\n",
    "\n",
    "    model_folder = f\"{working_dir}{roiloc}/{subject}/clf/\"\n",
    "\n",
    "    # #try out other forms of floor: C evidence in AC and D evidence for AD\n",
    "    # Y = ['bench'] * X.shape[0]\n",
    "    # AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    # AD_D_evidence = classifierEvidence(AD_clf,X,Y)\n",
    "    # evidence_floor = np.mean(AD_D_evidence)\n",
    "    # print(f\"evidence_floor2={np.mean(evidence_floor)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # # floor\n",
    "    # Y = ['bench'] * X.shape[0]\n",
    "    # CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    # CD_D_evidence = classifierEvidence(CD_clf,X,Y)\n",
    "    # evidence_floor = np.mean(CD_D_evidence)\n",
    "    # print(f\"evidence_floor={evidence_floor}\")\n",
    "\n",
    "    # Y = ['table'] * X.shape[0]\n",
    "    # CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    # CD_C_evidence = classifierEvidence(CD_clf,X,Y)\n",
    "    # evidence_floor = np.mean(CD_C_evidence)\n",
    "    # print(f\"evidence_floor={evidence_floor}\")\n",
    "\n",
    "\n",
    "    # # evidence_ceil  is A evidence in AC and AD classifier\n",
    "    # Y = ['bed'] * X.shape[0]\n",
    "    # AC_clf=joblib.load(model_folder +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib\n",
    "    # AC_A_evidence = classifierEvidence(AC_clf,X,Y)\n",
    "    # evidence_ceil1 = AC_A_evidence\n",
    "    # print(f\"evidence_ceil1={np.mean(evidence_ceil1)}\")\n",
    "\n",
    "    # Y = ['bed'] * X.shape[0]\n",
    "    # AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    # AD_A_evidence = classifierEvidence(AD_clf,X,Y)\n",
    "    # evidence_ceil2 = AD_A_evidence\n",
    "    # print(f\"evidence_ceil2={np.mean(evidence_ceil2)}\")\n",
    "\n",
    "    # # evidence_ceil = np.mean(evidence_ceil1)\n",
    "    # # evidence_ceil = np.mean(evidence_ceil2)\n",
    "    # evidence_ceil = np.mean((evidence_ceil1+evidence_ceil2)/2)\n",
    "    # print(f\"evidence_ceil={evidence_ceil}\")\n",
    "    store=\"\\n\"\n",
    "    print(\"floor\")\n",
    "    # D evidence for AD_clf when A is presented.\n",
    "    Y = ['bench'] * X.shape[0]\n",
    "    AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    AD_D_evidence = classifierEvidence(AD_clf,X,Y)\n",
    "    evidence_floor = np.mean(AD_D_evidence)\n",
    "    print(f\"D evidence for AD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+f\"D evidence for AD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # C evidence for AC_clf when A is presented.\n",
    "    Y = ['table'] * X.shape[0]\n",
    "    AC_clf=joblib.load(model_folder +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib\n",
    "    AC_C_evidence = classifierEvidence(AC_clf,X,Y)\n",
    "    evidence_floor = np.mean(AC_C_evidence)\n",
    "    print(f\"C evidence for AC_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"C evidence for AC_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # D evidence for CD_clf when A is presented.\n",
    "    Y = ['bench'] * X.shape[0]\n",
    "    CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    CD_D_evidence = classifierEvidence(CD_clf,X,Y)\n",
    "    evidence_floor = np.mean(CD_D_evidence)\n",
    "    print(f\"D evidence for CD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"D evidence for CD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # C evidence for CD_clf when A is presented.\n",
    "    Y = ['table'] * X.shape[0]\n",
    "    CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    CD_C_evidence = classifierEvidence(CD_clf,X,Y)\n",
    "    evidence_floor = np.mean(CD_C_evidence)\n",
    "    print(f\"C evidence for CD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"C evidence for CD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "\n",
    "    print(\"ceil\")\n",
    "    store=store+\"\\n\"+\"ceil\"\n",
    "    # evidence_ceil  is A evidence in AC and AD classifier\n",
    "    Y = ['bed'] * X.shape[0]\n",
    "    AC_clf=joblib.load(model_folder +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib\n",
    "    AC_A_evidence = classifierEvidence(AC_clf,X,Y)\n",
    "    evidence_ceil1 = AC_A_evidence\n",
    "    print(f\"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}\")\n",
    "    store=store+\"\\n\"+f\"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}\"\n",
    "\n",
    "    Y = ['bed'] * X.shape[0]\n",
    "    AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    AD_A_evidence = classifierEvidence(AD_clf,X,Y)\n",
    "    evidence_ceil2 = AD_A_evidence\n",
    "    print(f\"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}\")\n",
    "    store=store+\"\\n\"+f\"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}\"\n",
    "\n",
    "    # evidence_ceil = np.mean(evidence_ceil1)\n",
    "    # evidence_ceil = np.mean(evidence_ceil2)\n",
    "    evidence_ceil = np.mean((evidence_ceil1+evidence_ceil2)/2)\n",
    "    print(f\"evidence_ceil={evidence_ceil}\")\n",
    "    store=store+\"\\n\"+f\"evidence_ceil={evidence_ceil}\"\n",
    "    ceil,floor=evidence_ceil,evidence_floor\n",
    "    mu = (ceil+floor)/2\n",
    "    sig = (ceil-floor)/2.3548\n",
    "    print(f\"floor={floor}, ceil={ceil}\")\n",
    "    print(f\"mu={mu}, sig={sig}\")\n",
    "\n",
    "    store=store+\"\\n\"+f\"floor={floor}, ceil={ceil}\"\n",
    "    store=store+\"\\n\"+f\"mu={mu}, sig={sig}\"\n",
    "    return evidence_floor, evidence_ceil,store\n",
    "    \n",
    "    \n",
    "# sub_id=7\n",
    "import sys\n",
    "\n",
    "# subject= '0119173' #sys.argv[1]\n",
    "# sub_id = [i for i,x in enumerate(subjects) if x == subject][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subLoop(subject):\n",
    "    data={}\n",
    "    accs = minimalClass(subject)\n",
    "    print(\"best 4way classifier accuracy = \",GreedyBestAcc[subject][bestID[subject]])\n",
    "    data['best 4way classifier accuracy']=GreedyBestAcc[subject][bestID[subject]]\n",
    "    for acc in accs:\n",
    "        print(acc,accs[acc])\n",
    "    data[\"accs\"]=accs\n",
    "    floor, ceil,store = morphingTarget(subject,testRun=6)\n",
    "    data[\"store testing run\"]=store\n",
    "    floor, ceil,store = morphingTarget(subject,testRun=1)\n",
    "    data[\"store training run\"]=store\n",
    "    \n",
    "    save_obj(store,f\"./{subject}store\")\n",
    "    return data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "data={}\n",
    "for subject in tqdm(subjects):\n",
    "    data[subject]=subLoop(subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "\n",
      "subject=1206161\n",
      "store training run\n",
      "floor=-0.2152135502794307, ceil=3.4218479405226745 mu=1.6033171951216219, sig=1.5445309541371264\n",
      "\n",
      "store testing run\n",
      "floor=0.1040101817607326, ceil=0.1841148328129634 mu=0.144062507286848, sig=0.03401760279099321\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0119173\n",
      "store training run\n",
      "floor=0.11352732455801277, ceil=3.3454062062042453 mu=1.729466765381129, sig=1.372464277920092\n",
      "\n",
      "store testing run\n",
      "floor=0.0047471010805816725, ceil=0.03447178849028972 mu=0.019609444785435696, sig=0.01262301996335487\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=1206162\n",
      "store training run\n",
      "floor=-0.04883728537700199, ceil=3.2787981285871943 mu=1.6149804216050963, sig=1.4131286792781537\n",
      "\n",
      "store testing run\n",
      "floor=0.08732330754110029, ceil=-0.024526959849264375 mu=0.03139817384591796, sig=-0.04749883955765443\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=1130161\n",
      "store training run\n",
      "floor=0.07491391730443227, ceil=3.580882345732293 mu=1.8278981315183627, sig=1.4888603823797606\n",
      "\n",
      "store testing run\n",
      "floor=0.02608689598450814, ceil=0.16457888439874235 mu=0.09533289019162525, sig=0.058812633095903774\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=1206163\n",
      "store training run\n",
      "floor=0.12081135211297885, ceil=3.226684972508815 mu=1.673748162310897, sig=1.3189543147595701\n",
      "\n",
      "store testing run\n",
      "floor=0.14323473903859302, ceil=0.22409881496572087 mu=0.18366677700215694, sig=0.034340103587195456\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0120171\n",
      "store training run\n",
      "floor=-0.06377816928564801, ceil=3.548229650465877 mu=1.7422257405901145, sig=1.5338915490706322\n",
      "\n",
      "store testing run\n",
      "floor=0.12792851161918303, ceil=0.28636590039806975 mu=0.2071472060086264, sig=0.06728273686890042\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0111171\n",
      "store training run\n",
      "floor=-0.002963343113865857, ceil=3.5108519828388176 mu=1.7539443198624758, sig=1.4921926813116544\n",
      "\n",
      "store testing run\n",
      "floor=0.329794878788798, ceil=0.11983999290774498 mu=0.2248174358482715, sig=-0.08916038979151222\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=1202161\n",
      "store training run\n",
      "floor=0.24812092083963688, ceil=2.302105304263342 mu=1.2751131125514896, sig=0.8722542820722375\n",
      "\n",
      "store testing run\n",
      "floor=-0.2873623762795963, ceil=-0.15178756592240938 mu=-0.21957497110100285, sig=0.05757381109104252\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0125172\n",
      "store training run\n",
      "floor=-0.02020248048930326, ceil=3.467591254127913 mu=1.7236943868193049, sig=1.481142234846788\n",
      "\n",
      "store testing run\n",
      "floor=-0.2106666303373797, ceil=0.21911860322245538 mu=0.004225986442537841, sig=0.18251453777808524\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0110172\n",
      "store training run\n",
      "floor=0.00024273732490211753, ceil=3.2669866012653372 mu=1.6336146692951197, sig=1.3872701987176979\n",
      "\n",
      "store testing run\n",
      "floor=-0.1072611082128088, ceil=0.14672761948458551 mu=0.019733255635888354, sig=0.10785999987149411\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0123173\n",
      "store training run\n",
      "floor=-0.17864049922980088, ceil=2.6175881551637867 mu=1.219473827966993, sig=1.1874590854397773\n",
      "\n",
      "store testing run\n",
      "floor=-0.29176675572948063, ceil=0.53710622466542 mu=0.1226697344679697, sig=0.35199294224346045\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0120173\n",
      "store training run\n",
      "floor=-0.09491240827298392, ceil=3.5998724138838347 mu=1.7524800028054255, sig=1.569044004652972\n",
      "\n",
      "store testing run\n",
      "floor=-0.39001446762600817, ceil=0.4004473111273416 mu=0.005216421750666722, sig=0.3356810679265117\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0110171\n",
      "store training run\n",
      "floor=0.36390915947619307, ceil=3.15297616945954 mu=1.7584426644678666, sig=1.1844177891894627\n",
      "\n",
      "store testing run\n",
      "floor=-0.1281795099945023, ceil=0.2826212454095528 mu=0.07722086770752525, sig=0.174452503568904\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0119172\n",
      "store training run\n",
      "floor=-0.18610664294492832, ceil=2.9903985783164253 mu=1.4021459676857484, sig=1.3489490492871385\n",
      "\n",
      "store testing run\n",
      "floor=-0.1287003382515664, ceil=0.26083796634443124 mu=0.06606881404643242, sig=0.1654230952080846\n",
      "---------------------------------------------------------------\n",
      "\n",
      "subject=0124171\n",
      "store training run\n",
      "floor=-0.17406875220042564, ceil=3.157866051719029 mu=1.4918986497593016, sig=1.4149544776284417\n",
      "\n",
      "store testing run\n",
      "floor=0.5271831842105206, ceil=0.11486116750195734 mu=0.32102217585623893, sig=-0.17509852926302158\n"
     ]
    }
   ],
   "source": [
    "for sub in data:\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print()\n",
    "    print(f\"subject={sub}\")\n",
    "    \n",
    "    t=data[sub]['store training run']\n",
    "    t=t.split('\\n')[-2]+\" \"+t.split('\\n')[-1]\n",
    "    \n",
    "    print(f\"store training run\\n{t}\\n\")\n",
    "    \n",
    "    t=data[sub]['store testing run']\n",
    "    t=t.split('\\n')[-2]+\" \"+t.split('\\n')[-1]\n",
    "    print(f\"store testing run\\n{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'floor=0.5271831842105206, ceil=0.11486116750195734'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
