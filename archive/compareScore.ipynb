{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: The DICOM readers are highly experimental, unstable, and only work for Siemens time-series at the moment\n",
      "Please use with caution.  We would be grateful for your help in improving them\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda env=/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud\n",
      "toml filename=/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/projects/rtSynth_rt/conf/sub002.ses5.toml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/')\n",
    "import argparse\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.io as sio\n",
    "import subprocess\n",
    "from scipy.stats import zscore\n",
    "from nibabel.nicom import dicomreaders\n",
    "import pydicom as dicom  # type: ignore\n",
    "import time\n",
    "from glob import glob\n",
    "import shutil\n",
    "from nilearn.image import new_img_like\n",
    "import joblib\n",
    "import rtCommon.utils as utils\n",
    "from rtCommon.utils import loadConfigFile\n",
    "import pickle5 as pickle\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "# from rtCommon.fileClient import FileInterface\n",
    "# import rtCommon.projectUtils as projUtils\n",
    "# from rtCommon.imageHandling import readRetryDicomFromFileInterface, getDicomFileName, convertDicomImgToNifti\n",
    "\n",
    "\n",
    "argParser = argparse.ArgumentParser()\n",
    "argParser.add_argument('--config', '-c', default='sub002.ses5.toml', type=str, help='experiment file (.json or .toml)')\n",
    "argParser.add_argument('--skipPre', '-s', default=0, type=int, help='skip preprocess or not')\n",
    "argParser.add_argument('--skipGreedy', '-g', default=0, type=int, help='skip greedy or not')\n",
    "argParser.add_argument('--testRun', '-t', default=None, type=int, help='testRun, can be [None,1,2,3,4,5,6,7,8]')\n",
    "argParser.add_argument('--scan_asTemplate', '-a', default=1, type=int, help=\"which scan's middle dicom as Template?\")\n",
    "\n",
    "args = argParser.parse_args(\"\")\n",
    "from rtCommon.cfg_loading import mkdir,cfg_loading\n",
    "# config=\"sub001.ses2.toml\"\n",
    "cfg = cfg_loading(args.config)\n",
    "os.chdir(\"/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/\")\n",
    "cfg.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actualRuns=[1, 2, 15, 16]\n",
      "FEAT.shape=(96, 1390)\n",
      "new_run_indexs=[1, 2]\n",
      "bedbench_bedchair 0.7083333333333334\n",
      "bedbench_bedtable 0.5833333333333334\n",
      "bedbench_benchchair 0.5833333333333334\n",
      "bedbench_benchtable 0.8125\n",
      "bedchair_bedbench 0.7083333333333334\n",
      "bedchair_bedtable 0.5833333333333334\n",
      "bedchair_chairbench 0.5833333333333334\n",
      "bedchair_chairtable 0.8333333333333334\n",
      "bedtable_bedbench 0.7083333333333334\n",
      "bedtable_bedchair 0.7083333333333334\n",
      "bedtable_tablebench 0.8125\n",
      "bedtable_tablechair 0.8333333333333334\n",
      "benchchair_benchbed 0.7083333333333334\n",
      "benchchair_benchtable 0.8125\n",
      "benchchair_chairbed 0.7083333333333334\n",
      "benchchair_chairtable 0.8333333333333334\n",
      "benchtable_benchbed 0.7083333333333334\n",
      "benchtable_benchchair 0.5833333333333334\n",
      "benchtable_tablebed 0.5833333333333334\n",
      "benchtable_tablechair 0.8333333333333334\n",
      "chairtable_chairbed 0.7083333333333334\n",
      "chairtable_chairbench 0.5833333333333334\n",
      "chairtable_tablebed 0.5833333333333334\n",
      "chairtable_tablebench 0.8125\n",
      "average 2 way clf accuracy=0.7048611111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/site-packages/scipy/stats/stats.py:2500: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bedbench_bedchair': 0.7083333333333334,\n",
       " 'bedbench_bedtable': 0.5833333333333334,\n",
       " 'bedbench_benchchair': 0.5833333333333334,\n",
       " 'bedbench_benchtable': 0.8125,\n",
       " 'bedchair_bedbench': 0.7083333333333334,\n",
       " 'bedchair_bedtable': 0.5833333333333334,\n",
       " 'bedchair_chairbench': 0.5833333333333334,\n",
       " 'bedchair_chairtable': 0.8333333333333334,\n",
       " 'bedtable_bedbench': 0.7083333333333334,\n",
       " 'bedtable_bedchair': 0.7083333333333334,\n",
       " 'bedtable_tablebench': 0.8125,\n",
       " 'bedtable_tablechair': 0.8333333333333334,\n",
       " 'benchchair_benchbed': 0.7083333333333334,\n",
       " 'benchchair_benchtable': 0.8125,\n",
       " 'benchchair_chairbed': 0.7083333333333334,\n",
       " 'benchchair_chairtable': 0.8333333333333334,\n",
       " 'benchtable_benchbed': 0.7083333333333334,\n",
       " 'benchtable_benchchair': 0.5833333333333334,\n",
       " 'benchtable_tablebed': 0.5833333333333334,\n",
       " 'benchtable_tablechair': 0.8333333333333334,\n",
       " 'chairtable_chairbed': 0.7083333333333334,\n",
       " 'chairtable_chairbench': 0.5833333333333334,\n",
       " 'chairtable_tablebed': 0.5833333333333334,\n",
       " 'chairtable_tablebench': 0.8125}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compareScore(cfg,testRun=None): \n",
    "    # 这个函数是从minimalClass修改过来的。目的是为了使用ses4的模型来对比ses5的前两个recognition run和后两个recognition run 的testing score\n",
    "    # cfg 使用的是ses5的cfg，可以使用cfg.usingModel_dir 的模型，但是使用的是ses5的数据\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import sklearn\n",
    "    import joblib\n",
    "    import nibabel as nib\n",
    "    import itertools\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    def other(target):\n",
    "        other_objs = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in target]\n",
    "        return other_objs\n",
    "    def red_vox(n_vox, prop=0.1):\n",
    "        return int(np.ceil(n_vox * prop))\n",
    "    if 'milgram' in os.getcwd():\n",
    "        main_dir='/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/'\n",
    "    else:\n",
    "        main_dir='/Volumes/GoogleDrive/My Drive/Turk_Browne_Lab/rtcloud_kp/'\n",
    "    working_dir=main_dir\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    '''\n",
    "    if you read runRecording for current session and found that there are only 4 runs in the current session, \n",
    "    you read the runRecording for previous session and fetch the last 4 recognition runs from previous session\n",
    "    '''\n",
    "    runRecording = pd.read_csv(f\"{cfg.recognition_dir}../runRecording.csv\")\n",
    "\n",
    "    actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])]) # can be [1,2,3,4,5,6,7,8] or [1,2,4,5]\n",
    "    print(f\"actualRuns={actualRuns}\")\n",
    "    objects = ['bed', 'bench', 'chair', 'table']\n",
    "\n",
    "    new_run_indexs=[]\n",
    "    new_run_index=1 #使用新的run 的index，以便于后面的testRun selection的时候不会重复。正常的话 new_run_index 应该是1，2，3，4，5，6，7，8\n",
    "    for ii,run in enumerate(actualRuns[2:]): # load behavior and brain data for current session\n",
    "        t = np.load(f\"{cfg.recognition_dir}brain_run{run}.npy\")\n",
    "        mask = np.load(f\"{cfg.chosenMask}\")\n",
    "        t = t[:,mask==1]\n",
    "        t = normalize(t)\n",
    "        brain_data=t if ii==0 else np.concatenate((brain_data,t), axis=0)\n",
    "\n",
    "        t = pd.read_csv(f\"{cfg.recognition_dir}behav_run{run}.csv\")\n",
    "        t['run_num'] = new_run_index\n",
    "        new_run_indexs.append(new_run_index)\n",
    "        new_run_index+=1\n",
    "        behav_data=t if ii==0 else pd.concat([behav_data,t])\n",
    "    FEAT=brain_data\n",
    "    print(f\"FEAT.shape={FEAT.shape}\")\n",
    "    assert len(FEAT.shape)==2\n",
    "    META=behav_data\n",
    "\n",
    "    # convert item colume to label colume\n",
    "    imcodeDict={\n",
    "    'A': 'bed',\n",
    "    'B': 'chair',\n",
    "    'C': 'table',\n",
    "    'D': 'bench'}\n",
    "    label=[]\n",
    "    for curr_trial in range(META.shape[0]):\n",
    "        label.append(imcodeDict[META['Item'].iloc[curr_trial]])\n",
    "    META['label']=label # merge the label column with the data dataframe\n",
    "\n",
    "    # Which run to use as test data (leave as None to not have test data)\n",
    "    # testRun = 0 # when testing: testRun = 2 ; META['run_num'].iloc[:5]=2\n",
    "    def train4wayClf(META, FEAT):\n",
    "        runList = np.unique(list(META['run_num']))\n",
    "        print(f\"runList={runList}\")\n",
    "        accList={}\n",
    "        for testRun in runList:\n",
    "            trainIX = META['run_num']!=int(testRun)\n",
    "            testIX = META['run_num']==int(testRun)\n",
    "\n",
    "            # pull training and test data\n",
    "            trainX = FEAT[trainIX]\n",
    "            testX = FEAT[testIX]\n",
    "            trainY = META.iloc[np.asarray(trainIX)].label\n",
    "            testY = META.iloc[np.asarray(testIX)].label\n",
    "\n",
    "            # Train your classifier\n",
    "            clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                        multi_class='multinomial').fit(trainX, trainY)\n",
    "            \n",
    "            # model_folder = cfg.trainingModel_dir\n",
    "            # Save it for later use\n",
    "            # joblib.dump(clf, model_folder +'/{}.joblib'.format(naming))\n",
    "            \n",
    "            # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "            acc = clf.score(testX, testY)\n",
    "            print(\"acc=\", acc)\n",
    "            accList[testRun] = acc\n",
    "        print(f\"new trained full rotation 4 way accuracy mean={np.mean(list(accList.values()))}\")\n",
    "        return accList\n",
    "    # accList = train4wayClf(META, FEAT)\n",
    "    \n",
    "    # 获得full rotation的2way clf的accuracy 平均值 中文\n",
    "    accs_rotation=[]\n",
    "    print(f\"new_run_indexs={new_run_indexs}\")\n",
    "\n",
    "    # 用所有数据训练要保存并且使用的模型：\n",
    "    allpairs = itertools.combinations(objects,2)\n",
    "    accs={}\n",
    "    # Iterate over all the possible target pairs of objects\n",
    "    for pair in allpairs:\n",
    "        # Find the control (remaining) objects for this pair\n",
    "        altpair = other(pair)\n",
    "        for obj in pair:\n",
    "            # foil = [i for i in pair if i != obj][0]\n",
    "            for altobj in altpair:\n",
    "                # establish a naming convention where it is $TARGET_$CLASSIFICATION\n",
    "                # Target is the NF pair (e.g. bed/bench)\n",
    "                # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)\n",
    "                naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)\n",
    "\n",
    "                trainIX = ((META['label']==obj) | (META['label']==altobj))\n",
    "                testIX = ((META['label']==obj) | (META['label']==altobj))\n",
    "\n",
    "                # pull training and test data\n",
    "                trainX = FEAT[trainIX]\n",
    "                testX = FEAT[testIX]\n",
    "                trainY = META.iloc[np.asarray(trainIX)].label\n",
    "                testY = META.iloc[np.asarray(testIX)].label\n",
    "\n",
    "                assert len(np.unique(trainY))==2\n",
    "\n",
    "                # Train your classifier\n",
    "                # clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                            # multi_class='multinomial').fit(trainX, trainY)\n",
    "                \n",
    "                # Save it for later use\n",
    "                clf = joblib.load(cfg.usingModel_dir +'/{}.joblib'.format(naming))\n",
    "                \n",
    "                # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "                acc = clf.score(testX, testY)\n",
    "                print(naming, acc)\n",
    "                accs[naming]=acc\n",
    "    print(f\"average 2 way clf accuracy={np.mean(list(accs.values()))}\")\n",
    "\n",
    "    return accs\n",
    "\n",
    "from scipy.stats import zscore\n",
    "def normalize(X):\n",
    "    _X=X.copy()\n",
    "    _X = zscore(_X, axis=0)\n",
    "    _X[np.isnan(_X)]=0\n",
    "    return _X\n",
    "compareScore(cfg,testRun=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A={'bedbench_bedchair': 0.625, #average 2 way clf accuracy=0.6423611111111112\n",
    " 'bedbench_bedtable': 0.5416666666666666,\n",
    " 'bedbench_benchchair': 0.4583333333333333,\n",
    " 'bedbench_benchtable': 0.7708333333333334,\n",
    " 'bedchair_bedbench': 0.7083333333333334,\n",
    " 'bedchair_bedtable': 0.5416666666666666,\n",
    " 'bedchair_chairbench': 0.4583333333333333,\n",
    " 'bedchair_chairtable': 0.75,\n",
    " 'bedtable_bedbench': 0.7083333333333334,\n",
    " 'bedtable_bedchair': 0.625,\n",
    " 'bedtable_tablebench': 0.7708333333333334,\n",
    " 'bedtable_tablechair': 0.75,\n",
    " 'benchchair_benchbed': 0.7083333333333334,\n",
    " 'benchchair_benchtable': 0.7708333333333334,\n",
    " 'benchchair_chairbed': 0.625,\n",
    " 'benchchair_chairtable': 0.75,\n",
    " 'benchtable_benchbed': 0.7083333333333334,\n",
    " 'benchtable_benchchair': 0.4583333333333333,\n",
    " 'benchtable_tablebed': 0.5416666666666666,\n",
    " 'benchtable_tablechair': 0.75,\n",
    " 'chairtable_chairbed': 0.625,\n",
    " 'chairtable_chairbench': 0.4583333333333333,\n",
    " 'chairtable_tablebed': 0.5416666666666666,\n",
    " 'chairtable_tablebench': 0.7708333333333334}\n",
    "\n",
    "B={'bedbench_bedchair': 0.7083333333333334, # average 2 way clf accuracy=0.7048611111111112\n",
    " 'bedbench_bedtable': 0.5833333333333334,\n",
    " 'bedbench_benchchair': 0.5833333333333334,\n",
    " 'bedbench_benchtable': 0.8125,\n",
    " 'bedchair_bedbench': 0.7083333333333334,\n",
    " 'bedchair_bedtable': 0.5833333333333334,\n",
    " 'bedchair_chairbench': 0.5833333333333334,\n",
    " 'bedchair_chairtable': 0.8333333333333334,\n",
    " 'bedtable_bedbench': 0.7083333333333334,\n",
    " 'bedtable_bedchair': 0.7083333333333334,\n",
    " 'bedtable_tablebench': 0.8125,\n",
    " 'bedtable_tablechair': 0.8333333333333334,\n",
    " 'benchchair_benchbed': 0.7083333333333334,\n",
    " 'benchchair_benchtable': 0.8125,\n",
    " 'benchchair_chairbed': 0.7083333333333334,\n",
    " 'benchchair_chairtable': 0.8333333333333334,\n",
    " 'benchtable_benchbed': 0.7083333333333334,\n",
    " 'benchtable_benchchair': 0.5833333333333334,\n",
    " 'benchtable_tablebed': 0.5833333333333334,\n",
    " 'benchtable_tablechair': 0.8333333333333334,\n",
    " 'chairtable_chairbed': 0.7083333333333334,\n",
    " 'chairtable_chairbench': 0.5833333333333334,\n",
    " 'chairtable_tablebed': 0.5833333333333334,\n",
    " 'chairtable_tablebench': 0.8125}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
