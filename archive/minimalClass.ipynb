{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import joblib\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    return X\n",
    "\n",
    "def jitter(size,const=0):\n",
    "    jit = np.random.normal(0+const, 0.05, size)\n",
    "    X = np.zeros((size))\n",
    "    X = X + jit\n",
    "    return X\n",
    "\n",
    "def other(target):\n",
    "    other_objs = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in target]\n",
    "    return other_objs\n",
    "\n",
    "def red_vox(n_vox, prop=0.1):\n",
    "    return int(np.ceil(n_vox * prop))\n",
    "\n",
    "def get_inds(X, Y, pair, run=None):\n",
    "    \n",
    "    inds = {}\n",
    "    \n",
    "    # return relative indices\n",
    "    if run:\n",
    "        trainIX = Y.index[(Y['label'].isin(pair)) & (Y['run_num'] != int(run))]\n",
    "    else:\n",
    "        trainIX = Y.index[(Y['label'].isin(pair))]\n",
    "\n",
    "    # pull training and test data\n",
    "    trainX = X[trainIX]\n",
    "    trainY = Y.iloc[trainIX].label\n",
    "    \n",
    "    # Main classifier on 5 runs, testing on 6th\n",
    "    clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                             multi_class='multinomial').fit(trainX, trainY)\n",
    "    B = clf.coef_[0]  # pull betas\n",
    "\n",
    "    # retrieve only the first object, then only the second object\n",
    "    if run:\n",
    "        obj1IX = Y.index[(Y['label'] == pair[0]) & (Y['run_num'] != int(run))]\n",
    "        obj2IX = Y.index[(Y['label'] == pair[1]) & (Y['run_num'] != int(run))]\n",
    "    else:\n",
    "        obj1IX = Y.index[(Y['label'] == pair[0])]\n",
    "        obj2IX = Y.index[(Y['label'] == pair[1])]\n",
    "    # Get the average of the first object, then the second object\n",
    "    obj1X = np.mean(X[obj1IX], 0)\n",
    "    obj2X = np.mean(X[obj2IX], 0)\n",
    "\n",
    "    # Build the importance map\n",
    "    mult1X = obj1X * B\n",
    "    mult2X = obj2X * B\n",
    "\n",
    "    # Sort these so that they are from least to most important for a given category.\n",
    "    sortmult1X = mult1X.argsort()[::-1]\n",
    "    sortmult2X = mult2X.argsort()\n",
    "\n",
    "    # add to a dictionary for later use\n",
    "    inds[clf.classes_[0]] = sortmult1X\n",
    "    inds[clf.classes_[1]] = sortmult2X\n",
    "             \n",
    "    return inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171' '0110172' '0111171' '0112171']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('features')\n",
    "feats = [i for i in files if 'metadata' not in i]\n",
    "subjects = np.unique([i.split('_')[0] for i in feats])\n",
    "\n",
    "# If you want to reduce the number of subjects used for testing purposes\n",
    "subs=4\n",
    "subjects = subjects[:subs]\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = 'V1'\n",
    "highdict = {}\n",
    "scoredict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['bed', 'bench', 'chair', 'table']\n",
    "phases = ['12', '34', '56']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL READS IN ALL OF THE PARTICIPANTS' DATA and fills into dictionary\n",
    "FEATDICT = {}\n",
    "METADICT = {}\n",
    "for si, sub in enumerate(subjects[:]):\n",
    "    print('{}/{}'.format(si+1, subs))\n",
    "    diffs = []\n",
    "    scores = []\n",
    "    subcount = 0\n",
    "    for phase in phases:\n",
    "        _feat = np.load('features/{}_{}_{}_featurematrix.npy'.format(sub, roi, phase))\n",
    "        _feat = normalize(_feat)\n",
    "        _meta = pd.read_csv('features/metadata_{}_{}_{}.csv'.format(sub, roi, phase))\n",
    "        FEAT = _feat if phase == \"12\" else np.vstack((FEAT, _feat))\n",
    "        META = _meta if phase == \"12\" else pd.concat((META, _meta))\n",
    "    META = META.reset_index(drop=True)\n",
    "\n",
    "    assert FEAT.shape[0] == META.shape[0]\n",
    "    \n",
    "    METADICT[sub] = META\n",
    "    FEATDICT[sub] = FEAT\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0110171\n",
      "bedbench_bedchair 0.7\n",
      "bedbench_bedtable 0.575\n",
      "bedbench_benchchair 0.85\n",
      "bedbench_benchtable 0.625\n",
      "bedchair_bedbench 0.675\n",
      "bedchair_bedtable 0.575\n",
      "bedchair_chairbench 0.85\n",
      "bedchair_chairtable 0.675\n",
      "bedtable_bedbench 0.675\n",
      "bedtable_bedchair 0.7\n",
      "bedtable_tablebench 0.625\n",
      "bedtable_tablechair 0.675\n",
      "benchchair_benchbed 0.675\n",
      "benchchair_benchtable 0.625\n",
      "benchchair_chairbed 0.7\n",
      "benchchair_chairtable 0.675\n",
      "benchtable_benchbed 0.675\n",
      "benchtable_benchchair 0.85\n",
      "benchtable_tablebed 0.575\n",
      "benchtable_tablechair 0.675\n",
      "chairtable_chairbed 0.7\n",
      "chairtable_chairbench 0.85\n",
      "chairtable_tablebed 0.575\n",
      "chairtable_tablebench 0.625\n",
      "0110172\n",
      "bedbench_bedchair 0.5\n",
      "bedbench_bedtable 0.625\n",
      "bedbench_benchchair 0.625\n",
      "bedbench_benchtable 0.675\n",
      "bedchair_bedbench 0.625\n",
      "bedchair_bedtable 0.625\n",
      "bedchair_chairbench 0.625\n",
      "bedchair_chairtable 0.775\n",
      "bedtable_bedbench 0.625\n",
      "bedtable_bedchair 0.5\n",
      "bedtable_tablebench 0.675\n",
      "bedtable_tablechair 0.775\n",
      "benchchair_benchbed 0.625\n",
      "benchchair_benchtable 0.675\n",
      "benchchair_chairbed 0.5\n",
      "benchchair_chairtable 0.775\n",
      "benchtable_benchbed 0.625\n",
      "benchtable_benchchair 0.625\n",
      "benchtable_tablebed 0.625\n",
      "benchtable_tablechair 0.775\n",
      "chairtable_chairbed 0.5\n",
      "chairtable_chairbench 0.625\n",
      "chairtable_tablebed 0.625\n",
      "chairtable_tablebench 0.675\n",
      "0111171\n",
      "bedbench_bedchair 0.575\n",
      "bedbench_bedtable 0.6\n",
      "bedbench_benchchair 0.6\n",
      "bedbench_benchtable 0.55\n",
      "bedchair_bedbench 0.55\n",
      "bedchair_bedtable 0.6\n",
      "bedchair_chairbench 0.6\n",
      "bedchair_chairtable 0.7\n",
      "bedtable_bedbench 0.55\n",
      "bedtable_bedchair 0.575\n",
      "bedtable_tablebench 0.55\n",
      "bedtable_tablechair 0.7\n",
      "benchchair_benchbed 0.55\n",
      "benchchair_benchtable 0.55\n",
      "benchchair_chairbed 0.575\n",
      "benchchair_chairtable 0.7\n",
      "benchtable_benchbed 0.55\n",
      "benchtable_benchchair 0.6\n",
      "benchtable_tablebed 0.6\n",
      "benchtable_tablechair 0.7\n",
      "chairtable_chairbed 0.575\n",
      "chairtable_chairbench 0.6\n",
      "chairtable_tablebed 0.6\n",
      "chairtable_tablebench 0.55\n",
      "0112171\n",
      "bedbench_bedchair 0.675\n",
      "bedbench_bedtable 0.575\n",
      "bedbench_benchchair 0.625\n",
      "bedbench_benchtable 0.575\n",
      "bedchair_bedbench 0.525\n",
      "bedchair_bedtable 0.575\n",
      "bedchair_chairbench 0.625\n",
      "bedchair_chairtable 0.6\n",
      "bedtable_bedbench 0.525\n",
      "bedtable_bedchair 0.675\n",
      "bedtable_tablebench 0.575\n",
      "bedtable_tablechair 0.6\n",
      "benchchair_benchbed 0.525\n",
      "benchchair_benchtable 0.575\n",
      "benchchair_chairbed 0.675\n",
      "benchchair_chairtable 0.6\n",
      "benchtable_benchbed 0.525\n",
      "benchtable_benchchair 0.625\n",
      "benchtable_tablebed 0.575\n",
      "benchtable_tablechair 0.6\n",
      "chairtable_chairbed 0.675\n",
      "chairtable_chairbench 0.625\n",
      "chairtable_tablebed 0.575\n",
      "chairtable_tablebench 0.575\n"
     ]
    }
   ],
   "source": [
    "# Which run to use as test data (leave as None to not have test data)\n",
    "run = 6\n",
    "\n",
    "# Decide on the proportion of crescent data to use for classification\n",
    "include = 1\n",
    "for sub in subjects:\n",
    "    print(sub)\n",
    "    META = METADICT[sub]\n",
    "    FEAT = FEATDICT[sub]\n",
    "    \n",
    "    allpairs = itertools.combinations(objects,2)\n",
    "    \n",
    "    # Iterate over all the possible target pairs of objects\n",
    "    for pair in allpairs:\n",
    "        # Find the control (remaining) objects for this pair\n",
    "        altpair = other(pair)\n",
    "        \n",
    "        # pull sorted indices for each of the critical objects, in order of importance (low to high)\n",
    "        inds = get_inds(FEAT, META, pair, run=run)\n",
    "        \n",
    "        # Find the number of voxels that will be left given your inclusion parameter above\n",
    "        nvox = red_vox(FEAT.shape[1], include)\n",
    "        \n",
    "        for obj in pair:\n",
    "            # foil = [i for i in pair if i != obj][0]\n",
    "            for altobj in altpair:\n",
    "                \n",
    "                # establish a naming convention where it is $TARGET_$CLASSIFICATION\n",
    "                # Target is the NF pair (e.g. bed/bench)\n",
    "                # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)\n",
    "                naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)\n",
    "                \n",
    "                # Pull the relevant inds from your previously established dictionary \n",
    "                obj_inds = inds[obj]\n",
    "                \n",
    "                # If you're using testdata, this function will split it up. Otherwise it leaves out run as a parameter\n",
    "                if run:\n",
    "                    trainIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] != int(run))]\n",
    "                    testIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] == int(run))]\n",
    "                else:\n",
    "                    trainIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "                    testIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "\n",
    "                # pull training and test data\n",
    "                trainX = FEAT[trainIX]\n",
    "                testX = FEAT[testIX]\n",
    "                trainY = META.iloc[trainIX].label\n",
    "                testY = META.iloc[testIX].label\n",
    "                \n",
    "                # If you're selecting high-importance features, this bit handles that\n",
    "                if include < 1:\n",
    "                    trainX = trainX[:, obj_inds[-nvox:]]\n",
    "                    testX = testX[:, obj_inds[-nvox:]]\n",
    "                \n",
    "                # Train your classifier\n",
    "                clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                         multi_class='multinomial').fit(trainX, trainY)\n",
    "                \n",
    "                # Save it for later use\n",
    "                joblib.dump(clf, 'clf/{}_{}.joblib'.format(sub, naming))\n",
    "                \n",
    "                # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "                acc = clf.score(testX, testY)\n",
    "                print(naming, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is how you would load a saved classifier for a given subject, target axis and control classifier\n",
    "clf = joblib.load('clf/1206162_bedbench_bedtable.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the classifier on a new TR (assuming X has shape [1, nvox], and Y is [label]\n",
    "# X AND Y WILL NEED REPLACED\n",
    "acc = clf.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running NF to try to activate table during bench for subject 0118171, you would do this prior to starting:\n",
    "clf1 = joblib.load('clf/0118171_benchtable_tablebed.joblib') \n",
    "clf2 = joblib.load('clf/0118171_benchtable_tablechair.joblib') \n",
    "\n",
    "# then do this for each TR\n",
    "s1 = clf1.score(newTR, ['table'])\n",
    "s2 = clf2.score(newTR, ['table'])\n",
    "NFparam = s1 + s2 # or an average or whatever"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
