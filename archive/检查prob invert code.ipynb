{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda env=/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud\n",
      "np.sum(chosenMask)=3488\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "2--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "3--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "4--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "5--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "6--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of chosenMask (94, 94, 72)\n",
      "(480, 3488)\n",
      "(480, 2)\n",
      "FEAT.shape=(480, 3488)\n",
      "new trained 4 way classifier accuracy=0.325\n",
      "1--LENGTH OF TR: 80\n",
      "shape of features (80, 3488) shape of mask (94, 94, 72)\n",
      "(80, 3488)\n",
      "(80, 2)\n",
      "FEAT.shape=(80, 3488)\n",
      "floor\n",
      "> \u001b[0;32m<ipython-input-2-821397c3c47a>\u001b[0m(303)\u001b[0;36mclassifierProb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    301 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    302 \u001b[0;31m        \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 303 \u001b[0;31m        \u001b[0mID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    304 \u001b[0;31m        \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    305 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> clf.classes_\n",
      "array(['bed', 'bench'], dtype=object)\n",
      "ipdb> Y\n",
      "'bench'\n",
      "ipdb> np.where((clf.classes_==Y)*1==1)[0][0]\n",
      "1\n",
      "ipdb> ID=np.where((clf.classes_==Y)*1==1)[0][0]\n",
      "ipdb> clf.predict_proba(X)\n",
      "array([[0.93683107, 0.06316893],\n",
      "       [0.09842111, 0.90157889],\n",
      "       [0.70768053, 0.29231947],\n",
      "       [0.661695  , 0.338305  ],\n",
      "       [0.01782865, 0.98217135],\n",
      "       [0.71006081, 0.28993919],\n",
      "       [0.55393846, 0.44606154],\n",
      "       [0.01239683, 0.98760317],\n",
      "       [0.69522068, 0.30477932],\n",
      "       [0.61115972, 0.38884028],\n",
      "       [0.66479239, 0.33520761],\n",
      "       [0.79136829, 0.20863171],\n",
      "       [0.0160552 , 0.9839448 ],\n",
      "       [0.40751262, 0.59248738],\n",
      "       [0.2202043 , 0.7797957 ],\n",
      "       [0.69021722, 0.30978278],\n",
      "       [0.50129773, 0.49870227],\n",
      "       [0.13188222, 0.86811778],\n",
      "       [0.18544234, 0.81455766],\n",
      "       [0.70483858, 0.29516142]])\n",
      "ipdb> p = clf.predict_proba(X)[:,ID]\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> l\n",
      "\u001b[1;32m    298 \u001b[0m    \u001b[0;31m#     BX=np.log(p/(1-p))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    299 \u001b[0m    \u001b[0;31m#     return BX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    300 \u001b[0m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    301 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    302 \u001b[0m        \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 303 \u001b[0;31m        \u001b[0mID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    304 \u001b[0m        \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    305 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    306 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    307 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    308 \u001b[0m    \u001b[0mA_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMETA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'bed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> \n",
      "\u001b[1;32m    309 \u001b[0m    \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFEAT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    310 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    311 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    312 \u001b[0m    \u001b[0mmodel_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{working_dir}{roiloc}/{subject}/clf/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    313 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    314 \u001b[0m    \u001b[0mstore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    315 \u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"floor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    316 \u001b[0m    \u001b[0;31m# D evidence for AD_clf when A is presented.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    317 \u001b[0m    \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bench'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    318 \u001b[0m    \u001b[0mAD_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'bedchair_bedbench.joblib'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    319 \u001b[0m    \u001b[0mAD_D_evidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAD_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> 1\n",
      "1\n",
      "ipdb> 2\n",
      "2\n",
      "ipdb> ID=np.where((clf.classes_==Y)*1==1)[0][0]\n",
      "ipdb> ID\n",
      "1\n",
      "ipdb> p = clf.predict_proba(X)[:,ID]\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> \n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> clf.predict_proba(X)\n",
      "array([[0.93683107, 0.06316893],\n",
      "       [0.09842111, 0.90157889],\n",
      "       [0.70768053, 0.29231947],\n",
      "       [0.661695  , 0.338305  ],\n",
      "       [0.01782865, 0.98217135],\n",
      "       [0.71006081, 0.28993919],\n",
      "       [0.55393846, 0.44606154],\n",
      "       [0.01239683, 0.98760317],\n",
      "       [0.69522068, 0.30477932],\n",
      "       [0.61115972, 0.38884028],\n",
      "       [0.66479239, 0.33520761],\n",
      "       [0.79136829, 0.20863171],\n",
      "       [0.0160552 , 0.9839448 ],\n",
      "       [0.40751262, 0.59248738],\n",
      "       [0.2202043 , 0.7797957 ],\n",
      "       [0.69021722, 0.30978278],\n",
      "       [0.50129773, 0.49870227],\n",
      "       [0.13188222, 0.86811778],\n",
      "       [0.18544234, 0.81455766],\n",
      "       [0.70483858, 0.29516142]])\n",
      "ipdb> clf.predict_proba(X)[:,ID]\n",
      "array([0.06316893, 0.90157889, 0.29231947, 0.338305  , 0.98217135,\n",
      "       0.28993919, 0.44606154, 0.98760317, 0.30477932, 0.38884028,\n",
      "       0.33520761, 0.20863171, 0.9839448 , 0.59248738, 0.7797957 ,\n",
      "       0.30978278, 0.49870227, 0.86811778, 0.81455766, 0.29516142])\n",
      "ipdb> p = clf.predict_proba(X)[:,ID]\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> p=clf.predict_proba(X)[:,ID]\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> clf.predict_proba(X)[:,ID]\n",
      "array([0.06316893, 0.90157889, 0.29231947, 0.338305  , 0.98217135,\n",
      "       0.28993919, 0.44606154, 0.98760317, 0.30477932, 0.38884028,\n",
      "       0.33520761, 0.20863171, 0.9839448 , 0.59248738, 0.7797957 ,\n",
      "       0.30978278, 0.49870227, 0.86811778, 0.81455766, 0.29516142])\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-821397c3c47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnaming\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0maccs_rotation_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0mevidence_rotation_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorphingTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;31m# for testRun in range(1,7):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;31m#     t=np.mean(list(accs_rotation_container[testRun].values()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-821397c3c47a>\u001b[0m in \u001b[0;36mmorphingTarget\u001b[0;34m(subject, testRun)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bench'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mAD_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'bedchair_bedbench.joblib'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mAD_D_evidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAD_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0mevidence_floor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAD_D_evidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"D evidence for AD_clf when A is presented={evidence_floor}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-821397c3c47a>\u001b[0m in \u001b[0;36mclassifierProb\u001b[0;34m(clf, X, Y)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-821397c3c47a>\u001b[0m in \u001b[0;36mclassifierProb\u001b[0;34m(clf, X, Y)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassifierProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/milgram/project/turk-browne/users/kp578/CONDA/rtcloud/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "这个code的目的是用neurosketch 的数据来检测现在在realtime data里面发现的issue：也就是ceiling有时候竟然比floor更小\n",
    "这个code的运行逻辑是\n",
    "用neurosketch前五个run训练2 way classifiers，然后用最后一个run来计算ceiling和floor的值，看是否合理\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "purpose:\n",
    "    find the best performed mask from the result of aggregate_greedy.py and save as chosenMask\n",
    "    train all possible pairs of 2way classifiers and save for evidence calculation\n",
    "    load saved classifiers and calculate different forms of evidence\n",
    "steps:\n",
    "    load the result of aggregate_greedy.py\n",
    "    display the result of aggregate_greedy.py\n",
    "    find the best performed ROI for each subject and display the accuracy of each subject, save the best performed ROI as chosenMask\n",
    "    load the functional and behavior data and choseMask and train all possible pairs of 2way classifiers\n",
    "    calculate the evidence floor and ceil for each subject and display different forms of evidences.\n",
    "    \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "load the result of aggregate_greedy.py\n",
    "'''\n",
    "# To visualize the greedy result starting for 31 ROIs, in total 25 subjects.\n",
    "import os\n",
    "os.chdir(\"/gpfs/milgram/project/turk-browne/projects/rtTest/kp_scratch/\")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle5 as pickle\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "print(f\"conda env={os.environ['CONDA_DEFAULT_ENV']}\") \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools\n",
    "import pickle\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "workingDir=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "roiloc=\"schaefer2018\"\n",
    "dataSource=\"neurosketch\"\n",
    "subjects_correctly_aligned=['1206161','0119173','1206162','1130161','1206163','0120171','0111171','1202161','0125172','0110172','0123173','0120173','0110171','0119172','0124171','0123171','1203161','0118172','0118171','0112171','1207162','0117171','0119174','0112173','0112172']\n",
    "subjects=subjects_correctly_aligned\n",
    "N=25\n",
    "workingPath=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "GreedyBestAcc=np.zeros((len(subjects),N+1))\n",
    "GreedyBestAcc[GreedyBestAcc==0]=None\n",
    "GreedyBestAcc={}\n",
    "numberOfROIs={}\n",
    "for ii,subject in enumerate(subjects):\n",
    "    # try:\n",
    "    #     GreedyBestAcc[ii,N]=np.load(workingPath+\"./{}/{}/output/uniMaskRanktag2_top{}.npy\".format(roiloc, subject, N))\n",
    "    # except:\n",
    "    #     pass\n",
    "    t=np.load(workingPath+\"./{}/{}/output/uniMaskRanktag2_top{}.npy\".format(roiloc, subject, N))\n",
    "    GreedyBestAcc[subject]=[np.float(t)]\n",
    "    numberOfROIs[subject]=[N]\n",
    "    # for len_topN_1 in range(N-1,0,-1):\n",
    "    for len_topN in range(1,N):\n",
    "        # Wait(f\"./tmp/{subject}_{N}_{roiloc}_{dataSource}_{len_topN_1}.pkl\")\n",
    "        try:\n",
    "            # {当前的被试}_{greedy开始的ROI数目，也就是25}_{mask的种类schaefer2018}_{数据来源neurosketch}_{当前的 megaROI 包含有的数目}\n",
    "            di = load_obj(f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len_topN}\")\n",
    "            GreedyBestAcc[subject].append(np.float(di['bestAcc']))\n",
    "            numberOfROIs[subject].append(len_topN)\n",
    "            # GreedyBestAcc[ii,len_topN] = di['bestAcc']\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# '''\n",
    "# to load the imtermediate results from greedy code to examine the system\n",
    "# '''\n",
    "# def wait(tmpFile):\n",
    "#     while not os.path.exists(tmpFile+'_result.npy'):\n",
    "#         time.sleep(5)\n",
    "#         print(f\"waiting for {tmpFile}_result.npy\\n\")\n",
    "#     return np.load(tmpFile+'_result.npy')\n",
    "\n",
    "# subject= '0119173' #sys.argv[1]\n",
    "# sub_id = [i for i,x in enumerate(subjects) if x == subject][0]\n",
    "# intermediate_result=np.zeros((N+1,N+1))\n",
    "# # 应该有多少？25个24ROI，2个1ROI，24个\n",
    "# for i in range(N,1,-1):\n",
    "#     for j in range(i):\n",
    "#         tmpFile=f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{i}_{j}\"\n",
    "#         sl_result=wait(tmpFile)\n",
    "#         intermediate_result[i,j]=sl_result\n",
    "\n",
    "# # _=plt.imshow(intermediate_result)\n",
    "# #最后一行是25个24ROI，第2行是2个1ROI\n",
    "\n",
    "'''\n",
    "display the result of aggregate_greedy.py\n",
    "'''\n",
    "# GreedyBestAcc=GreedyBestAcc.T\n",
    "# plt.imshow(GreedyBestAcc)\n",
    "# _=plt.figure()\n",
    "# for i in range(GreedyBestAcc.shape[0]):\n",
    "#     plt.scatter([i]*GreedyBestAcc.shape[1],GreedyBestAcc[i,:],c='g',s=2)\n",
    "# plt.plot(np.arange(GreedyBestAcc.shape[0]),np.nanmean(GreedyBestAcc,axis=1))\n",
    "# # plt.ylim([0.19,0.36])\n",
    "# # plt.xlabel(\"number of ROIs\")\n",
    "# # plt.ylabel(\"accuracy\")\n",
    "# _=plt.figure()\n",
    "# for j in range(GreedyBestAcc.shape[1]):\n",
    "#     plt.plot(GreedyBestAcc[:,j])\n",
    "\n",
    "\n",
    "# GreedyBestAcc=GreedyBestAcc.T\n",
    "# _=plt.figure()\n",
    "# plt.imshow(GreedyBestAcc)\n",
    "\n",
    "'''\n",
    "find the best performed ROI for each subject and display the accuracy of each subject, save the best performed ROI as chosenMask\n",
    "'''\n",
    "#find best ID for each subject\n",
    "bestID={}\n",
    "for ii,subject in enumerate(subjects):\n",
    "    t=GreedyBestAcc[subject]\n",
    "    bestID[subject] = numberOfROIs[subject][np.where(t==np.nanmax(t))[0][0]] #bestID 指的是每一个subject对应的最好的megaROI包含的ROI的数目\n",
    "chosenMask={}\n",
    "for subject in bestID:\n",
    "    # best ID  \n",
    "    # {当前的被试}_{greedy开始的ROI数目，也就是25}_{mask的种类schaefer2018}_{数据来源neurosketch}_{最好的megaROI 包含有的数目}\n",
    "    di = load_obj(f\"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{bestID[subject]}\")\n",
    "    chosenMask[subject] = di['bestROIs']\n",
    "\n",
    "def getMask(topN, subject):\n",
    "    workingDir=\"/gpfs/milgram/project/turk-browne/projects/rtTest/\"\n",
    "    for pn, parc in enumerate(topN):\n",
    "        _mask = nib.load(workingDir+\"/{}/{}/{}\".format(roiloc, subject, parc))\n",
    "        aff = _mask.affine\n",
    "        _mask = _mask.get_data()\n",
    "        _mask = _mask.astype(int)\n",
    "        # say some things about the mask.\n",
    "        mask = _mask if pn == 0 else mask + _mask\n",
    "        mask[mask>0] = 1\n",
    "    return mask\n",
    "\n",
    "for sub in chosenMask:\n",
    "    mask=getMask(chosenMask[sub], sub)\n",
    "    # if not os.path.exists(f\"{workingDir}/{roiloc}/{sub}/chosenMask.npy\"):\n",
    "    np.save(f\"{workingDir}/{roiloc}/{sub}/chosenMask\",mask)\n",
    "    \n",
    "\n",
    "from scipy.stats import zscore\n",
    "def normalize(X):\n",
    "    _X=X.copy()\n",
    "    _X = zscore(_X, axis=0)\n",
    "    _X[np.isnan(_X)]=0\n",
    "    return _X\n",
    "\n",
    "def mkdir(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "'''\n",
    "calculate the evidence floor and ceil for each subject and display different forms of evidences.\n",
    "'''\n",
    "def morphingTarget(subject,testRun=6):\n",
    "    '''\n",
    "    purpose:\n",
    "        get the morphing target function\n",
    "    steps:\n",
    "        load train clf\n",
    "        load brain data and behavior data\n",
    "        get the morphing target function\n",
    "            evidence_floor is C evidence for CD classifier(can also be D evidence for CD classifier)\n",
    "            evidence_ceil  is A evidence in AC and AD classifier\n",
    "    '''\n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    import nibabel as nib\n",
    "\n",
    "\n",
    "    phasedict = dict(zip([1,2,3,4,5,6],[\"12\", \"12\", \"34\", \"34\", \"56\", \"56\"]))\n",
    "    imcodeDict={\"A\": \"bed\", \"B\": \"Chair\", \"C\": \"table\", \"D\": \"bench\"}\n",
    "    if 'milgram' in os.getcwd():\n",
    "        main_dir='/gpfs/milgram/project/turk-browne/projects/rtTest/'\n",
    "    else:\n",
    "        main_dir='/Users/kailong/Desktop/rtTest'\n",
    "\n",
    "    working_dir=main_dir\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    funcdata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/realtime_preprocessed/{sub}_neurosketch_recognition_run_{run}.nii.gz\"\n",
    "    metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "\n",
    "    metas = []\n",
    "\n",
    "    run=testRun\n",
    "    print(run, end='--')\n",
    "    # retrieve from the dictionary which phase it is, assign the session\n",
    "    phase = phasedict[run]\n",
    "    ses = 1\n",
    "    \n",
    "    # Build the path for the preprocessed functional data\n",
    "    this4d = funcdata.format(ses=ses, run=run, phase=phase, sub=subject)\n",
    "    \n",
    "    # Read in the metadata, and reduce it to only the TR values from this run, add to a list\n",
    "    thismeta = pd.read_csv(metadata.format(ses=ses, run=run, phase=phase, sub=subject))\n",
    "    if dataSource == \"neurosketch\":\n",
    "        _run = 1 if run % 2 == 0 else 2\n",
    "    else:\n",
    "        _run = run\n",
    "    thismeta = thismeta[thismeta['run_num'] == int(_run)]\n",
    "    \n",
    "    if dataSource == \"realtime\":\n",
    "        TR_num = list(thismeta.TR.astype(int))\n",
    "        labels = list(thismeta.Item)\n",
    "        labels = [imcodeDict[label] for label in labels]\n",
    "    else:\n",
    "        TR_num = list(thismeta.TR_num.astype(int))\n",
    "        labels = list(thismeta.label)\n",
    "    \n",
    "    print(\"LENGTH OF TR: {}\".format(len(TR_num)))\n",
    "    # Load the functional data\n",
    "    runIm = nib.load(this4d)\n",
    "    affine_mat = runIm.affine\n",
    "    runImDat = runIm.get_fdata()\n",
    "    \n",
    "    # Use the TR numbers to select the correct features\n",
    "    features = [runImDat[:,:,:,n+3] for n in TR_num]\n",
    "    features = np.array(features)\n",
    "    chosenMask = np.load(f\"/gpfs/milgram/project/turk-browne/projects/rtTest/schaefer2018/{subject}/chosenMask.npy\")\n",
    "    features = features[:, chosenMask==1]\n",
    "    print(\"shape of features\", features.shape, \"shape of mask\", mask.shape)\n",
    "    # featmean = features.mean(1).mean(1).mean(1)[..., None,None,None] #features.mean(1)[..., None]\n",
    "    # features = features - featmean\n",
    "    # features = features - features.mean(0)\n",
    "    features = normalize(features)\n",
    "    # features = np.expand_dims(features, 0)\n",
    "    \n",
    "    # Append both so we can use it later\n",
    "    # metas.append(labels)\n",
    "    # metas['label']\n",
    "\n",
    "    t=pd.DataFrame()\n",
    "    t['label']=labels\n",
    "    t[\"run_num\"]=run\n",
    "    behav_data=t\n",
    "    \n",
    "    runs = features\n",
    "\n",
    "    \n",
    "    dimsize = runIm.header.get_zooms()\n",
    "    \n",
    "    brain_data = runs\n",
    "    print(brain_data.shape)\n",
    "    print(behav_data.shape)\n",
    "    FEAT=brain_data\n",
    "    print(f\"FEAT.shape={FEAT.shape}\")\n",
    "    META=behav_data\n",
    "\n",
    "    # convert item colume to label colume\n",
    "    imcodeDict={\n",
    "    'A': 'bed',\n",
    "    'B': 'chair',\n",
    "    'C': 'table',\n",
    "    'D': 'bench'}\n",
    "\n",
    "\n",
    "    # def classifierEvidence(clf,X,Y):\n",
    "    #     ID=np.where((clf.classes_==Y)*1==1)[0][0]\n",
    "    #     Evidence=(X@clf.coef_.T+clf.intercept_) if ID==1 else (-(X@clf.coef_.T+clf.intercept_))\n",
    "    #     # Evidence=(X@clf.coef_.T+clf.intercept_) if ID==0 else (-(X@clf.coef_.T+clf.intercept_))\n",
    "    #     return np.asarray(Evidence)\n",
    "\n",
    "    # def classifierEvidence(clf,X,Y):\n",
    "    #     ID=np.where((clf.classes_==Y)*1==1)[0][0]\n",
    "    #     p = clf.predict_proba(X)[:,ID]\n",
    "    #     BX=np.log(p/(1-p))\n",
    "    #     return BX\n",
    "    import pdb\n",
    "    def classifierProb(clf,X,Y):\n",
    "        _=pdb.set_trace()\n",
    "        ID=np.where((clf.classes_==Y)*1==1)[0][0]\n",
    "        p = clf.predict_proba(X)[:,ID]\n",
    "        return p\n",
    "    def logit(p):\n",
    "        return np.log(p/(1-p))\n",
    "    A_ID = (META['label']=='bed')\n",
    "    X = FEAT[A_ID]\n",
    "\n",
    "\n",
    "    model_folder = f\"{working_dir}{roiloc}/{subject}/clf/\"\n",
    "\n",
    "    store=\"\\n\"\n",
    "    print(\"floor\")\n",
    "    # D evidence for AD_clf when A is presented.\n",
    "    Y = 'bench'\n",
    "    AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    AD_D_evidence = classifierProb(AD_clf,X,Y)\n",
    "    evidence_floor = np.mean(AD_D_evidence)\n",
    "    print(f\"D evidence for AD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+f\"D evidence for AD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # C evidence for AC_clf when A is presented.\n",
    "    Y = 'table'\n",
    "    AC_clf=joblib.load(model_folder +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib\n",
    "    AC_C_evidence = classifierProb(AC_clf,X,Y)\n",
    "    evidence_floor = np.mean(AC_C_evidence)\n",
    "    print(f\"C evidence for AC_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"C evidence for AC_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # D evidence for CD_clf when A is presented.\n",
    "    Y = 'bench'\n",
    "    CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    CD_D_evidence = classifierProb(CD_clf,X,Y)\n",
    "    evidence_floor = np.mean(CD_D_evidence)\n",
    "    print(f\"D evidence for CD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"D evidence for CD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "    # C evidence for CD_clf when A is presented.\n",
    "    Y = 'table'\n",
    "    CD_clf=joblib.load(model_folder +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    CD_C_evidence = classifierProb(CD_clf,X,Y)\n",
    "    evidence_floor = np.mean(CD_C_evidence)\n",
    "    print(f\"C evidence for CD_clf when A is presented={evidence_floor}\")\n",
    "    store=store+\"\\n\"+f\"C evidence for CD_clf when A is presented={evidence_floor}\"\n",
    "\n",
    "\n",
    "    print(\"ceil\")\n",
    "    store=store+\"\\n\"+\"ceil\"\n",
    "    # evidence_ceil  is A evidence in AC and AD classifier\n",
    "    Y = 'bed'\n",
    "    AC_clf=joblib.load(model_folder +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib\n",
    "    AC_A_evidence = classifierProb(AC_clf,X,Y)\n",
    "    evidence_ceil1 = AC_A_evidence\n",
    "    print(f\"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}\")\n",
    "    store=store+\"\\n\"+f\"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}\"\n",
    "\n",
    "    Y = 'bed'\n",
    "    AD_clf=joblib.load(model_folder +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib\n",
    "    AD_A_evidence = classifierProb(AD_clf,X,Y)\n",
    "    evidence_ceil2 = AD_A_evidence\n",
    "    print(f\"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}\")\n",
    "    store=store+\"\\n\"+f\"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}\"\n",
    "\n",
    "    # evidence_ceil = np.mean(evidence_ceil1)\n",
    "    # evidence_ceil = np.mean(evidence_ceil2)\n",
    "    evidence_ceil = np.mean((evidence_ceil1+evidence_ceil2)/2)\n",
    "    print(f\"evidence_ceil={evidence_ceil}\")\n",
    "    store=store+\"\\n\"+f\"evidence_ceil={evidence_ceil}\"\n",
    "    ceil,floor=logit(evidence_ceil),logit(evidence_floor)\n",
    "    mu = (ceil+floor)/2\n",
    "    sig = (ceil-floor)/2.3548\n",
    "    print(f\"floor={floor}, ceil={ceil}\")\n",
    "    print(f\"mu={mu}, sig={sig}\")\n",
    "\n",
    "    store=store+\"\\n\"+f\"floor={floor}, ceil={ceil}\"\n",
    "    store=store+\"\\n\"+f\"mu={mu}, sig={sig}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    BC_clf=joblib.load(model_folder +'benchchair_chairtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    BD_clf=joblib.load(model_folder +'bedchair_chairbench.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib\n",
    "    Y = 'chair'\n",
    "    # imcodeDict={\n",
    "    # 'A': 'bed',\n",
    "    # 'B': 'chair',\n",
    "    # 'C': 'table',\n",
    "    # 'D': 'bench'}\n",
    "    print(f\"classifierProb(BC_clf,FEAT,Y)={classifierProb(BC_clf,FEAT,Y)}\")\n",
    "    print(f\"classifierProb(BD_clf,FEAT,Y)={classifierProb(BD_clf,FEAT,Y)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # convert item colume to label colume\n",
    "    # imcodeDict={\n",
    "    # 'A': 'bed',\n",
    "    # 'B': 'chair',\n",
    "    # 'C': 'table',\n",
    "    # 'D': 'bench'}\n",
    "    def testMorphParamFor(A): #A='bed''chair'...\n",
    "        A_ID = (META['label']==A)\n",
    "        X = FEAT[A_ID]\n",
    "\n",
    "\n",
    "        # 这里的X是选择的testRun里面的所有的展示A的trials\n",
    "        BC_B_evidence = classifierProb(BC_clf,X,Y)\n",
    "        BD_B_evidence = classifierProb(BD_clf,X,Y)\n",
    "        print(f\"BC_B_evidence={BC_B_evidence}\")\n",
    "        print(f\"BD_B_evidence={BD_B_evidence}\")\n",
    "        B_evidence = (BC_B_evidence+BD_B_evidence)/2\n",
    "        print(f\"B_evidence={B_evidence}\")\n",
    "        print(f\"mu={mu}, sig={sig}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        def gaussian(x, mu, sig):\n",
    "            # mu and sig is determined before each neurofeedback session using 2 recognition runs.\n",
    "            return np.round(1+18*(1 - np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))))) # map from (-∞,∞) -> [1,19]\n",
    "        morphParam=np.mean(gaussian(B_evidence, mu, sig))\n",
    "        # B_evidences.append(B_evidence)\n",
    "        print(f\"morphParam={morphParam}\")\n",
    "        return f\"morphParam for {A} = {morphParam}\"\n",
    "\n",
    "    store=store+\"\\n\"+testMorphParamFor('bed')\n",
    "    store=store+\"\\n\"+testMorphParamFor('chair')\n",
    "    store=store+\"\\n\"+testMorphParamFor('table')\n",
    "    store=store+\"\\n\"+testMorphParamFor('bench')\n",
    "\n",
    "    return evidence_floor, evidence_ceil,store\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "load the functional and behavior data and choseMask and train all possible pairs of 2way classifiers\n",
    "''' \n",
    "# def minimalClass(subject):\n",
    "subject=subjects[1]\n",
    "'''\n",
    "purpose: \n",
    "    train offline models\n",
    "\n",
    "steps:\n",
    "    load preprocessed and aligned behavior and brain data \n",
    "    select data with the wanted pattern like AB AC AD BC BD CD \n",
    "    train correspondng classifier and save the classifier performance and the classifiers themselves.\n",
    "\n",
    "'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import joblib\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def gaussian(x, mu, sig):\n",
    "    # mu and sig is determined before each neurofeedback session using 2 recognition runs.\n",
    "    return round(1+18*(1 - np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))))) # map from (0,1) -> [1,19]\n",
    "\n",
    "def jitter(size,const=0):\n",
    "    jit = np.random.normal(0+const, 0.05, size)\n",
    "    X = np.zeros((size))\n",
    "    X = X + jit\n",
    "    return X\n",
    "\n",
    "def other(target):\n",
    "    other_objs = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in target]\n",
    "    return other_objs\n",
    "\n",
    "def red_vox(n_vox, prop=0.1):\n",
    "    return int(np.ceil(n_vox * prop))\n",
    "\n",
    "def get_inds(X, Y, pair, testRun=None):\n",
    "\n",
    "    inds = {}\n",
    "\n",
    "    # return relative indices\n",
    "    if testRun:\n",
    "        trainIX = Y.index[(Y['label'].isin(pair)) & (Y['run_num'] != int(testRun))]\n",
    "    else:\n",
    "        trainIX = Y.index[(Y['label'].isin(pair))]\n",
    "\n",
    "    # pull training and test data\n",
    "    trainX = X[trainIX]\n",
    "    trainY = Y.iloc[trainIX].label\n",
    "\n",
    "    # Main classifier on 5 runs, testing on 6th\n",
    "    clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                            multi_class='multinomial').fit(trainX, trainY)\n",
    "    B = clf.coef_[0]  # pull betas\n",
    "\n",
    "    # retrieve only the first object, then only the second object\n",
    "    if testRun:\n",
    "        obj1IX = Y.index[(Y['label'] == pair[0]) & (Y['run_num'] != int(testRun))]\n",
    "        obj2IX = Y.index[(Y['label'] == pair[1]) & (Y['run_num'] != int(testRun))]\n",
    "    else:\n",
    "        obj1IX = Y.index[(Y['label'] == pair[0])]\n",
    "        obj2IX = Y.index[(Y['label'] == pair[1])]\n",
    "\n",
    "    # Get the average of the first object, then the second object\n",
    "    obj1X = np.mean(X[obj1IX], 0)\n",
    "    obj2X = np.mean(X[obj2IX], 0)\n",
    "\n",
    "    # Build the importance map\n",
    "    mult1X = obj1X * B\n",
    "    mult2X = obj2X * B\n",
    "\n",
    "    # Sort these so that they are from least to most important for a given category.\n",
    "    sortmult1X = mult1X.argsort()[::-1]\n",
    "    sortmult2X = mult2X.argsort()\n",
    "\n",
    "    # add to a dictionary for later use\n",
    "    inds[clf.classes_[0]] = sortmult1X\n",
    "    inds[clf.classes_[1]] = sortmult2X\n",
    "\n",
    "    return inds\n",
    "\n",
    "if 'milgram' in os.getcwd():\n",
    "    main_dir='/gpfs/milgram/project/turk-browne/projects/rtTest/'\n",
    "else:\n",
    "    main_dir='/Users/kailong/Desktop/rtTest'\n",
    "\n",
    "working_dir=main_dir\n",
    "os.chdir(working_dir)\n",
    "\n",
    "objects = ['bed', 'bench', 'chair', 'table']\n",
    "\n",
    "\n",
    "if dataSource == \"neurosketch\":\n",
    "    funcdata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/realtime_preprocessed/{sub}_neurosketch_recognition_run_{run}.nii.gz\"\n",
    "    metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "    anat = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/subjects/{sub}_neurosketch/data/nifti/{sub}_neurosketch_anat_mprage_brain.nii.gz\"\n",
    "elif dataSource == \"realtime\":\n",
    "    funcdata = \"/gpfs/milgram/project/turk-browne/projects/rtcloud_kp/subjects/{sub}/ses{ses}_recognition/run0{run}/nifti/{sub}_functional.nii.gz\"\n",
    "    metadata = \"/gpfs/milgram/project/turk-browne/projects/rtcloud_kp/subjects/{sub}/ses{ses}_recognition/run0{run}/{sub}_0{run}_preprocessed_behavData.csv\"\n",
    "    anat = \"$TO_BE_FILLED\"\n",
    "else:\n",
    "    funcdata = \"/gpfs/milgram/project/turk-browne/projects/rtTest/searchout/feat/{sub}_pre.nii.gz\"\n",
    "    metadata = \"/gpfs/milgram/project/turk-browne/jukebox/ntb/projects/sketchloop02/data/features/recog/metadata_{sub}_V1_{phase}.csv\"\n",
    "    anat = \"$TO_BE_FILLED\"\n",
    "\n",
    "# print('mask dimensions: {}'. format(mask.shape))\n",
    "# print('number of voxels in mask: {}'.format(np.sum(mask)))\n",
    "phasedict = dict(zip([1,2,3,4,5,6],[\"12\", \"12\", \"34\", \"34\", \"56\", \"56\"]))\n",
    "imcodeDict={\"A\": \"bed\", \"B\": \"Chair\", \"C\": \"table\", \"D\": \"bench\"}\n",
    "chosenMask = np.load(f\"/gpfs/milgram/project/turk-browne/projects/rtTest/schaefer2018/{subject}/chosenMask.npy\")\n",
    "print(f\"np.sum(chosenMask)={np.sum(chosenMask)}\")\n",
    "# Compile preprocessed data and corresponding indices\n",
    "metas = []\n",
    "for run in range(1, 7):\n",
    "    print(run, end='--')\n",
    "    # retrieve from the dictionary which phase it is, assign the session\n",
    "    phase = phasedict[run]\n",
    "\n",
    "    # Build the path for the preprocessed functional data\n",
    "    this4d = funcdata.format(run=run, phase=phase, sub=subject)\n",
    "\n",
    "    # Read in the metadata, and reduce it to only the TR values from this run, add to a list\n",
    "    thismeta = pd.read_csv(metadata.format(run=run, phase=phase, sub=subject))\n",
    "    if dataSource == \"neurosketch\":\n",
    "        _run = 1 if run % 2 == 0 else 2\n",
    "    else:\n",
    "        _run = run\n",
    "    thismeta = thismeta[thismeta['run_num'] == int(_run)]\n",
    "\n",
    "    if dataSource == \"realtime\":\n",
    "        TR_num = list(thismeta.TR.astype(int))\n",
    "        labels = list(thismeta.Item)\n",
    "        labels = [imcodeDict[label] for label in labels]\n",
    "    else:\n",
    "        TR_num = list(thismeta.TR_num.astype(int))\n",
    "        labels = list(thismeta.label)\n",
    "\n",
    "    print(\"LENGTH OF TR: {}\".format(len(TR_num)))\n",
    "    # Load the functional data\n",
    "    runIm = nib.load(this4d)\n",
    "    affine_mat = runIm.affine\n",
    "    runImDat = runIm.get_fdata()\n",
    "\n",
    "    # Use the TR numbers to select the correct features\n",
    "    features = [runImDat[:,:,:,n+3] for n in TR_num] # here shape is from (94, 94, 72, 240) to (80, 94, 94, 72)\n",
    "    features = np.array(features)\n",
    "    features = features[:, chosenMask==1]\n",
    "    print(\"shape of features\", features.shape, \"shape of chosenMask\", chosenMask.shape)\n",
    "    features = normalize(features)\n",
    "    # features = np.expand_dims(features, 0)\n",
    "\n",
    "    # Append both so we can use it later\n",
    "    # metas.append(labels)\n",
    "    # metas['label']\n",
    "\n",
    "    t=pd.DataFrame()\n",
    "    t['label']=labels\n",
    "    t[\"run_num\"]=run\n",
    "    behav_data=t if run==1 else pd.concat([behav_data,t])\n",
    "\n",
    "    runs = features if run == 1 else np.concatenate((runs, features))\n",
    "\n",
    "dimsize = runIm.header.get_zooms()\n",
    "brain_data = runs\n",
    "print(brain_data.shape)\n",
    "print(behav_data.shape)\n",
    "FEAT=brain_data\n",
    "print(f\"FEAT.shape={FEAT.shape}\")\n",
    "META=behav_data\n",
    "\n",
    "def Class(brain_data,behav_data):\n",
    "    accs = []\n",
    "    for run in range(1,7):\n",
    "        trainIX = behav_data['run_num']!=int(run)\n",
    "        testIX = behav_data['run_num']==int(run)\n",
    "\n",
    "        trainX =  brain_data[trainIX]\n",
    "        trainY =  behav_data.iloc[np.asarray(trainIX)].label\n",
    "\n",
    "        testX =  brain_data[testIX]\n",
    "        testY =  behav_data.iloc[np.asarray(testIX)].label\n",
    "\n",
    "        clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                multi_class='multinomial').fit(trainX, trainY)\n",
    "\n",
    "        # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "        acc = clf.score(testX, testY)\n",
    "        accs.append(acc)\n",
    "    accs\n",
    "    return np.mean(accs)\n",
    "accs=Class(brain_data,behav_data)\n",
    "print(f\"new trained 4 way classifier accuracy={accs}\")\n",
    "\n",
    "\n",
    "# convert item colume to label colume\n",
    "imcodeDict={\n",
    "'A': 'bed',\n",
    "'B': 'chair',\n",
    "'C': 'table',\n",
    "'D': 'bench'}\n",
    "\n",
    "# Which run to use as test data (leave as None to not have test data)\n",
    "accs_rotation_container={}\n",
    "evidence_rotation_container={}\n",
    "for testRun in range(1,7):\n",
    "    # testRun = 6 # when testing: testRun = 2 ; META['run_num'].iloc[:5]=2\n",
    "\n",
    "    # Decide on the proportion of crescent data to use for classification\n",
    "    include = 1\n",
    "    objects = ['bed', 'bench', 'chair', 'table']\n",
    "    allpairs = itertools.combinations(objects,2)\n",
    "    accs={}\n",
    "    # Iterate over all the possible target pairs of objects\n",
    "    for pair in allpairs:\n",
    "        # Find the control (remaining) objects for this pair\n",
    "        altpair = other(pair)\n",
    "\n",
    "        # pull sorted indices for each of the critical objects, in order of importance (low to high)\n",
    "        # inds = get_inds(FEAT, META, pair, testRun=testRun)\n",
    "\n",
    "        # Find the number of voxels that will be left given your inclusion parameter above\n",
    "        # nvox = red_vox(FEAT.shape[1], include)\n",
    "\n",
    "        for obj in pair:\n",
    "            # foil = [i for i in pair if i != obj][0]\n",
    "            for altobj in altpair:\n",
    "\n",
    "                # establish a naming convention where it is $TARGET_$CLASSIFICATION\n",
    "                # Target is the NF pair (e.g. bed/bench)\n",
    "                # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)\n",
    "                naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)\n",
    "\n",
    "                # Pull the relevant inds from your previously established dictionary \n",
    "                # obj_inds = inds[obj]\n",
    "\n",
    "                # If you're using testdata, this function will split it up. Otherwise it leaves out run as a parameter\n",
    "                # if testRun:\n",
    "                #     trainIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] != int(testRun))]\n",
    "                #     testIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] == int(testRun))]\n",
    "                # else:\n",
    "                #     trainIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "                #     testIX = META.index[(META['label'].isin([obj, altobj]))]\n",
    "                # # pull training and test data\n",
    "                # trainX = FEAT[trainIX]\n",
    "                # testX = FEAT[testIX]\n",
    "                # trainY = META.iloc[trainIX].label\n",
    "                # testY = META.iloc[testIX].label\n",
    "\n",
    "                # print(f\"obj={obj},altobj={altobj}\")\n",
    "                # print(f\"unique(trainY)={np.unique(trainY)}\")\n",
    "                # print(f\"unique(testY)={np.unique(testY)}\")\n",
    "                # assert len(np.unique(trainY))==2\n",
    "\n",
    "                # for testRun in range(6):\n",
    "                if testRun:\n",
    "                    trainIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']!=int(testRun))\n",
    "                    testIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']==int(testRun))\n",
    "                else:\n",
    "                    trainIX = ((META['label']==obj) + (META['label']==altobj))\n",
    "                    testIX = ((META['label']==obj) + (META['label']==altobj))\n",
    "                # pull training and test data\n",
    "                trainX = FEAT[trainIX]\n",
    "                testX = FEAT[testIX]\n",
    "                trainY = META.iloc[np.asarray(trainIX)].label\n",
    "                testY = META.iloc[np.asarray(testIX)].label\n",
    "\n",
    "                # print(f\"obj={obj},altobj={altobj}\")\n",
    "                # print(f\"unique(trainY)={np.unique(trainY)}\")\n",
    "                # print(f\"unique(testY)={np.unique(testY)}\")\n",
    "                assert len(np.unique(trainY))==2\n",
    "\n",
    "                # # If you're selecting high-importance features, this bit handles that\n",
    "                # if include < 1:\n",
    "                #     trainX = trainX[:, obj_inds[-nvox:]]\n",
    "                #     testX = testX[:, obj_inds[-nvox:]]\n",
    "\n",
    "                # Train your classifier\n",
    "                clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, \n",
    "                                        multi_class='multinomial').fit(trainX, trainY)\n",
    "\n",
    "\n",
    "                model_folder = f\"{working_dir}{roiloc}/{subject}/clf/\"\n",
    "                mkdir(model_folder)\n",
    "                # Save it for later use\n",
    "                joblib.dump(clf, model_folder +'/{}.joblib'.format(naming))\n",
    "\n",
    "                # Monitor progress by printing accuracy (only useful if you're running a test set)\n",
    "                acc = clf.score(testX, testY)\n",
    "                # print(naming, acc)\n",
    "                accs[naming]=acc\n",
    "    accs_rotation_container[testRun] = accs\n",
    "    evidence_rotation_container[testRun] = morphingTarget(subject,testRun=testRun)\n",
    "# for testRun in range(1,7):\n",
    "#     t=np.mean(list(accs_rotation_container[testRun].values()))\n",
    "#     print(f\"testRun {testRun} mean testing accracy={t}\")\n",
    "#     print(evidence_rotation_container[testRun][2])\n",
    "def getString(string,searchFor,end):\n",
    "    return string.split(searchFor)[1].split(end)[0]\n",
    "# getString(string,searchFor)\n",
    "\n",
    "floors=[]\n",
    "ceils=[]\n",
    "for testRun in range(1,7):\n",
    "    t=np.mean(list(accs_rotation_container[testRun].values()))\n",
    "    print(f\"testRun {testRun} mean testing accracy={t}\")\n",
    "    # print(evidence_rotation_container[testRun][2])\n",
    "    t=np.float(getString(evidence_rotation_container[testRun][2],\"floor=\",\",\"))\n",
    "    print(\"floor=\",t)\n",
    "    floors.append(t)\n",
    "\n",
    "    t=np.float(getString(evidence_rotation_container[testRun][2],\"ceil=\",\"\\n\"))\n",
    "    print(\"ceiling=\",t)\n",
    "    ceils.append(t)\n",
    "    print()\n",
    "    print()\n",
    "print(np.mean(floors))\n",
    "print(np.mean(ceils))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
