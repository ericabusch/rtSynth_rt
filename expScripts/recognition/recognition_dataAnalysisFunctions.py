'''
input: 
    cfg.subjectName
    cfg.dicom_dir # Folder where data is saved 
        # e.g. /gpfs/milgram/project/realtime/DICOM/20201019.rtSynth_pilot001_2.rtSynth_pilot001_2/ 
        # inside which is like 001_000003_000067.dcm

output: save

major steps: 
    figure out the number of runs # should be 8, but need confirmation 
        day1 in cfg.dicom_dir there are 8 runs
        day2 in cfg.dicom_dir there are 2+1+2 runs
        day3 in cfg.dicom_dir there are 2+1+2 runs
        day4 in cfg.dicom_dir there are 2+1+2 runs
        day1 in cfg.dicom_dir there are 8 runs

    # preprocess and alignment
    1. figure out the number of dicoms in each runs, should be the maxTR for each run.
    2. select the middle volume of the first run as the template functional volume and save it inside the cfg and save cfg using pickle
    3. align every other functional volume with templateFunctionalVolume (3dvolreg)
    4. merge the aligned data to the PreprocessedData, finish preprocessing (fslmerge)

    # recog_features.py portion
    5. load the aligned nifti file generated by neurosketch_realtime_preprocess.py
    6. no filter
    7. load mask data and apply mask
    8. load behavior data and push the behavior data back for 2 TRs

    # offlineModelTraining.py portion
    9. load preprocessed and aligned behavior and brain data 
    10. select data with the wanted pattern like AB AC AD BC BD CD 
    11. train correspondng classifier and save the classifier performance and the classifiers themselves.


'''

# import and set up environment
import sys
from subprocess import call
import nibabel as nib
import pydicom as dicom
import numpy as np
import time
import os
from glob import glob
import shutil
import pandas as pd
# from import convertDicomFileToNifti
from rtCommon.imageHandling import convertDicomImgToNifti, readDicomFromFile
from rtCommon.cfg_loading import mkdir,cfg_loading

# setting up code testing environment: 
# from rtCommon.cfg_loading import mkdir,cfg_loading ;cfg = cfg_loading('pilot_sub001.ses1.toml')

def recognition_preprocess(cfg): 
    '''
    purpose: 
        prepare data for the model training code.
    steps:
        convert all dicom files into nii files in the temp dir. 
        find the middle volume of the run1 as the template volume
        align every other functional volume with templateFunctionalVolume (3dvolreg)
    '''

    # convert all dicom files into nii files in the temp dir. 
    tmp_dir=f"{cfg.tmp_folder}{time.time()}/" ; mkdir(tmp_dir)
    dicomFiles=glob(f"{cfg.dicom_dir}/*.dcm") ; dicomFiles.sort()
    for curr_dicom in dicomFiles:
        dicomImg = readDicomFromFile(curr_dicom) # read dicom file
        convertDicomImgToNifti(dicomImg, dicomFilename=f"{tmp_dir}/{curr_dicom.split('/')[-1]}") #convert dicom to nii    
        # os.remove(f"{tmp_dir}/{curr_dicom.split('/')[-1]}") # remove temp dcm file

    # find the middle volume of the run1 as the template volume
    tmp=glob(f"{tmp_dir}/001_000001*.nii") ; tmp.sort()
    cfg.templateFunctionalVolume = f"{cfg.recognition_dir}/templateFunctionalVolume.nii" 
    call(f"cp {tmp[int(len(tmp)/2)]} {cfg.templateFunctionalVolume}", shell=True)

    # align every other functional volume with templateFunctionalVolume (3dvolreg)
    allTRs=glob(f"{tmp_dir}/001_*.nii") ; allTRs.sort()

    # select a list of run IDs based on the runRecording.csv, actualRuns would be [1,2] is the 1st and the 3rd runs are recognition runs.
    runRecording = pd.read_csv(f"{cfg.recognition_dir}../runRecording.csv")
    actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])])
    for curr_run in actualRuns:
        outputFileNames=[]
        runTRs=glob(f"{tmp_dir}/001_{str(curr_run).zfill(6)}_*.nii") ; runTRs.sort()
        for curr_TR in runTRs:
            command = f"3dvolreg \
                -base {cfg.templateFunctionalVolume} \
                -prefix  {curr_TR[0:-4]}_aligned.nii \
                {curr_TR}"
            call(command,shell=True)
            outputFileNames.append(f"{curr_TR[0:-4]}_aligned.nii")
        files=''
        for f in outputFileNames:
            files=files+' '+f
        command=f"fslmerge -t {cfg.recognition_dir}run{curr_run}.nii {files}"
        print('running',command)
        call(command, shell=True)

    # remove the tmp folder
    shutil.rmtree(tmp_dir)

    # load and apply mask
            
    '''
    for each run, 
        load behavior data 
        push the behavior data back for 2 TRs
        save the brain TRs with images
        save the behavior data
    '''

    for curr_run_behav,curr_run in enumerate(actualRuns):
        # load behavior data
        behav_data = behaviorDataLoading(cfg,curr_run_behav+1)

        # brain data is first aligned by pushed back 2TR(4s)
        brain_data = nib.load(f"{cfg.recognition_dir}run{curr_run}.nii.gz").get_data() ; brain_data=np.transpose(brain_data,(3,0,1,2))
        Brain_TR=np.arange(brain_data.shape[0])
        Brain_TR = Brain_TR + 2
        
        # select volumes of brain_data by counting which TR is left in behav_data
        Brain_TR=Brain_TR[list(behav_data['TR'])] # original TR begin with 0
        if Brain_TR[-1]>=brain_data.shape[0]: # when the brain data is not as long as the behavior data, delete the last row
            Brain_TR = Brain_TR[:-1]
            behav_data = behav_data.drop([behav_data.iloc[-1].TR])
        brain_data=brain_data[Brain_TR]
        np.save(f"{cfg.recognition_dir}brain_run{curr_run}.npy", brain_data)
        # save the behavior data
        behav_data.to_csv(f"{cfg.recognition_dir}behav_run{curr_run}.csv")

from scipy.stats import zscore
def normalize(X):
    _X=X.copy()
    _X = zscore(_X, axis=0)
    _X[np.isnan(_X)]=0
    return _X

def minimalClass(cfg,testRun=None):
    '''
    purpose: 
        train offline models

    steps:
        load preprocessed and aligned behavior and brain data 
        select data with the wanted pattern like AB AC AD BC BD CD 
        train correspondng classifier and save the classifier performance and the classifiers themselves.
    '''

    import os
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    import sklearn
    import joblib
    import nibabel as nib
    import itertools
    from sklearn.linear_model import LogisticRegression

    # def gaussian(x, mu, sig):
    #     # mu and sig is determined before each neurofeedback session using 2 recognition runs.
    #     return round(1+18*(1 - np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))))) # map from (0,1) -> [1,19]

    # def jitter(size,const=0):
    #     jit = np.random.normal(0+const, 0.05, size)
    #     X = np.zeros((size))
    #     X = X + jit
    #     return X

    def other(target):
        other_objs = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in target]
        return other_objs

    def red_vox(n_vox, prop=0.1):
        return int(np.ceil(n_vox * prop))

    def get_inds(X, Y, pair, testRun=None):
        
        inds = {}
        
        # return relative indices
        if testRun:
            trainIX = Y.index[(Y['label'].isin(pair)) & (Y['run_num'] != int(testRun))]
        else:
            trainIX = Y.index[(Y['label'].isin(pair))]

        # pull training and test data
        trainX = X[trainIX]
        trainY = Y.iloc[trainIX].label
        
        # Main classifier on 5 runs, testing on 6th
        clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, 
                                    multi_class='multinomial').fit(trainX, trainY)
        B = clf.coef_[0]  # pull betas

        # retrieve only the first object, then only the second object
        if testRun:
            obj1IX = Y.index[(Y['label'] == pair[0]) & (Y['run_num'] != int(testRun))]
            obj2IX = Y.index[(Y['label'] == pair[1]) & (Y['run_num'] != int(testRun))]
        else:
            obj1IX = Y.index[(Y['label'] == pair[0])]
            obj2IX = Y.index[(Y['label'] == pair[1])]

        # Get the average of the first object, then the second object
        obj1X = np.mean(X[obj1IX], 0)
        obj2X = np.mean(X[obj2IX], 0)

        # Build the importance map
        mult1X = obj1X * B
        mult2X = obj2X * B

        # Sort these so that they are from least to most important for a given category.
        sortmult1X = mult1X.argsort()[::-1]
        sortmult2X = mult2X.argsort()

        # add to a dictionary for later use
        inds[clf.classes_[0]] = sortmult1X
        inds[clf.classes_[1]] = sortmult2X
                    
        return inds

    if 'milgram' in os.getcwd():
        main_dir='/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/'
    else:
        main_dir='/Volumes/GoogleDrive/My Drive/Turk_Browne_Lab/rtcloud_kp/'

    working_dir=main_dir
    os.chdir(working_dir)

    '''
    if you read runRecording for current session and found that there are only 4 runs in the current session, 
    you read the runRecording for previous session and fetch the last 4 recognition runs from previous session
    '''
    runRecording = pd.read_csv(f"{cfg.recognition_dir}../runRecording.csv")
    actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])]) # can be [1,2,3,4,5,6,7,8] or [1,2,4,5]
    if len(actualRuns) < 8:
        runRecording_preDay = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/../runRecording.csv")
        actualRuns_preDay = list(runRecording_preDay['run'].iloc[list(np.where(1==1*(runRecording_preDay['type']=='recognition'))[0])])[-(8-len(actualRuns)):] # might be [5,6,7,8]
    else: 
        actualRuns_preDay = []

    # assert len(actualRuns_preDay)+len(actualRuns)==8 
    if len(actualRuns_preDay)+len(actualRuns)<8:
        runRecording_prepreDay = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/../runRecording.csv")
        actualRuns_prepreDay = list(runRecording_prepreDay['run'].iloc[list(np.where(1==1*(runRecording_prepreDay['type']=='recognition'))[0])])[-(8-len(actualRuns)-len(actualRuns_preDay)):] # might be [5,6,7,8]
    else:
        actualRuns_prepreDay = []

    objects = ['bed', 'bench', 'chair', 'table']

    for ii,run in enumerate(actualRuns): # load behavior and brain data for current session
        t = np.load(f"{cfg.recognition_dir}brain_run{run}.npy")
        mask = np.load(f"{cfg.chosenMask}")
        t = t[:,mask==1]
        t = normalize(t)
        brain_data=t if ii==0 else np.concatenate((brain_data,t), axis=0)

        t = pd.read_csv(f"{cfg.recognition_dir}behav_run{run}.csv")
        behav_data=t if ii==0 else pd.concat([behav_data,t])

    for ii,run in enumerate(actualRuns_preDay): # load behavior and brain data for previous session
        t = np.load(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/brain_run{run}.npy")
        mask = np.load(f"{cfg.chosenMask}")
        t = t[:,mask==1]
        t = normalize(t)
        brain_data = np.concatenate((brain_data,t), axis=0)

        t = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/behav_run{run}.csv")
        behav_data = pd.concat([behav_data,t])

    for ii,run in enumerate(actualRuns_prepreDay): # load behavior and brain data for previous session
        t = np.load(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/brain_run{run}.npy")
        mask = np.load(f"{cfg.chosenMask}")
        t = t[:,mask==1]
        t = normalize(t)
        brain_data = np.concatenate((brain_data,t), axis=0)

        t = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/behav_run{run}.csv")
        behav_data = pd.concat([behav_data,t])

    # FEAT=brain_data.reshape(brain_data.shape[0],-1)

    FEAT=brain_data
    print(f"FEAT.shape={FEAT.shape}")
    assert len(FEAT.shape)==2
    # FEAT_mean=np.mean(FEAT,axis=1)
    # FEAT=(FEAT.T-FEAT_mean).T
    # FEAT_mean=np.mean(FEAT,axis=0)
    # FEAT=FEAT-FEAT_mean
    # FEAT = normalize(FEAT)

    META=behav_data

    # convert item colume to label colume
    imcodeDict={
    'A': 'bed',
    'B': 'chair',
    'C': 'table',
    'D': 'bench'}
    label=[]
    for curr_trial in range(META.shape[0]):
        label.append(imcodeDict[META['Item'].iloc[curr_trial]])
    META['label']=label # merge the label column with the data dataframe

    # Which run to use as test data (leave as None to not have test data)
    # testRun = 0 # when testing: testRun = 2 ; META['run_num'].iloc[:5]=2

    # Decide on the proportion of crescent data to use for classification
    allpairs = itertools.combinations(objects,2)
    accs={}
    # Iterate over all the possible target pairs of objects
    for pair in allpairs:
        # Find the control (remaining) objects for this pair
        altpair = other(pair)
        
        # pull sorted indices for each of the critical objects, in order of importance (low to high)
        # inds = get_inds(FEAT, META, pair, testRun=testRun)
        
        # Find the number of voxels that will be left given your inclusion parameter above
        # nvox = red_vox(FEAT.shape[1], include)
        
        for obj in pair:
            # foil = [i for i in pair if i != obj][0]
            for altobj in altpair:
                
                # establish a naming convention where it is $TARGET_$CLASSIFICATION
                # Target is the NF pair (e.g. bed/bench)
                # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)
                naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)
                
                # Pull the relevant inds from your previously established dictionary 
                # obj_inds = inds[obj]
                
                # If you're using testdata, this function will split it up. Otherwise it leaves out run as a parameter
                # if testRun:
                #     trainIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] != int(testRun))]
                #     testIX = META.index[(META['label'].isin([obj, altobj])) & (META['run_num'] == int(testRun))]
                # else:
                #     trainIX = META.index[(META['label'].isin([obj, altobj]))]
                #     testIX = META.index[(META['label'].isin([obj, altobj]))]
                # # pull training and test data
                # trainX = FEAT[trainIX]
                # testX = FEAT[testIX]
                # trainY = META.iloc[trainIX].label
                # testY = META.iloc[testIX].label
                
                # print(f"obj={obj},altobj={altobj}")
                # print(f"unique(trainY)={np.unique(trainY)}")
                # print(f"unique(testY)={np.unique(testY)}")
                # assert len(np.unique(trainY))==2

                if testRun:
                    trainIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']!=int(testRun))
                    testIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']==int(testRun))
                else:
                    trainIX = ((META['label']==obj) | (META['label']==altobj))
                    testIX = ((META['label']==obj) | (META['label']==altobj))
                # pull training and test data
                trainX = FEAT[trainIX]
                testX = FEAT[testIX]
                trainY = META.iloc[np.asarray(trainIX)].label
                testY = META.iloc[np.asarray(testIX)].label

                # print(f"obj={obj},altobj={altobj}")
                # print(f"unique(trainY)={np.unique(trainY)}")
                # print(f"unique(testY)={np.unique(testY)}")
                assert len(np.unique(trainY))==2

                # # If you're selecting high-importance features, this bit handles that
                # if include < 1:
                #     trainX = trainX[:, obj_inds[-nvox:]]
                #     testX = testX[:, obj_inds[-nvox:]]
                
                # Train your classifier
                clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, 
                                            multi_class='multinomial').fit(trainX, trainY)
                
                model_folder = cfg.trainingModel_dir
                # Save it for later use
                joblib.dump(clf, model_folder +'/{}.joblib'.format(naming))
                
                # Monitor progress by printing accuracy (only useful if you're running a test set)
                acc = clf.score(testX, testY)
                print(naming, acc)
                accs[naming]=acc

    print(f"average 2 way clf accuracy={np.mean(list(accs.values()))}")
    # def evidence(trainX,trainY):
    #     # def classifierEvidence(clf,X,Y):
    #     #     ID=np.where((clf.classes_==Y[0])*1==1)[0][0]
    #     #     Evidence=(X@clf.coef_.T+clf.intercept_) if ID==1 else (-(X@clf.coef_.T+clf.intercept_))
    #     #     # Evidence=(X@clf.coef_.T+clf.intercept_) if ID==0 else (-(X@clf.coef_.T+clf.intercept_))
    #     #     return np.asarray(Evidence)
    #     FEAT=trainX
    #     META=trainY
        
    #     A_ID = META['label']=='bed'
    #     X = FEAT[A_ID]

    #     print("floor")
    #     # D evidence for AD_clf when A is presented.
    #     Y = 'bench'
    #     AD_clf=joblib.load(cfg.trainingModel_dir +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
    #     AD_D_evidence = classifierEvidence(AD_clf,X,Y)
    #     evidence_floor = np.mean(AD_D_evidence)
    #     print(f"D evidence for AD_clf when A is presented={evidence_floor}")

    #     # C evidence for AC_clf when A is presented.
    #     Y = 'table'
    #     AC_clf=joblib.load(cfg.trainingModel_dir +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib
    #     AC_C_evidence = classifierEvidence(AC_clf,X,Y)
    #     evidence_floor = np.mean(AC_C_evidence)
    #     print(f"C evidence for AC_clf when A is presented={evidence_floor}")


    #     # D evidence for CD_clf when A is presented.
    #     Y = 'bench'
    #     CD_clf=joblib.load(cfg.trainingModel_dir +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib
    #     CD_D_evidence = classifierEvidence(CD_clf,X,Y)
    #     evidence_floor = np.mean(CD_D_evidence)
    #     print(f"D evidence for CD_clf when A is presented={evidence_floor}")

    #     # C evidence for CD_clf when A is presented.
    #     Y = 'table'
    #     CD_clf=joblib.load(cfg.trainingModel_dir +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib
    #     CD_C_evidence = classifierEvidence(CD_clf,X,Y)
    #     evidence_floor = np.mean(CD_C_evidence)
    #     print(f"C evidence for CD_clf when A is presented={evidence_floor}")

    #     # since this subject has CD_clf C evidence systematically too high(sometimes higher than AC_clf A evidence or AD_clf A evidence), I choose to use 0 as the floor
    #     evidence_floor = 0




    #     print("ceil")
    #     # evidence_ceil  is A evidence in AC and AD classifier
    #     Y = 'bed'
    #     AC_clf=joblib.load(cfg.trainingModel_dir +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib
    #     AC_A_evidence = classifierEvidence(AC_clf,X,Y)
    #     evidence_ceil1 = AC_A_evidence
    #     print(f"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}")

    #     Y = 'bed'
    #     AD_clf=joblib.load(cfg.trainingModel_dir +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
    #     AD_A_evidence = classifierEvidence(AD_clf,X,Y)
    #     evidence_ceil2 = AD_A_evidence
    #     print(f"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}")

    #     # evidence_ceil = np.mean(evidence_ceil1)
    #     # evidence_ceil = np.mean(evidence_ceil2)
    #     evidence_ceil = np.mean((evidence_ceil1+evidence_ceil2)/2)
    #     print(f"evidence_ceil={evidence_ceil}")

    #     mu = (evidence_ceil+evidence_floor)/2
    #     sig = (evidence_ceil-evidence_floor)/2.3548
    #     print(f"floor={evidence_floor}, ceil={evidence_ceil}")
    #     print(f"mu={mu}, sig={sig}")


    # # print the evidence using model training data
    # evidence(FEAT,META)
    # print the evidence using model testing data
    
    return accs
                

def behaviorDataLoading(cfg,curr_run):
    '''
    extract the labels which is selected by the subject and coresponding TR and time
    check if the subject's response is correct. When Item is A,bed, response should be 1, or it is wrong
    '''
    behav_data = pd.read_csv(f"{cfg.recognition_dir}{cfg.subjectName}_{curr_run}.csv")

    # the item(imcode) colume of the data represent each image in the following correspondence
    imcodeDict={
    'A': 'bed',
    'B': 'chair',
    'C': 'table',
    'D': 'bench'}

    # When the imcode code is "A", the correct response should be '1', "B" should be '2'
    correctResponseDict={
    'A': 1,
    'B': 2,
    'C': 1,
    'D': 2}

    # extract the labels which is selected by the subject and coresponding TR and time
    behav_data = behav_data[['TR', 'image_on', 'Resp',  'Item']] # the TR, the real time it was presented, 

    # 为了处理 情况 A.被试的反应慢了一个TR，或者 B.两个按钮都被按了(这种情况下按照第二个按钮处理)
    # 现在的问题是”下一个TR“可能超过了behav_data的长度
    # this for loop is to deal with the situation where Resp is late for 1 TR, or two buttons are pressed. 
    # when Resp is late for 1 TR, set the current Resp as the later Response.
    # when two buttons are pressed, set the current Resp as the later Response because the later one should be the real choice
    for curr_trial in range(behav_data.shape[0]):
        if behav_data['Item'].iloc[curr_trial]  in ["A","B","C","D"]:
            if curr_trial+1<behav_data.shape[0]: # 为了防止”下一个TR“超过behav_data的长度  中文
                if behav_data['Resp'].iloc[curr_trial+1] in [1.0,2.0]:
                    behav_data['Resp'].iloc[curr_trial]=behav_data['Resp'].iloc[curr_trial+1]


    behav_data=behav_data.dropna(subset=['Item'])

    # check if the subject's response is correct. When Item is A,bed, response should be 1, or it is wrong
    isCorrect=[]
    for curr_trial in range(behav_data.shape[0]):
        isCorrect.append(correctResponseDict[behav_data['Item'].iloc[curr_trial]]==behav_data['Resp'].iloc[curr_trial])
    print(f"behavior pressing accuracy for run {curr_run} = {np.mean(isCorrect)}")

    behav_data['isCorrect']=isCorrect # merge the isCorrect clumne with the data dataframe
    behav_data['subj']=[cfg.subjectName for i in range(len(behav_data))]
    behav_data['run_num']=[int(curr_run) for i in range(len(behav_data))]
    behav_data=behav_data[behav_data['isCorrect']] # discard the trials where the subject made wrong selection
    return behav_data




def recognition_preprocess_2run(cfg,run_asTemplate): 
    '''
    purpose: 
        prepare the data for 2 recognition runs     (to later(not in this function) get the morphing target function)
        find the functional template image for current session
    steps:
        convert all dicom files into nii files in the temp dir. 
        find the middle volume of the run1 as the template volume, convert this to the previous template volume space and save the converted file as today's functional template (templateFunctionalVolume)
        align every other functional volume with templateFunctionalVolume (3dvolreg)
    '''
    from shutil import copyfile
    from rtCommon.imageHandling import convertDicomFileToNifti
    # convert all dicom files into nii files in the temp dir. 
    tmp_dir=f"{cfg.tmp_folder}{time.time()}/" ; mkdir(tmp_dir)
    dicomFiles=glob(f"{cfg.dicom_dir}/*.dcm") ; dicomFiles.sort()
    for curr_dicom in dicomFiles:
        # dicomImg = readDicomFromFile(curr_dicom) # read dicom file
        dicomFilename=f"{tmp_dir}{curr_dicom.split('/')[-1]}"
        copyfile(curr_dicom,dicomFilename)
        niftiFilename = dicomFilename[:-4]+'.nii'
        convertDicomFileToNifti(dicomFilename, niftiFilename)
        # convertDicomImgToNifti(dicomImg, dicomFilename=f"{tmp_dir}{curr_dicom.split('/')[-1]}") #convert dicom to nii    
        # os.remove(f"{tmp_dir}/{curr_dicom.split('/')[-1]}") # remove temp dcm file

    # find the middle volume of the run1 as the template volume
    # here you are assuming that the first run is a good run
    run_asTemplate=str(run_asTemplate).zfill(6)
    tmp=glob(f"{tmp_dir}001_{run_asTemplate}*.nii") ; tmp.sort()
    # print(f"all nii files: {tmp}")
    # call(f"cp {tmp[int(len(tmp)/2)]} {cfg.recognition_dir}t.nii", shell=True)

    # convert cfg.templateFunctionalVolume to the previous template volume space 
    cmd=f"flirt -ref {cfg.templateFunctionalVolume} \
        -in {tmp[int(len(tmp)/2)]} \
        -out {cfg.templateFunctionalVolume_converted}"
    print(cmd)
    call(cmd,shell=True) 
        
    # align every other functional volume with templateFunctionalVolume (3dvolreg)
    allTRs=glob(f"{tmp_dir}001_*.nii") ; allTRs.sort()

    # select a list of run IDs based on the runRecording.csv, actualRuns would be [1,2] is the 1st and the 3rd runs are recognition runs.
    runRecording = pd.read_csv(f"{cfg.recognition_dir}../runRecording.csv")
    actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])])[:2]
    for curr_run in actualRuns:
        if not (os.path.exists(f"{cfg.recognition_dir}run{curr_run}.nii.gz") and os.path.exists(f"{cfg.recognition_dir}run{curr_run}.nii")):
            outputFileNames=[]
            runTRs=glob(f"{tmp_dir}001_{str(curr_run).zfill(6)}_*.nii") ; runTRs.sort()
            for curr_TR in runTRs:
                command = f"3dvolreg \
                    -base {cfg.templateFunctionalVolume_converted} \
                    -prefix  {curr_TR[0:-4]}_aligned.nii \
                    {curr_TR}"
                call(command,shell=True)
                outputFileNames.append(f"{curr_TR[0:-4]}_aligned.nii")
            files=''
            for f in outputFileNames:
                files=files+' '+f
            command=f"fslmerge -t {cfg.recognition_dir}run{curr_run}.nii {files}"
            print('running',command)
            call(command, shell=True)

    # remove the tmp folder
    shutil.rmtree(tmp_dir)
            
    '''
    for each run, 
        load behavior data 
        push the behavior data back for 2 TRs
        save the brain TRs with images
        save the behavior data
    '''

    for curr_run_behav,curr_run in enumerate(actualRuns):
        # load behavior data
        behav_data = behaviorDataLoading(cfg,curr_run_behav+1)

        # brain data is first aligned by pushed back 2TR(4s)
        brain_data = nib.load(f"{cfg.recognition_dir}run{curr_run}.nii.gz").get_data() ; brain_data=np.transpose(brain_data,(3,0,1,2))
        Brain_TR=np.arange(brain_data.shape[0])
        Brain_TR = Brain_TR+2

        # select volumes of brain_data by counting which TR is left in behav_data
        Brain_TR=Brain_TR[list(behav_data['TR'])] # original TR begin with 0
        if Brain_TR[-1]>=brain_data.shape[0]: # when the brain data is not as long as the behavior data, delete the last row
            Brain_TR = Brain_TR[:-1]
            behav_data = behav_data.drop([behav_data.iloc[-1].TR])
        brain_data=brain_data[Brain_TR]
        np.save(f"{cfg.recognition_dir}brain_run{curr_run}.npy", brain_data)
        # save the behavior data
        behav_data.to_csv(f"{cfg.recognition_dir}behav_run{curr_run}.csv")


# def classifierEvidence(clf,X,Y): # X shape is [trials,voxelNumber], Y is ['bed', 'bed'] for example # return a 1-d array of probability
#     # This function get the data X and evidence object I want to know Y, and output the trained model evidence.
#     targetID=[np.where((clf.classes_==i)==True)[0][0] for i in Y]
#     # Evidence=(np.sum(X*clf.coef_,axis=1)+clf.intercept_) if targetID[0]==1 else (1-(np.sum(X*clf.coef_,axis=1)+clf.intercept_))
#     Evidence=(X@clf.coef_.T+clf.intercept_) if targetID[0]==1 else (-(X@clf.coef_.T+clf.intercept_))
#     Evidence = 1/(1+np.exp(-Evidence))
#     return np.asarray(Evidence)

# def classifierEvidence(clf,X,Y):
#     ID=np.where((clf.classes_==Y)*1==1)[0][0]
#     p = clf.predict_proba(X)[:,ID]
#     BX=np.log(p/(1-p))
#     return BX

# def classifierEvidence(clf,X,Y):
#     ID=np.where((clf.classes_==Y)*1==1)[0][0]
#     Evidence=(X@clf.coef_.T+clf.intercept_) if ID==1 else (-(X@clf.coef_.T+clf.intercept_))
#     # Evidence=(X@clf.coef_.T+clf.intercept_) if ID==0 else (-(X@clf.coef_.T+clf.intercept_))
#     return np.asarray(Evidence)

def classifierProb(clf,X,Y):
    ID=np.where((clf.classes_==Y)*1==1)[0][0]
    p = clf.predict_proba(X)[:,ID]
    return p



def Wait(waitfor, delay=1):
    while not os.path.exists(waitfor):
        time.sleep(delay)
        print('waiting for {}'.format(waitfor))
        

def fetchXnat(sess_ID):
    "rtSynth_sub001"
    "rtSynth_sub001_ses2"
    import subprocess
    from subprocess import call
    rawPath="/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/expScripts/recognition/recognitionDataAnalysis/raw/"
    proc = subprocess.Popen([f'sbatch {rawPath}../fetchXNAT.sh {sess_ID}'],shell=True)

    Wait(f"{rawPath}{sess_ID}.zip")
    call(f"unzip {rawPath}{sess_ID}.zip")
    time.sleep(10)
    proc = subprocess.Popen([f'sbatch {rawPath}../change2nifti.sh {sess_ID}'],shell=True)

    # furthur work need to be done with this resulting nifti folder

def greedyMask(cfg,N=78): # N used to be 31, 25
    '''
    purpose:
        starting from N ROIs, get the best performed ROI combination in a greedy way
        this code is aggregate_greedy.py adapted to match rtcloud
    steps:
        load the N ROIs from result of neurosketch dataset
        train the model using the NROIs and get the accuracy.

        get the N combinations of N-1 ROIs
        retrain the model and get the accuracy for these N combinations

        get the N-1 combinations of N-2 ROIs
        retrain the model and get the accuracy for these N-1 combinations

        when everything is finished, find the best ROI and save as cfg.chosenMask
        
    '''
    import os
    print(f"conda env={os.environ['CONDA_DEFAULT_ENV']}") 
    import numpy as np
    import nibabel as nib
    import sys
    sys.path.append('/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/')
    import time
    import pandas as pd
    from sklearn.linear_model import LogisticRegression
    import itertools
    # from tqdm import tqdm
    import pickle5 as pickle
    import subprocess
    from subprocess import call
    def save_obj(obj, name):
        with open(name + '.pkl', 'wb') as f:
            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)

    def load_obj(name):
        with open(name + '.pkl', 'rb') as f:
            return pickle.load(f)

    # What subject are you running
    '''
    Takes args (in order):
        subject (e.g. sub001)
        dataSource (e.g. realtime)
        roiloc (wang2014 or schaefer2018)
        N (the number of parcels or ROIs to start with)
    '''


    from rtCommon.cfg_loading import mkdir,cfg_loading
    config="sub001.ses1.toml"
    cfg = cfg_loading(config)

    subject,dataSource,roiloc,N=cfg.subjectName,"realtime","schaefer2018",N
    # subject,dataSource,roiloc,N=sys.argv[1],sys.argv[2],sys.argv[3],int(sys.argv[4])

    print("Running subject {}, with {} as a data source, {}, starting with {} ROIs".format(subject, dataSource, roiloc, N))

    funcdata = cfg.recognition_dir + "brain_run{run}.npy"
    metadata = cfg.recognition_dir + "behav_run{run}.csv"

    workingDir="/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/subjects/sub001/ses1/recognition"

    topN = load_obj(f"{cfg.recognition_expScripts_dir}top{N}ROIs")
    print(f"len(topN)={len(topN)}")
    print(f"topN={topN}")

    def Wait(waitfor, delay=1):
        while not os.path.exists(waitfor):
            time.sleep(delay)
            print('waiting for {}'.format(waitfor))

    imcodeDict={"A": "bed", "B": "Chair", "C": "table", "D": "bench"}

    def getMask(topN, cfg):
        for pn, parc in enumerate(topN):
            _mask = nib.load(cfg.recognition_dir+"mask/GMschaefer_{}".format(parc))
            # schaefer_56.nii.gz
            aff = _mask.affine
            _mask = _mask.get_data()
            _mask = _mask.astype(int)
            # say some things about the mask.
            mask = _mask if pn == 0 else mask + _mask
            mask[mask>0] = 1
        return mask

    mask=getMask(topN, cfg)

    print('mask dimensions: {}'. format(mask.shape))
    print('number of voxels in mask: {}'.format(np.sum(mask)))


    runRecording = pd.read_csv(f"{cfg.recognition_dir}../runRecording.csv")
    actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])]) # can be [1,2,3,4,5,6,7,8] or [1,2,4,5]
    if len(actualRuns) < 8:
        runRecording_preDay = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/../runRecording.csv")
        actualRuns_preDay = list(runRecording_preDay['run'].iloc[list(np.where(1==1*(runRecording_preDay['type']=='recognition'))[0])])[-(8-len(actualRuns)):] # might be [5,6,7,8]
    else: 
        actualRuns_preDay = []

    # assert len(actualRuns_preDay)+len(actualRuns)==8 
    if len(actualRuns_preDay)+len(actualRuns)<8:
        runRecording_prepreDay = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/../runRecording.csv")
        actualRuns_prepreDay = list(runRecording_prepreDay['run'].iloc[list(np.where(1==1*(runRecording_prepreDay['type']=='recognition'))[0])])[-(8-len(actualRuns)-len(actualRuns_preDay)):] # might be [5,6,7,8]
    else:
        actualRuns_prepreDay = []

    objects = ['bed', 'bench', 'chair', 'table']

    brain_data=[]
    behav_data=[]
    for ii,run in enumerate(actualRuns): # load behavior and brain data for current session
        t = np.load(f"{cfg.recognition_dir}brain_run{run}.npy")
        t = normalize(t)
        brain_data.append(t)

        t = pd.read_csv(f"{cfg.recognition_dir}behav_run{run}.csv")
        t=list(t['Item'])
        behav_data.append(t)

    for ii,run in enumerate(actualRuns_preDay): # load behavior and brain data for previous session
        t = np.load(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/brain_run{run}.npy")
        t = normalize(t)
        brain_data.append(t)

        t = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-1}/recognition/behav_run{run}.csv")
        t=list(t['Item'])
        behav_data.append(t)
    for ii,run in enumerate(actualRuns_prepreDay): # load behavior and brain data for previous session
        t = np.load(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/brain_run{run}.npy")
        t = normalize(t)
        brain_data.append(t)

        t = pd.read_csv(f"{cfg.subjects_dir}{cfg.subjectName}/ses{cfg.session-2}/recognition/behav_run{run}.csv")
        t=list(t['Item'])
        behav_data.append(t)

    save_obj([brain_data,behav_data],f"{cfg.projectDir}tmp__folder/{subject}_{dataSource}_{roiloc}_{N}") #{len(topN)}_{i}

    def wait(tmpFile):
        while not os.path.exists(tmpFile+'_result.npy'):
            time.sleep(5)
            print(f"waiting for {tmpFile}_result.npy\n")
        return np.load(tmpFile+'_result.npy')

    def numOfRunningJobs():
        # subprocess.Popen(['squeue -u kp578 | wc -l > squeue.txt'],shell=True) # sl_result = Class(_runs, bcvar)
        randomID=str(time.time())
        # print(f"squeue -u kp578 | wc -l > squeue/{randomID}.txt")
        call(f'squeue -u kp578 | wc -l > {cfg.projectDir}squeue/{randomID}.txt',shell=True)
        numberOfJobsRunning = int(open(f"{cfg.projectDir}squeue/{randomID}.txt", "r").read())
        print(f"numberOfJobsRunning={numberOfJobsRunning}")
        return numberOfJobsRunning

    def Class(brain_data,behav_data):
        # metas = bcvar[0]
        # data4d = data[0]
        print([t.shape for t in brain_data])

        accs = []
        for run in range(8):
            testX = brain_data[run]
            testY = behav_data[run]

            trainX=np.zeros((1,1))
            for i in range(8):
                if i !=run:
                    trainX=brain_data[i] if trainX.shape==(1,1) else np.concatenate((trainX,brain_data[i]),axis=0)

            trainY = []
            for i in range(8):
                if i != run:
                    trainY.extend(behav_data[i])
            clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, 
                                    multi_class='multinomial').fit(trainX, trainY)
                    
            # Monitor progress by printing accuracy (only useful if you're running a test set)
            acc = clf.score(testX, testY)
            accs.append(acc)
        
        return np.mean(accs)

    if not os.path.exists(f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)}.pkl"):
        brain_data = [t[:,mask==1] for t in brain_data]
        # _runs = [runs[:,mask==1]]
        print("Runs shape", [t.shape for t in brain_data])
        slstart = time.time()
        sl_result = Class(brain_data, behav_data)
        print(f"passed {time.time()-slstart}s for training")
        save_obj({"subject":subject,
        "startFromN":N,
        "currNumberOfROI":len(topN),
        "bestAcc":sl_result, # this is the sl_result for the topN, not the bestAcc, bestAcc is for the purpose of keeping consistent with others
        "bestROIs":topN},# this is the topN, not the bestROIs, bestROIs is for the purpose of keeping consistent with others
        f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)}"
        )
    # ./tmp__folder/0125171_40_schaefer2018_neurosketch_39.pkl
    if os.path.exists(f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{1}.pkl"):
        print(f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_1.pkl exists")
        raise Exception('runned or running')

    # N-1
    def next(topN):
        print(f"len(topN)={len(topN)}")
        print(f"topN={topN}")

        if len(topN)==1:
            return None
        else:
            allpairs = itertools.combinations(topN,len(topN)-1)
            topNs=[]
            sl_results=[]
            tmpFiles=[]
            while os.path.exists(f"{cfg.projectDir}tmp__folder/holdon.npy"):
                time.sleep(10)
                print("sleep for 10s ; waiting for ./tmp__folder/holdon.npy to be deleted")
            np.save(f"{cfg.projectDir}tmp__folder/holdon",1)

            # 对于每一个round，提交一个job array，然后等待这个job array完成之后再进行下一轮
            # 具体的方法是首先保存需要的input，也就是这一轮需要用到的tmpFile，然后再将tmpFile除了之外的字符串输入
            skip_flag=0
            for i,_topN in enumerate(allpairs):
                tmpFile=f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)}_{i}"
                print(f"tmpFile={tmpFile}")
                topNs.append(_topN)
                tmpFiles.append(tmpFile)

                if not os.path.exists(tmpFile+'_result.npy'):
                    # prepare brain data(runs) mask and behavior data(bcvar) 

                    save_obj([_topN,subject,dataSource,roiloc,N], tmpFile)

                    # print("kp2")
                    # numberOfJobsRunning = numOfRunningJobs()
                    # print("kp3")
                    # while numberOfJobsRunning > 400: # 300 is not filling it up
                    #     print("kp4 300")
                    #     print("waiting 10, too many jobs running") ; time.sleep(10)
                    #     numberOfJobsRunning = numOfRunningJobs()
                    #     print("kp5")

                    # get the evidence for the current mask
                    # cmd=f'sbatch --requeue {cfg.recognition_expScripts_dir}class.sh {tmpFile}'
                    # print(cmd)
                    # proc = subprocess.Popen([cmd],shell=True) # sl_result = Class(_runs, bcvar) 
                    # print("kp6")
                else:
                    print(tmpFile+'_result.npy exists!')
                    skip_flag+=1

            if skip_flag!=(i+1): # 如果有一个不存在，就需要跑一跑
                command=f'sbatch --array=1-{i+1} {cfg.recognition_expScripts_dir}class.sh ./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)}_'
                print(command)
                proc = subprocess.Popen([command], shell=True) # sl_result = Class(_runs, bcvar) 
            else:
                command=f'sbatch --array=1-{i+1} {cfg.recognition_expScripts_dir}class.sh ./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)}_'
                print(f"skip {command}")

            os.remove(f"{cfg.projectDir}tmp__folder/holdon.npy")

            # wait for everything to be finished and make a summary to find the best performed megaROI
            sl_results=[]
            for tmpFile in tmpFiles:
                sl_result=wait(tmpFile)
                sl_results.append(sl_result)
            print(f"sl_results={sl_results}")
            print(f"max(sl_results)=={max(sl_results)}")
            maxID=np.where(sl_results==max(sl_results))[0][0]
            save_obj({"subject":subject,
            "startFromN":N,
            "currNumberOfROI":len(topN)-1,
            "bestAcc":max(sl_results),
            "bestROIs":topNs[maxID]},
            f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)-1}"
            )
            print(f"bestAcc={max(sl_results)} For {len(topN)-1} = {cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len(topN)-1}")
            tmpFiles=next(topNs[maxID])
            return 0
    tmpFiles=next(topN)



    # when every mask has run, find the best mask and save as the chosenMask
    roiloc="schaefer2018"
    dataSource="realtime"
    subjects=[cfg.subjectName]
    N=N
    GreedyBestAcc=np.zeros((len(subjects),N+1))
    GreedyBestAcc[GreedyBestAcc==0]=None
    for ii,subject in enumerate(subjects):
    #     try:
    #         GreedyBestAcc[ii,40]=np.load("./{}/{}/output/top{}.npy".format(roiloc, subject, N))
    #     except:
    #         pass
        for len_topN_1 in range(N-1,0,-1):
            try:
                # print(f"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len_topN_1}")
                di = load_obj(f"{cfg.projectDir}tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{len_topN_1}")
                GreedyBestAcc[ii,len_topN_1-1] = di['bestAcc']
            except:
                pass
    GreedyBestAcc=GreedyBestAcc.T

    # plt.imshow(GreedyBestAcc)
    # _=plt.figure()
    # for i in range(GreedyBestAcc.shape[0]):
    #     plt.scatter([i]*GreedyBestAcc.shape[1],GreedyBestAcc[i],c='g',s=2)
    # plt.plot(np.arange(GreedyBestAcc.shape[0]),np.nanmean(GreedyBestAcc,axis=1))

    performance_mean = np.nanmean(GreedyBestAcc,axis=1)
    bestID=np.where(performance_mean==max(performance_mean))[0][0]
    di = load_obj(f"./tmp__folder/{subject}_{N}_{roiloc}_{dataSource}_{bestID+1}")
    mask = getMask(di['bestROIs'],cfg)
    np.save(cfg.chosenMask,mask)
    return 0

def AdaptiveThreshold(cfg,ThresholdLog):
    ThresholdList = list(ThresholdLog['threshold'])
    SuccessList = list(ThresholdLog["successful_trials"]) #成功列表

    # 如果现在是第1个session的第一个feedback training run
    # threshold=0.6
    if cfg.session == 2 and cfg.run == 1:
        threshold=0.6

    # 如果现在是第N个session的第一个feedback training run
    # threshold=前一天的最后一个threshold
    elif cfg.run == 1:
        try:
            threshold=ThresholdList[-1]
        except:
            threshold=0.6 #在极端情况下，我可能第二个session没有能够运行feedback session，就必须在第三个session的时候的第一个run才产生第一个threshold
    else:
        threshold=ThresholdList[-1]

        # 如果之前的1个run的进步是<=1
        # threshold=threshold-5%
        if SuccessList[-1] <= 1:
            threshold=threshold - 0.05

        # 如果之前的1个run的进步全部>=11
        # threshold=threshold+5%
        elif SuccessList[-1] >= 11:
            threshold=threshold + 0.05

        elif len(SuccessList)>=3:
            # 如果之前的3个run的进步全部<=3
            # threshold=threshold-5%
            if SuccessList[-1] <= 3 and SuccessList[-2] <= 3 and SuccessList[-3] <= 3:
                threshold=threshold - 0.05

            # 如果之前的3个run的进步全部>=9
            # threshold=threshold+5%
            elif SuccessList[-1] >= 9 and SuccessList[-2] >= 9 and SuccessList[-3] >= 9:
                threshold=threshold - 0.05

        elif len(SuccessList)>=5:
            # 如果之前的5个run的进步全部<=5
            # threshold=threshold-5%
            if SuccessList[-1] <= 5 and SuccessList[-2] <= 5 and SuccessList[-3] <= 5 and SuccessList[-4] <= 5 and SuccessList[-5] <= 5:
                threshold=threshold - 0.05

            # 如果之前的5个run的进步全部>=7
            # threshold=threshold+5%
            elif SuccessList[-1] >= 7 and SuccessList[-2] >= 7 and SuccessList[-3] >= 7 and SuccessList[-4] >= 7 and SuccessList[-5] >= 7:
                threshold=threshold - 0.05

        # 如果之前的任意个run的进步全部【6】
        # threshold=threshold
        else:
            threshold=threshold

    # 不要越界
    if threshold>0.9:
        threshold=0.9
    if threshold<0.4:
        threshold=0.4


    ThresholdLog = ThresholdLog.append({
        'sub':cfg.subjectName, 
        'session':cfg.session, 
        'run':cfg.run, 
        'threshold':threshold},
        ignore_index=True)
    return ThresholdLog

# def morphingTarget(cfg):
#     '''
#     purpose:
#         get the morphing target function
#     steps:
#         load train clf
#         load brain data and behavior data
#         get the morphing target function
#             evidence_floor is C evidence for CD classifier(can also be D evidence for CD classifier)
#             evidence_ceil  is A evidence in AC and AD classifier
#     '''

#     import os
#     import numpy as np
#     import pandas as pd
#     import joblib
#     import nibabel as nib



#     if 'milgram' in os.getcwd():
#         main_dir='/gpfs/milgram/project/turk-browne/projects/rtSynth_rt/'
#     else:
#         main_dir='/Volumes/GoogleDrive/My Drive/Turk_Browne_Lab/rtcloud_kp/'

#     working_dir=main_dir
#     os.chdir(working_dir)

#     runRecording = pd.read_csv(f"{cfg.recognition_dir}../runRecording.csv")
#     actualRuns = list(runRecording['run'].iloc[list(np.where(1==1*(runRecording['type']=='recognition'))[0])]) # can be [1,2,3,4,5,6,7,8] or [1,2,4,5]

#     objects = ['bed', 'bench', 'chair', 'table']

#     for ii,run in enumerate(actualRuns[:2]): # load behavior and brain data for current session
#         t = np.load(f"{cfg.recognition_dir}brain_run{run}.npy")
#         # mask = nib.load(f"{cfg.chosenMask}").get_data()
#         mask = np.load(cfg.chosenMask)
#         t = t[:,mask==1]
#         t = normalize(t)
#         brain_data=t if ii==0 else np.concatenate((brain_data,t), axis=0)

#         t = pd.read_csv(f"{cfg.recognition_dir}behav_run{run}.csv")
#         behav_data=t if ii==0 else pd.concat([behav_data,t])

#     # FEAT=brain_data.reshape(brain_data.shape[0],-1)
#     FEAT=brain_data
#     print("FEAT.shape=",FEAT.shape)
#     assert len(FEAT.shape)==2
#     # FEAT_mean=np.mean(FEAT,axis=1)
#     # FEAT=(FEAT.T-FEAT_mean).T
#     # FEAT_mean=np.mean(FEAT,axis=0)
#     # FEAT=FEAT-FEAT_mean

#     META=behav_data

#     # convert item colume to label colume
#     imcodeDict={
#     'A': 'bed',
#     'B': 'chair',
#     'C': 'table',
#     'D': 'bench'}
#     label=[]
#     for curr_trial in range(META.shape[0]):
#         label.append(imcodeDict[META['Item'].iloc[curr_trial]])
#     META['label']=label # merge the label column with the data dataframe




#     def clf_score(obj,altobj,clf,FEAT,META): # obj is A, altobj is B, clf is AC_clf
#         ID = (META['label']==imcodeDict[obj]) | (META['label']==imcodeDict[altobj])
#         X = FEAT[ID]
#         Y = META['label'][ID]
#         acc = clf.score(X, Y)
#         print(f"{obj}{altobj}_clf accuracy = {acc}")

#     A_ID = (META['label']=='bed')
#     X = FEAT[A_ID]

#     # evidence_floor is C evidence for AC_CD BC_CD CD_CD classifier(can also be D evidence for CD classifier)




#     #try out other forms of floor: C evidence in AC and D evidence for AD

#     # imcodeDict={
#     # 'A': 'bed',
#     # 'B': 'chair',
#     # 'C': 'table',
#     # 'D': 'bench'}

#     # this part is to know the performance of BC and BD clf on current day to judge whether to use both clf in realtime.
#     print("BC_clf BD_clf accuracy")

#     BC_clf=joblib.load(cfg.usingModel_dir +'bedchair_chairtable.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
#     clf_score("B","C",BC_clf,FEAT,META)
#     B_ID = (META['label']=='chair')
#     BC_B_evidence = np.mean(classifierEvidence(BC_clf,FEAT[B_ID],'chair'))
#     print(f"B evidence for BC_clf when B is presented={BC_B_evidence}")

#     BD_clf=joblib.load(cfg.usingModel_dir +'bedchair_chairbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
#     clf_score("B","D",BD_clf,FEAT,META)
#     B_ID = (META['label']=='chair')
#     BD_B_evidence = np.mean(classifierEvidence(BD_clf,FEAT[B_ID],'chair'))
#     print(f"B evidence for BD_clf when B is presented={BD_B_evidence}")

#     print()

#     print("floor")
#     # D evidence for AD_clf when A is presented.
#     Y = 'bench'
#     AD_clf=joblib.load(cfg.usingModel_dir +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
#     clf_score("A","D",AD_clf,FEAT,META)
#     AD_D_evidence = classifierEvidence(AD_clf,X,Y)
#     evidence_floor = np.mean(AD_D_evidence)
#     print(f"D evidence for AD_clf when A is presented={evidence_floor}")

#     # C evidence for AC_clf when A is presented.
#     Y = 'table'
#     AC_clf=joblib.load(cfg.usingModel_dir +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib
#     clf_score("A","C",AC_clf,FEAT,META)
#     AC_C_evidence = classifierEvidence(AC_clf,X,Y)
#     evidence_floor = np.mean(AC_C_evidence)
#     print(f"C evidence for AC_clf when A is presented={evidence_floor}")


#     # D evidence for CD_clf when A is presented.
#     Y = 'bench'
#     CD_clf=joblib.load(cfg.usingModel_dir +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib
#     clf_score("C","D",CD_clf,FEAT,META)
#     CD_D_evidence = classifierEvidence(CD_clf,X,Y)
#     evidence_floor = np.mean(CD_D_evidence)
#     print(f"D evidence for CD_clf when A is presented={evidence_floor}")

#     # C evidence for CD_clf when A is presented.
#     Y = 'table'
#     CD_clf=joblib.load(cfg.usingModel_dir +'bedbench_benchtable.joblib') # These 4 clf are the same: bedbench_benchtable.joblib bedtable_tablebench.joblib benchchair_benchtable.joblib chairtable_tablebench.joblib
#     clf_score("C","D",CD_clf,FEAT,META)
#     CD_C_evidence = classifierEvidence(CD_clf,X,Y)
#     evidence_floor = np.mean(CD_C_evidence)
#     print(f"C evidence for CD_clf when A is presented={evidence_floor}")
#     evidence_floor = 0




#     print("ceil")
#     # evidence_ceil  is A evidence in AC and AD classifier
#     Y = 'bed'
#     AC_clf=joblib.load(cfg.usingModel_dir +'benchtable_tablebed.joblib') # These 4 clf are the same:   bedbench_bedtable.joblib bedchair_bedtable.joblib benchtable_tablebed.joblib chairtable_tablebed.joblib
#     clf_score("A","C",AC_clf,FEAT,META)
#     AC_A_evidence = classifierEvidence(AC_clf,X,Y)
#     evidence_ceil1 = AC_A_evidence
#     print(f"A evidence in AC_clf when A is presented={np.mean(evidence_ceil1)}")

#     Y = 'bed'
#     AD_clf=joblib.load(cfg.usingModel_dir +'bedchair_bedbench.joblib') # These 4 clf are the same:   bedchair_bedbench.joblib bedtable_bedbench.joblib benchchair_benchbed.joblib benchtable_benchbed.joblib
#     clf_score("A","D",AD_clf,FEAT,META)
#     AD_A_evidence = classifierEvidence(AD_clf,X,Y)
#     evidence_ceil2 = AD_A_evidence
#     print(f"A evidence in AD_clf when A is presented={np.mean(evidence_ceil2)}")

#     # evidence_ceil = np.mean(evidence_ceil1)
#     # evidence_ceil = np.mean(evidence_ceil2)
#     evidence_ceil = np.mean((evidence_ceil1+evidence_ceil2)/2)
#     print(f"evidence_ceil={evidence_ceil}")

#     return evidence_floor, evidence_ceil

#     # allpairs = itertools.combinations(objects,2)

#     # # Iterate over all the possible target pairs of objects
#     # for pair in allpairs:
#     #     # Find the control (remaining) objects for this pair
#     #     altpair = other(pair)
       
#     #     for obj in pair:
#     #         # foil = [i for i in pair if i != obj][0]
#     #         for altobj in altpair:
                
#     #             # establish a naming convention where it is $TARGET_$CLASSIFICATION
#     #             # Target is the NF pair (e.g. bed/bench)
#     #             # Classificationis is btw one of the targets, and a control (e.g. bed/chair, or bed/table, NOT bed/bench)
#     #             naming = '{}{}_{}{}'.format(pair[0], pair[1], obj, altobj)
              

#     #             if testRun:
#     #                 trainIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']!=int(testRun))
#     #                 testIX = ((META['label']==obj) + (META['label']==altobj)) * (META['run_num']==int(testRun))
#     #             else:
#     #                 trainIX = ((META['label']==obj) + (META['label']==altobj))
#     #                 testIX = ((META['label']==obj) + (META['label']==altobj))
#     #             # pull training and test data
#     #             trainX = FEAT[trainIX]
#     #             testX = FEAT[testIX]
#     #             trainY = META.iloc[np.asarray(trainIX)].label
#     #             testY = META.iloc[np.asarray(testIX)].label

#     #             print(f"obj={obj},altobj={altobj}")
#     #             print(f"unique(trainY)={np.unique(trainY)}")
#     #             print(f"unique(testY)={np.unique(testY)}")
#     #             assert len(np.unique(trainY))==2

#     #             # # If you're selecting high-importance features, this bit handles that
#     #             # if include < 1:
#     #             #     trainX = trainX[:, obj_inds[-nvox:]]
#     #             #     testX = testX[:, obj_inds[-nvox:]]
                
#     #             # Train your classifier
#     #             clf = LogisticRegression(penalty='l2',C=1, solver='lbfgs', max_iter=1000, 
#     #                                      multi_class='multinomial').fit(trainX, trainY)
                
#     #             model_folder = cfg.trainingModel_dir
#     #             # Save it for later use
#     #             joblib.dump(clf, model_folder +'/{}.joblib'.format(naming))
                
#     #             # Monitor progress by printing accuracy (only useful if you're running a test set)
#     #             acc = clf.score(testX, testY)
#     #             print(naming, acc)
